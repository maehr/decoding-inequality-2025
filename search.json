[
  {
    "objectID": "SECURITY.html",
    "href": "SECURITY.html",
    "title": "Security Policy",
    "section": "",
    "text": "To report a security issue, please email moritz.maehr@faculty.unibe.ch with a description of the issue, the steps you took to create the issue, affected versions, and, if known, mitigations for the issue. This project follows a 90 day disclosure timeline."
  },
  {
    "objectID": "SECURITY.html#reporting-a-vulnerability",
    "href": "SECURITY.html#reporting-a-vulnerability",
    "title": "Security Policy",
    "section": "",
    "text": "To report a security issue, please email moritz.maehr@faculty.unibe.ch with a description of the issue, the steps you took to create the issue, affected versions, and, if known, mitigations for the issue. This project follows a 90 day disclosure timeline."
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "When contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change.\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n\n\nEnsure any install or build dependencies are removed before the end of the layer when doing a build.\nUpdate the README.md with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.\nIncrease the version numbers in any examples files and the README.md to the new version that this Pull Request would represent. The versioning scheme we use is SemVer.\nYou may merge the Pull Request in once you have the sign-off of two other developers, or if you do not have permission to do that, you may request the second reviewer to merge it for you."
  },
  {
    "objectID": "CONTRIBUTING.html#pull-request-process",
    "href": "CONTRIBUTING.html#pull-request-process",
    "title": "Contributing",
    "section": "",
    "text": "Ensure any install or build dependencies are removed before the end of the layer when doing a build.\nUpdate the README.md with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.\nIncrease the version numbers in any examples files and the README.md to the new version that this Pull Request would represent. The versioning scheme we use is SemVer.\nYou may merge the Pull Request in once you have the sign-off of two other developers, or if you do not have permission to do that, you may request the second reviewer to merge it for you."
  },
  {
    "objectID": "LICENSE-CCBYSA.html",
    "href": "LICENSE-CCBYSA.html",
    "title": "Decoding Inequality 2025",
    "section": "",
    "text": "Attribution-ShareAlike 4.0 International\n=======================================================================\nCreative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n=======================================================================\nCreative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)\n\nnever produces Adapted Material.\n\nDownstream recipients.\n\nOffer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nAdditional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nNo downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\n\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\nTO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n=======================================================================\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org.\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/blog.html",
    "href": "contents/blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT im Klassenzimmer\n\n\nEin Manifest\n\n\n\n\n\n\n\n\n27.05.2025\n\n\nAnke Breihan\n\n\n\n\n\n\n\n\n\n\n\n\nSaubere und gerechte KI?\n\n\nDie Schattenseiten einer Technologie im Umwelt- und Gerechtigkeitsdiskurs\n\n\n\n\n\n\n\n\n21.05.2025\n\n\nRafael Klöpper\n\n\n\n\n\n\n\n\n\n\n\n\nThe Humans in the Loop: Labor Exploitation and AI Training\n\n\nAttempting a self-experiment.\n\n\n\n\n\n\n\n\n30.05.2025\n\n\nQuirin Pfister\n\n\n\n\n\nKeine Treffer\n Zurück nach oben",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge"
    ]
  },
  {
    "objectID": "contents/interesting-stuff.html",
    "href": "contents/interesting-stuff.html",
    "title": "Interessante Links",
    "section": "",
    "text": "Interessante Links\nWir haben hier einige interessante Dinge für Sie zusammengestellt. Schauen Sie sich die Liste unten an und klicken Sie auf die Links, um mehr zu erfahren.\n\n\n   \n    \n    \n      Sortieren nach\n      Voreinstellung\n      \n        Titel\n      \n      \n        Autor:in\n      \n      \n        Datum - Datum (aufsteigend)\n      \n      \n        Datum - Neueste\n      \n      \n        Kategorien\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nFineWeb: Decanting the Web for the Finest Text Data at Scale\n\n\n\npaper\n\n\n\nThe performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. This blog post explores the challenges of creating…\n\n\n\nMoritz Mähr\n\n\n01.04.2025\n\n\n\n\n\n\n\n\n\n\nWinterkongress 2025\n\n\n\nrecording\n\n\n\nDer Winterkongress ist die wichtigste Veranstaltung für digitale Freiheitsrechte in der Schweiz. Sie ist nicht-kommerziell und wird von und für die Community veranstaltet.…\n\n\n\nMoritz Mähr\n\n\n20.03.2025\n\n\n\n\n\n\n\n\n\n\nSeminar: Critical Data Studies (Summer 2024)\n\n\n\ncourse\n\n\n\nThis is the main course website for the seminar Critical Data Studies in summer term 2024 at University of Bayreuth. The umbrella topic for this iteration of the seminar is…\n\n\n\nMoritz Mähr\n\n\n21.11.2024\n\n\n\n\n\n\n\n\n\n\nThe Good Robot\n\n\n\npodcast\n\n\n\nJoin Dr Eleanor Drage and Dr Kerry McInerney as they ask the experts: what is good technology? Is ‘good’ technology even possible? And how can feminism help us work towards…\n\n\n\nMoritz Mähr\n\n\n21.11.2024\n\n\n\n\n\n\n\n\n\n\nMystery AI Hype Theater 3000\n\n\n\npodcast\n\n\n\nArtificial Intelligence has too much hype. In this stream, linguist Prof. Emily M. Bender and sociologist Dr. Alex Hanna break down the AI hype, separate fact from fiction…\n\n\n\nMoritz Mähr\n\n\n21.11.2024\n\n\n\n\n\n\nKeine Treffer\n\nWenn Sie interessante Links oder Ressourcen haben, die Sie teilen möchten, öffnen Sie einfach ein Issue. Wir freuen uns auf Ihre Beiträge!\n\n\n\n\n\n Zurück nach oben",
    "crumbs": [
      "Kursbeschreibung",
      "Interessante Links"
    ]
  },
  {
    "objectID": "contents/sessions/08.html",
    "href": "contents/sessions/08.html",
    "title": "Session 8",
    "section": "",
    "text": "Recap\nLeseauftrag gemeinsam anschauen\nApplikationen diskutieren\n\n\n\nmündlich\n\n\n\nThis influential 2021 paper by Emily Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell critically examines the rapid development of increasingly large language models (LMs) such as GPT-3 and Google’s Switch-C. It questions the assumption that “bigger is always better” in natural language processing (NLP) and highlights key risks that should concern technologists and humanists alike.\n\n\nLarge LMs are trained to predict and generate text based on statistical patterns in massive datasets. While they can produce impressively fluent text, the authors argue that this does not mean they understand language. Instead, they are “stochastic parrots”: systems that generate plausible-sounding output without actual comprehension or intent.\n\n\n\nTraining large LMs consumes enormous amounts of energy, contributing significantly to CO₂ emissions. This is a justice issue: the environmental impact disproportionately affects marginalized communities, while the benefits of these technologies accrue mostly to wealthy, English-speaking users and corporations.\n\n\n\nMost LMs are trained on huge, uncurated datasets scraped from the internet. These datasets overrepresent hegemonic, often discriminatory viewpoints and exclude marginalized voices. The models inherit and reproduce these biases, including racism, sexism, ableism, and more—creating risks of psychological harm and systemic discrimination.\n\n\n\nBecause these systems can produce text that appears coherent, people may falsely assume the content is meaningful, factual, or generated by a human. This creates dangers of automation bias, misinformation, and manipulation (e.g. through fake news, extremist content, or abusive language).\n\n\n\nA core critique is that datasets are often undocumented or under-documented, making it impossible to understand or audit how LMs behave. The authors argue for a “documentation budget” and recommend curating smaller, well-understood datasets over massive opaque ones.\n\n\n\nFocusing on ever-larger LMs draws attention and resources away from alternative, potentially more equitable paths in language technology, such as: - Smaller, task-specific models - Multilingual or low-resource language research - Approaches centered on human linguistic meaning, not just surface-level form\n\n\n\nThe authors propose shifting toward: - Pre-mortem analysis: anticipate harms before development begins - Value-sensitive design: include affected stakeholders in the design process - Environmental benchmarking: consider carbon and energy efficiency as research metrics - Research redirection: focus less on leaderboard metrics and more on social impact and inclusivity\nWhy It Matters for Digital Humanities: This paper bridges critical perspectives from linguistics, ethics, and STS (science and technology studies). For DH scholars, it encourages skepticism toward “black-box” AI systems and stresses the importance of: - Interrogating data sources - Understanding power and representation in digital systems - Advocating for inclusive, sustainable, and human-centered computational research\n\n\n\n\nmündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 8"
    ]
  },
  {
    "objectID": "contents/sessions/08.html#recap",
    "href": "contents/sessions/08.html#recap",
    "title": "Session 8",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 8"
    ]
  },
  {
    "objectID": "contents/sessions/08.html#leseauftrag-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big",
    "href": "contents/sessions/08.html#leseauftrag-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big",
    "title": "Session 8",
    "section": "",
    "text": "This influential 2021 paper by Emily Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell critically examines the rapid development of increasingly large language models (LMs) such as GPT-3 and Google’s Switch-C. It questions the assumption that “bigger is always better” in natural language processing (NLP) and highlights key risks that should concern technologists and humanists alike.\n\n\nLarge LMs are trained to predict and generate text based on statistical patterns in massive datasets. While they can produce impressively fluent text, the authors argue that this does not mean they understand language. Instead, they are “stochastic parrots”: systems that generate plausible-sounding output without actual comprehension or intent.\n\n\n\nTraining large LMs consumes enormous amounts of energy, contributing significantly to CO₂ emissions. This is a justice issue: the environmental impact disproportionately affects marginalized communities, while the benefits of these technologies accrue mostly to wealthy, English-speaking users and corporations.\n\n\n\nMost LMs are trained on huge, uncurated datasets scraped from the internet. These datasets overrepresent hegemonic, often discriminatory viewpoints and exclude marginalized voices. The models inherit and reproduce these biases, including racism, sexism, ableism, and more—creating risks of psychological harm and systemic discrimination.\n\n\n\nBecause these systems can produce text that appears coherent, people may falsely assume the content is meaningful, factual, or generated by a human. This creates dangers of automation bias, misinformation, and manipulation (e.g. through fake news, extremist content, or abusive language).\n\n\n\nA core critique is that datasets are often undocumented or under-documented, making it impossible to understand or audit how LMs behave. The authors argue for a “documentation budget” and recommend curating smaller, well-understood datasets over massive opaque ones.\n\n\n\nFocusing on ever-larger LMs draws attention and resources away from alternative, potentially more equitable paths in language technology, such as: - Smaller, task-specific models - Multilingual or low-resource language research - Approaches centered on human linguistic meaning, not just surface-level form\n\n\n\nThe authors propose shifting toward: - Pre-mortem analysis: anticipate harms before development begins - Value-sensitive design: include affected stakeholders in the design process - Environmental benchmarking: consider carbon and energy efficiency as research metrics - Research redirection: focus less on leaderboard metrics and more on social impact and inclusivity\nWhy It Matters for Digital Humanities: This paper bridges critical perspectives from linguistics, ethics, and STS (science and technology studies). For DH scholars, it encourages skepticism toward “black-box” AI systems and stresses the importance of: - Interrogating data sources - Understanding power and representation in digital systems - Advocating for inclusive, sustainable, and human-centered computational research",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 8"
    ]
  },
  {
    "objectID": "contents/sessions/08.html#applikationen-diskutieren",
    "href": "contents/sessions/08.html#applikationen-diskutieren",
    "title": "Session 8",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 8"
    ]
  },
  {
    "objectID": "contents/sessions/07.html",
    "href": "contents/sessions/07.html",
    "title": "Session 6",
    "section": "",
    "text": "Einführung: «Machine Bias. There’s software used across the country to predict future criminals. And it’s biased against blacks.» (15 Min.)\n\nVorstellung des Falls: ProPublica-Untersuchung zu COMPAS, einem Algorithmus zur Risikobewertung von Straftätern.\nProblem: Schwarze Personen wurden fälschlicherweise häufiger als Hochrisiko eingestuft als weiße Personen.\nDiskussion: Erste Reaktionen der Studierenden auf den Fall.\n\nTeil 1: Diskriminierungsrisiken in prädiktiven Algorithmen (30 Min.)\nA. Gruppenarbeit (15 Min.)\n1.     Studierende analysieren in Kleingruppen: Warum generiert COMPAS rassistische Ergebnisse?\n1.1.   Datenprobleme: Verzerrte Trainingsdaten aus einem diskriminierenden Justizsystem.\n1.2.   Intransparenz: Proprietäre Algorithmen verhindern Nachvollziehbarkeit.\n1.3.   Fehlende Kontextualisierung: Sozialstrukturelle Faktoren werden ignoriert.\nB. Plenumsdiskussion (15 Min.)\n1.     Ergebnisse der Gruppen werden vorgestellt und diskutiert.\n2.     Bezug zu Predictive Policing: Ähnliche Probleme in der polizeilichen Risikoanalyse?\n3.     Regulierungsansätze: Wie könnte man algorithmische Voreingenommenheit verhindern?\nTeil 2: KI im Migrationswesen – Der Schweizer Algorithmus (45 Min.)\nA. Nutzen und positive Aspekte (20 Min.)\n1.     Fallstudie: Algorithmus zur Arbeitsmarktintegration von Flüchtenden (ETH Zürich, Bansak et al. 2018).\n2.     Wie funktioniert der Algorithmus? Datenbasierte Zuweisung von Geflüchteten zu Kantonen mit hohen Integrationschancen.\n3.     Vorteile:\n3.1.   Effizienzsteigerung: Schnellere Integration in den Arbeitsmarkt.\n3.2.   Datenbasierte Politik: Optimierung der Ressourcenallokation.\n3.3.   Positive empirische Ergebnisse: Studie zeigt signifikante Verbesserungen.\nB. Kritische Reflexion und Herausforderungen (25 Min.)\n1.     Gruppenarbeit (10 Min.): Studierende erarbeiten potenzielle Risiken:\n1.1.   Diskriminierungspotenzial: Welche Daten werden genutzt, und sind sie neutral?\n1.2.   Fehlende Wahlfreiheit: Algorithmische Zuweisung vs. individuelle Präferenzen.\n1.3.   Transparenz & Kontrolle: Wer entscheidet über die Kriterien?\n2.     Gemeinsame Diskussion (15 Min.): Welche ethischen und rechtlichen Rahmenbedingungen braucht es?\nAbschlussdiskussion & Fazit (10 Min.)\n1.     Vergleich: Justiz- vs. Migrationsalgorithmen – unterschiedliche Kontexte, ähnliche Risiken?\n2.     Welche Maßnahmen könnten faire KI-Systeme fördern?\n3.     Offene Fragen für zukünftige Forschung und Politik.\nVorbereitete Literatur:\n\nLauren Kirchner Mattu Jeff Larson, «Machine Bias» (ProPublica), zugegriffen 25. November 2024, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n«Jobs für Flüchtlinge - Algorithmus verteilt neu Asylbewerber auf Kantone» (Schweizer Radio und Fernsehen (SRF), 10. Mai 2018), https://www.srf.ch/news/schweiz/jobs-fuer-fluechtlinge-algorithmus-verteilt-neu-asylbewerber-auf-kantone.\n«Algorithmus verbessert Erwerbschancen von Flüchtlingen» (ETH Zürich, 18. Januar 2018), https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/01/algorithmus-verbessert-erwerbschancen-von-fluechtlingen.html.\n\n\n\n\n Back to top",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 6"
    ]
  },
  {
    "objectID": "contents/sessions/04.html",
    "href": "contents/sessions/04.html",
    "title": "Session 4",
    "section": "",
    "text": "Recap Session 3\nLeseauftrag gemeinsam anschauen\nDatenbegriff klären\n\n\n\nmündlich\n\n\n\n\n\nThe paper discusses the environmental impact of training machine learning (ML) models, emphasizing the factors contributing to carbon emissions. It introduces the Machine Learning Emissions Calculator to estimate emissions and offers recommendations for mitigating ML-related carbon footprints.\n\n\n\n\nEnergy Source & Location\n\nThe carbon footprint of ML training varies based on the energy grid used by the cloud server.\n\nRegions reliant on fossil fuels have significantly higher emissions compared to those powered by renewables.\n\nExample: CO₂ emissions range from 20g CO₂eq/kWh (Quebec) to 736.6g CO₂eq/kWh (Iowa, USA).\n\nComputing Infrastructure & Training Time\n\nML models require substantial computation, often involving multiple GPUs for extended periods.\n\nHardware efficiency matters: newer GPUs and TPUs are more energy-efficient.\n\nUsing pre-trained models and fine-tuning can reduce emissions compared to training from scratch.\n\n\n\n\n\n\nDeveloped to estimate CO₂ emissions based on:\n\nLocation of training server\n\nType of hardware used\n\nTraining duration\n\n\nUses publicly available data to ensure transparency and allow improvements over time.\n\n\n\n\n\nChoosing Cloud Providers Wisely\n\nGoogle Cloud, Microsoft Azure, and AWS vary in sustainability efforts.\n\nSelecting carbon-neutral cloud providers or low-emission data centers can significantly reduce impact.\n\nSelecting Data Center Locations\n\nTraining in regions with renewable energy can lower emissions up to 40 times compared to fossil-fuel-powered locations.\n\nReducing Wasted Resources\n\nRandom search for hyperparameter tuning is more efficient than grid search.\n\nAvoid unnecessary training experiments through better planning and debugging.\n\nUsing Energy-Efficient Hardware\n\nTPUs and newer GPUs (e.g., TPU3) have significantly better FLOPS/Watt efficiency compared to CPUs.\n\n\n\n\n\n\nGlobal Load Balancing: A shift towards low-carbon data centers may still require fossil-fuel-powered backup servers.\nTransparency Issues: Lack of precise data on energy consumption from cloud providers limits accuracy.\nInference Emissions: While the focus is on training, deploying models also contributes to emissions.\nTrade-offs: Balancing efficiency and scientific progress, especially in AI applications for climate solutions.\n\n\n\n\nThe paper highlights the growing energy demands of ML and provides a practical framework to quantify and mitigate its environmental impact. The authors advocate for transparency, efficiency in model training, and sustainable computing choices.\n\n\n\n\nTBD",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 4"
    ]
  },
  {
    "objectID": "contents/sessions/04.html#recap-session-3",
    "href": "contents/sessions/04.html#recap-session-3",
    "title": "Session 4",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 4"
    ]
  },
  {
    "objectID": "contents/sessions/04.html#leseauftrag-quantifying-the-carbon-emissions-of-machine-learning",
    "href": "contents/sessions/04.html#leseauftrag-quantifying-the-carbon-emissions-of-machine-learning",
    "title": "Session 4",
    "section": "",
    "text": "The paper discusses the environmental impact of training machine learning (ML) models, emphasizing the factors contributing to carbon emissions. It introduces the Machine Learning Emissions Calculator to estimate emissions and offers recommendations for mitigating ML-related carbon footprints.\n\n\n\n\nEnergy Source & Location\n\nThe carbon footprint of ML training varies based on the energy grid used by the cloud server.\n\nRegions reliant on fossil fuels have significantly higher emissions compared to those powered by renewables.\n\nExample: CO₂ emissions range from 20g CO₂eq/kWh (Quebec) to 736.6g CO₂eq/kWh (Iowa, USA).\n\nComputing Infrastructure & Training Time\n\nML models require substantial computation, often involving multiple GPUs for extended periods.\n\nHardware efficiency matters: newer GPUs and TPUs are more energy-efficient.\n\nUsing pre-trained models and fine-tuning can reduce emissions compared to training from scratch.\n\n\n\n\n\n\nDeveloped to estimate CO₂ emissions based on:\n\nLocation of training server\n\nType of hardware used\n\nTraining duration\n\n\nUses publicly available data to ensure transparency and allow improvements over time.\n\n\n\n\n\nChoosing Cloud Providers Wisely\n\nGoogle Cloud, Microsoft Azure, and AWS vary in sustainability efforts.\n\nSelecting carbon-neutral cloud providers or low-emission data centers can significantly reduce impact.\n\nSelecting Data Center Locations\n\nTraining in regions with renewable energy can lower emissions up to 40 times compared to fossil-fuel-powered locations.\n\nReducing Wasted Resources\n\nRandom search for hyperparameter tuning is more efficient than grid search.\n\nAvoid unnecessary training experiments through better planning and debugging.\n\nUsing Energy-Efficient Hardware\n\nTPUs and newer GPUs (e.g., TPU3) have significantly better FLOPS/Watt efficiency compared to CPUs.\n\n\n\n\n\n\nGlobal Load Balancing: A shift towards low-carbon data centers may still require fossil-fuel-powered backup servers.\nTransparency Issues: Lack of precise data on energy consumption from cloud providers limits accuracy.\nInference Emissions: While the focus is on training, deploying models also contributes to emissions.\nTrade-offs: Balancing efficiency and scientific progress, especially in AI applications for climate solutions.\n\n\n\n\nThe paper highlights the growing energy demands of ML and provides a practical framework to quantify and mitigate its environmental impact. The authors advocate for transparency, efficiency in model training, and sustainable computing choices.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 4"
    ]
  },
  {
    "objectID": "contents/sessions/04.html#was-können-wir-tun",
    "href": "contents/sessions/04.html#was-können-wir-tun",
    "title": "Session 4",
    "section": "",
    "text": "TBD",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 4"
    ]
  },
  {
    "objectID": "contents/sessions/01.html",
    "href": "contents/sessions/01.html",
    "title": "Session 1",
    "section": "",
    "text": "Lernziele\n\nBegriffsverständnis: Diskriminierung, strukturelle Diskriminierung, unbewusste Diskriminierung (unconscious bias).\nSozialer Kontext: Erkennen, wie Sozialisierung und gesellschaftliche Machtverhältnisse Bias in Daten und Algorithmen einschleusen.\nPraxisbezug: Verstehen, wie KI-Systeme Ungleichheiten reproduzieren können.\nReflexion: Eigene Vorannahmen hinterfragen und erste Schritte kennenlernen, um Bias in algorithmischen Systemen zu verringern.\n\nWorkshop\nTeil 1 (45 Minuten)\n\nBegrüßung & Einführung (ca. 5 Minuten)\n\n\nVorstellung des Workshop-Ziels: Sensibilisierung für unterschiedliche Formen von Diskriminierung und deren Einfluss auf KI-Systeme.\nKurze Vorstellung der Teilnehmenden (z.B. Blitzlicht: „Welcher Aspekt von KI-Bias interessiert dich am meisten?“).\n\n\nBegriffe klären: Diskriminierung, strukturelle Diskriminierung, unbewusste Diskriminierung (ca. 10 Minuten)\n\n\nDiskriminierung: Ungleichbehandlung aufgrund von Gruppenzugehörigkeit (z.B. Geschlecht, Ethnie, Religion).\nStrukturelle Diskriminierung: Diskriminierung, die in gesellschaftlichen Institutionen und Prozessen verankert ist (z.B. Bildung, Arbeitsmarkt).\nUnbewusste Diskriminierung / Unconscious Bias: Vorurteile und Annahmen, die Menschen unbemerkt in ihren Handlungen leiten.\n\nMethode: Kurzer Input-Vortrag mit Beispielen (z.B. gender pay gap, „racial bias“ in Justizsystemen).\n\nGruppenübung: Beispiele für (un)bewusste Diskriminierung sammeln (ca. 15 Minuten)\n\n\nAufgabe: Kleingruppen (3–4 Personen) überlegen sich Alltagsbeispiele, in denen sie selbst oder Menschen in ihrem Umfeld diskriminiert wurden oder in denen sie unbewusste Vorurteile beobachtet haben.\nZiel: Herausarbeiten, dass Diskriminierung häufig subtil und unbemerkt abläuft.\n\nMethode: Anschließendes kurzes Plenum (2–3 Minuten pro Gruppe), um die Beispiele vorzustellen.\n\nÜberleitung zu KI: Warum ist das relevant für Algorithmen? (ca. 10 Minuten)\n\n\nWie gelangen diese gesellschaftlichen Vorurteile und Machtverhältnisse in Daten?\nKurzer Überblick über Datenerhebung und -auswahl (Stichwort: „biased data“).\nErster Ausblick, wie KI-Systeme daraus Diskriminierung reproduzieren können.\n\nMethode: Vortrag mit einfachen Beispielen (z.B. Gesichtserkennung, die bestimmte Hauttöne schlechter erkennt).\n\nAbschluss Teil 1 & Ausblick (ca. 5 Minuten)\n\n\nKurze Zusammenfassung: Was wurde bisher gelernt?\nVorschau auf Teil 2: Vertiefte Auseinandersetzung mit konkreten Beispielen und Lösungsansätzen.\n\n\nTeil 2 (45 Minuten)\n\nKurze Wiederholung (ca. 5 Minuten)\n\n\nRecap der wichtigsten Punkte aus Teil 1.\nEventuell kurze Rückfragen oder Anmerkungen aus dem Plenum.\n\n\nPraxisbeispiele: Bias in KI-Systemen (ca. 15 Minuten)\n\n\nFallbeispiele:\nRecruiting-Tools: Benachteiligung von Bewerber*innen durch automatisierte Systeme.\nGesichtserkennung: Schlechtere Erkennungsraten für People of Color.\nSprachmodelle: Reproduktion von stereotypen Geschlechterrollen.\nDiskussion: Warum treten diese Verzerrungen auf? Welche Rolle spielt Datenauswahl, Labeling und Training?\n\nMethode: Präsentation der Beispiele (kurze Zusammenfassung oder kurze Videoclips) und anschließend Offene Fragen ins Plenum.\n\nKleingruppenarbeit: „Wo liegt das Problem?“ (ca. 15 Minuten)\n\n\nAufgabe:\n\n\nWählt eines der vorgestellten Beispiele aus.\nIdentifiziert die gesellschaftlichen Strukturen und Vorurteile, die sich darin abbilden.\nÜberlegt, wie die Daten erhoben wurden und wo in diesem Prozess Bias entsteht.\n\n\nZiel: Verständnis, dass technische Systeme immer in soziale Kontexte eingebettet sind und diese widerspiegeln (und oft verstärken).\n\nMethode: Kleingruppen erarbeiten das Problem, dokumentieren zentrale Punkte auf einem Flipchart oder digital (z.B. Miro, Google Jamboard).\n\nPlenum & Lösungsansätze (ca. 5 Minuten)\n\n\nKurze Präsentation der Ergebnisse aus den Kleingruppen (1–2 Minuten pro Gruppe).\nErste Ideen, wie man Bias reduzieren kann:\nDiversität im Entwicklungsteam,\nSensible Datenerhebung,\nTransparente Dokumentation (z.B. „Datasheets for Datasets“),\nExterne Audits und Testverfahren.\n\n\nAbschluss & Reflexion (ca. 5 Minuten)\n\n\nKurze Zusammenfassung der wichtigsten Erkenntnisse:\nWie beeinflussen Sozialisierung und strukturelle Ungleichheit die Daten?\nWarum ist es entscheidend, diese Einflüsse zu verstehen, bevor man Algorithmen trainiert?\nReflexionsrunde: Jede_r Teilnehmer_in teilt in einem Satz, was sie/er aus dem Workshop mitnimmt.\nAusblick: Hinweis auf weiterführende Literatur/Materialien zu Fairness in Machine Learning und Critical Algorithm Studies.\n\n\nBenötigte Materialien & Methoden\n\nBeamer/Präsentationsmaterial: Zum Vorstellen von Definitionen und Beispielen.\nFlipchart/Whiteboard: Für spontane Notizen und Ergebnisse aus den Kleingruppen.\nKleingruppenräume oder genügend Platz im Seminarraum, damit Gruppen parallel arbeiten können.\nDigitale Tools (optional): Miro, Google Jamboard, Mentimeter für interaktive Umfragen.\n\n\nWeiterführende Ressourcen\n\nKate Crawford: Atlas of AI (Buch)\nRuha Benjamin: Race After Technology (Buch)\nJoy Buolamwini: Gender Shades (Studie zur Gesichtserkennung)\nCathy O’Neil: Weapons of Math Destruction (Buch)\nDokumentation: Coded Bias (Film)\n\n\nFazit\nDer Workshop vermittelt in zwei kompakten Einheiten die grundlegenden Konzepte von Diskriminierung, struktureller Diskriminierung und unbewusster Diskriminierung. Anhand konkreter Beispiele wird deutlich, wie sich Bias in Datensätzen und algorithmischen Modellen manifestiert und welche Folgen dies für gesellschaftliche Ungleichheit hat. Durch Diskussionen und Gruppenarbeiten werden die Teilnehmenden für die Komplexität und Relevanz dieser Themen sensibilisiert und lernen erste Lösungsansätze kennen.\n\n\n\n\n Back to top",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 1"
    ]
  },
  {
    "objectID": "contents/sessions/02.html",
    "href": "contents/sessions/02.html",
    "title": "Session 2",
    "section": "",
    "text": "Recap Session 1\nÜberblick ML-Lebenszyklus\nLeseauftrag gemeinsam anschauen\nTypische Entscheidungen bei der Architekturwahl\n\n\n\nmündlich\n\n\n\nDer ML-Lebenszyklus:\n\nArchitekturauswahl: Diskussion verschiedener ML-Architekturen und ihrer Auswirkungen auf Modellkapazitäten und -grenzen. Kritische Betrachtung, wie architektonische Entscheidungen bestimmte Voreingenommenheiten einbetten können.\nDatensammlung: Untersuchung von Datenquellen, Kuratierungs- und Filterprozessen. Kritische Perspektiven auf Repräsentationsprobleme, Copyright-Fragen und Umweltkosten der Datenspeicherung.\nTraining: Technische Aspekte des Trainingsprozesses und Auswahl von Hyperparametern. Kritische Betrachtung der Umweltauswirkungen, Arbeitsbedingungen in der KI-Industrie und Machtkonzentration bei ressourcenstarken Unternehmen.\nAnwendung: Analyse verschiedener Anwendungsfälle von ML-Systemen, Feinabstimmung für spezifische Aufgaben und Bereitstellungsstrategien. Kritische Diskussion ethischer Überlegungen, potenzieller Missbrauchsszenarien und Fragen der Transparenz und Erklärbarkeit.\nEvaluation und Überwachung: Methoden zur Bewertung von Modellleistung und Verzerrungen. Kritische Perspektiven auf die Grenzen aktueller Evaluierungsmetriken.\nGovernance und Regulierung: Diskussion aktueller und vorgeschlagener Regulierungsrahmen, ethischer Richtlinien und Herausforderungen bei der Steuerung sich schnell entwickelnder KI-Technologien.\n\n\n\n\nThis paper by Fabian Offert and Ranjodh Singh Dhaliwal critiques existing methodological tendencies in Critical AI Studies, arguing that the field lacks a cohesive methodology. The authors identify three primary forms of casuistry—problematic tendencies in critique—that hinder more rigorous analysis:\n\nBenchmark Casuistry: Overreliance on individual test cases (e.g., “AI got this prompt wrong, therefore AI is flawed”), which leads to shallow critiques that do not account for the probabilistic nature of machine-learning models.\nBlack Box Casuistry: The assumption that AI models are entirely opaque, reinforcing a misleading notion that they cannot be understood or analyzed meaningfully. The authors argue that AI models are historically and incrementally developed, making them more interpretable than critics often acknowledge.\nStack Casuistry: The outdated assumption that AI systems function as deterministic stacks (a linear sequence of computational steps), when in reality, contemporary models rely on pipelines, A/B testing, and evolving probabilistic structures.\n\nThe authors advocate for a shift in methodology: instead of critiquing AI as if it were a static and deterministic system, scholars should engage with the probabilistic and historically layered nature of AI models. They call for an interdisciplinary approach, integrating computational insights with humanities-driven critique.\n\n\n\nBelow is a step-by-step “recipe”—in the form of guiding questions—to help you decide which machine-learning architecture might best suit your project. The idea is to systematically walk through key considerations: the data, the nature of the task, resource constraints, and more.\n\n\n\nImages or video → Look at Convolutional Neural Networks (CNNs), possibly Vision Transformers.\nText, language, or other sequential data → Consider Recurrent Neural Networks (RNNs, LSTM, GRU) or Transformers.\nTabular (rows/columns) or numeric → Often tree-based methods (Random Forest, XGBoost) or simpler neural networks.\nGraph-structured data → Investigate Graph Neural Networks (GNNs).\nMixed or multimodal data (e.g., text + images) → Transformers with multimodal extensions or custom architectures.\n\n\n\n\n\nPlenty of labeled data → Deep learning is a strong contender; you can train large neural networks.\nVery limited labeled data →\n\nLook at simpler models (logistic regression, smaller neural nets, or SVMs).\nConsider transfer learning (using a pretrained model as a starting point).\nTry data augmentation or few-shot learning approaches.\n\nMixed (some labeled, a lot unlabeled) → Consider semi-supervised or self-supervised methods.\n\n\n\n\n\nClassification or regression (predicting categories/numbers) → Common with feedforward networks or ensembles (Random Forest, XGBoost).\nSequence prediction/analysis (e.g., forecasting time series, analyzing text) → RNNs, LSTMs/GRUs, or Transformers.\nGenerating new content (images, text, synthetic data) → Generative Adversarial Networks (GANs), Variational Autoencoders, or Transformers for text generation.\nDetecting anomalies → Autoencoders or one-class SVMs are often used.\n\n\n\n\n\nStrong interpretability needed (healthcare, finance, or regulated sectors) → Simpler models (decision trees, linear models), or advanced methods but with extra interpretability techniques (e.g., SHAP, LIME).\nAccuracy/performance is priority → Larger neural networks, ensembles. But remember that black-box models can raise ethical or compliance issues.\n\n\n\n\n\nHardware availability: Do you have access to powerful GPUs/TPUs?\nBudget: Training large models can be expensive in terms of cloud compute and electricity.\nTime: If you need results quickly, large-scale training might be impractical; you could opt for smaller or pretrained models.\n\n\n\n\n\nReal-time/low-latency → You might need optimized or compressed models (pruning, quantization).\nEdge devices (smartphones, IoT) → Smaller architectures or specialized hardware accelerators.\nBatch processing (run offline) → Larger, more complex models are fine if you can afford the compute time.\n\n\n\n\n\nHigh-stakes decisions (criminal justice, hiring, healthcare) → Consider simpler or more transparent models, robust fairness checks, or specialized frameworks to reduce bias.\nLarge-scale public deployments → Must address potential bias in data and architecture. Tools exist (e.g., fairness libraries) to test and mitigate discriminatory outcomes.\n\n\n\n\n\nFrequent new data → Consider models that can be retrained or fine-tuned incrementally (e.g., Transfer Learning, partial retraining of large models).\nStable environment (data or requirements don’t change much) → A one-shot large training might be enough, with occasional updates.\n\n\n\n\n\nDimensionality reduction or unsupervised representation → Autoencoders can learn compact representations, useful for anomaly detection or data visualization.\nGenerating synthetic data → GANs or Diffusion Models can create additional training samples or handle data-privacy constraints.\n\n\n\n\n\nStart with a baseline model (e.g., a simple logistic regression or small Random Forest) to see if you can meet your basic performance goal.\nIncrementally add complexity: If you need more accuracy, consider deeper or more specialized networks.\nEvaluate each approach using consistent metrics (accuracy, F1 score, or mean squared error), plus interpretability, training time, cost, and potential bias.\n\n\n\n\nHere’s a rough cheat-sheet matching common data/tasks to suggested architectures:\n\n\n\n\n\n\n\nData/Task\nRecommended Approach\n\n\n\n\nTabular (structured)\nRandom Forest, XGBoost, or smaller MLP (feedforward net)\n\n\nImages\nCNNs (ResNet, etc.), Vision Transformers\n\n\nText or Language\nTransformers (BERT, GPT), or older RNNs/LSTMs/GRUs\n\n\nTime Series\nRNN/LSTM/GRU or 1D-CNN, Transformers\n\n\nGraph Data\nGraph Neural Networks (GNNs)\n\n\nGenerating Images/Text\nGANs, Diffusion Models, or Transformer-based generators\n\n\nAnomaly Detection\nAutoencoders, one-class SVM\n\n\n\n\n\n\nAnswering these 10 questions should narrow down your options. The best practice is to prototype a couple of models, run real tests, and pick the one that strikes the best balance between accuracy, interpretability, efficiency, cost, and ethical considerations.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 2"
    ]
  },
  {
    "objectID": "contents/sessions/02.html#recap-session-1",
    "href": "contents/sessions/02.html#recap-session-1",
    "title": "Session 2",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 2"
    ]
  },
  {
    "objectID": "contents/sessions/02.html#überblick-ml-lebenszyklus",
    "href": "contents/sessions/02.html#überblick-ml-lebenszyklus",
    "title": "Session 2",
    "section": "",
    "text": "Der ML-Lebenszyklus:\n\nArchitekturauswahl: Diskussion verschiedener ML-Architekturen und ihrer Auswirkungen auf Modellkapazitäten und -grenzen. Kritische Betrachtung, wie architektonische Entscheidungen bestimmte Voreingenommenheiten einbetten können.\nDatensammlung: Untersuchung von Datenquellen, Kuratierungs- und Filterprozessen. Kritische Perspektiven auf Repräsentationsprobleme, Copyright-Fragen und Umweltkosten der Datenspeicherung.\nTraining: Technische Aspekte des Trainingsprozesses und Auswahl von Hyperparametern. Kritische Betrachtung der Umweltauswirkungen, Arbeitsbedingungen in der KI-Industrie und Machtkonzentration bei ressourcenstarken Unternehmen.\nAnwendung: Analyse verschiedener Anwendungsfälle von ML-Systemen, Feinabstimmung für spezifische Aufgaben und Bereitstellungsstrategien. Kritische Diskussion ethischer Überlegungen, potenzieller Missbrauchsszenarien und Fragen der Transparenz und Erklärbarkeit.\nEvaluation und Überwachung: Methoden zur Bewertung von Modellleistung und Verzerrungen. Kritische Perspektiven auf die Grenzen aktueller Evaluierungsmetriken.\nGovernance und Regulierung: Diskussion aktueller und vorgeschlagener Regulierungsrahmen, ethischer Richtlinien und Herausforderungen bei der Steuerung sich schnell entwickelnder KI-Technologien.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 2"
    ]
  },
  {
    "objectID": "contents/sessions/02.html#leseauftrag-the-method-of-critical-ai-studies-a-propaedeutic",
    "href": "contents/sessions/02.html#leseauftrag-the-method-of-critical-ai-studies-a-propaedeutic",
    "title": "Session 2",
    "section": "",
    "text": "This paper by Fabian Offert and Ranjodh Singh Dhaliwal critiques existing methodological tendencies in Critical AI Studies, arguing that the field lacks a cohesive methodology. The authors identify three primary forms of casuistry—problematic tendencies in critique—that hinder more rigorous analysis:\n\nBenchmark Casuistry: Overreliance on individual test cases (e.g., “AI got this prompt wrong, therefore AI is flawed”), which leads to shallow critiques that do not account for the probabilistic nature of machine-learning models.\nBlack Box Casuistry: The assumption that AI models are entirely opaque, reinforcing a misleading notion that they cannot be understood or analyzed meaningfully. The authors argue that AI models are historically and incrementally developed, making them more interpretable than critics often acknowledge.\nStack Casuistry: The outdated assumption that AI systems function as deterministic stacks (a linear sequence of computational steps), when in reality, contemporary models rely on pipelines, A/B testing, and evolving probabilistic structures.\n\nThe authors advocate for a shift in methodology: instead of critiquing AI as if it were a static and deterministic system, scholars should engage with the probabilistic and historically layered nature of AI models. They call for an interdisciplinary approach, integrating computational insights with humanities-driven critique.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 2"
    ]
  },
  {
    "objectID": "contents/sessions/02.html#typische-entscheidungen-bei-der-architekturwahl",
    "href": "contents/sessions/02.html#typische-entscheidungen-bei-der-architekturwahl",
    "title": "Session 2",
    "section": "",
    "text": "Below is a step-by-step “recipe”—in the form of guiding questions—to help you decide which machine-learning architecture might best suit your project. The idea is to systematically walk through key considerations: the data, the nature of the task, resource constraints, and more.\n\n\n\nImages or video → Look at Convolutional Neural Networks (CNNs), possibly Vision Transformers.\nText, language, or other sequential data → Consider Recurrent Neural Networks (RNNs, LSTM, GRU) or Transformers.\nTabular (rows/columns) or numeric → Often tree-based methods (Random Forest, XGBoost) or simpler neural networks.\nGraph-structured data → Investigate Graph Neural Networks (GNNs).\nMixed or multimodal data (e.g., text + images) → Transformers with multimodal extensions or custom architectures.\n\n\n\n\n\nPlenty of labeled data → Deep learning is a strong contender; you can train large neural networks.\nVery limited labeled data →\n\nLook at simpler models (logistic regression, smaller neural nets, or SVMs).\nConsider transfer learning (using a pretrained model as a starting point).\nTry data augmentation or few-shot learning approaches.\n\nMixed (some labeled, a lot unlabeled) → Consider semi-supervised or self-supervised methods.\n\n\n\n\n\nClassification or regression (predicting categories/numbers) → Common with feedforward networks or ensembles (Random Forest, XGBoost).\nSequence prediction/analysis (e.g., forecasting time series, analyzing text) → RNNs, LSTMs/GRUs, or Transformers.\nGenerating new content (images, text, synthetic data) → Generative Adversarial Networks (GANs), Variational Autoencoders, or Transformers for text generation.\nDetecting anomalies → Autoencoders or one-class SVMs are often used.\n\n\n\n\n\nStrong interpretability needed (healthcare, finance, or regulated sectors) → Simpler models (decision trees, linear models), or advanced methods but with extra interpretability techniques (e.g., SHAP, LIME).\nAccuracy/performance is priority → Larger neural networks, ensembles. But remember that black-box models can raise ethical or compliance issues.\n\n\n\n\n\nHardware availability: Do you have access to powerful GPUs/TPUs?\nBudget: Training large models can be expensive in terms of cloud compute and electricity.\nTime: If you need results quickly, large-scale training might be impractical; you could opt for smaller or pretrained models.\n\n\n\n\n\nReal-time/low-latency → You might need optimized or compressed models (pruning, quantization).\nEdge devices (smartphones, IoT) → Smaller architectures or specialized hardware accelerators.\nBatch processing (run offline) → Larger, more complex models are fine if you can afford the compute time.\n\n\n\n\n\nHigh-stakes decisions (criminal justice, hiring, healthcare) → Consider simpler or more transparent models, robust fairness checks, or specialized frameworks to reduce bias.\nLarge-scale public deployments → Must address potential bias in data and architecture. Tools exist (e.g., fairness libraries) to test and mitigate discriminatory outcomes.\n\n\n\n\n\nFrequent new data → Consider models that can be retrained or fine-tuned incrementally (e.g., Transfer Learning, partial retraining of large models).\nStable environment (data or requirements don’t change much) → A one-shot large training might be enough, with occasional updates.\n\n\n\n\n\nDimensionality reduction or unsupervised representation → Autoencoders can learn compact representations, useful for anomaly detection or data visualization.\nGenerating synthetic data → GANs or Diffusion Models can create additional training samples or handle data-privacy constraints.\n\n\n\n\n\nStart with a baseline model (e.g., a simple logistic regression or small Random Forest) to see if you can meet your basic performance goal.\nIncrementally add complexity: If you need more accuracy, consider deeper or more specialized networks.\nEvaluate each approach using consistent metrics (accuracy, F1 score, or mean squared error), plus interpretability, training time, cost, and potential bias.\n\n\n\n\nHere’s a rough cheat-sheet matching common data/tasks to suggested architectures:\n\n\n\n\n\n\n\nData/Task\nRecommended Approach\n\n\n\n\nTabular (structured)\nRandom Forest, XGBoost, or smaller MLP (feedforward net)\n\n\nImages\nCNNs (ResNet, etc.), Vision Transformers\n\n\nText or Language\nTransformers (BERT, GPT), or older RNNs/LSTMs/GRUs\n\n\nTime Series\nRNN/LSTM/GRU or 1D-CNN, Transformers\n\n\nGraph Data\nGraph Neural Networks (GNNs)\n\n\nGenerating Images/Text\nGANs, Diffusion Models, or Transformer-based generators\n\n\nAnomaly Detection\nAutoencoders, one-class SVM\n\n\n\n\n\n\nAnswering these 10 questions should narrow down your options. The best practice is to prototype a couple of models, run real tests, and pick the one that strikes the best balance between accuracy, interpretability, efficiency, cost, and ethical considerations.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 2"
    ]
  },
  {
    "objectID": "contents/home.html",
    "href": "contents/home.html",
    "title": "Decoding Inequality: Kritische Perspektiven auf Machine Learning und gesellschaftliche Ungleichheit",
    "section": "",
    "text": "Die kritische Auseinandersetzung mit Machine-Learning-Systemen und ihren gesellschaftlichen Auswirkungen ist in der heutigen Zeit von höchster Relevanz. Während KI-Technologien zunehmend Einzug in alle Bereiche unseres Lebens halten - von der Gesundheitsversorgung über die Strafverfolgung bis hin zu Finanzdienstleistungen und sozialen Medien - wächst auch ihr Potenzial, bestehende soziale Ungleichheiten zu verstärken oder sogar neue zu schaffen. Die Fähigkeit, diese Systeme zu verstehen, ihre Auswirkungen auf bereits minorisierte Gesellschaftsgruppen kritisch zu hinterfragen und Lösungen für eine gerechtere Gestaltung zu entwickeln, ist entscheidend für eine ethisch verantwortungsvolle und sozial gerechte technologische Zukunft. Dieses Kolloquium befähigt Studierende, aktiv an dieser wichtigen gesellschaftlichen Debatte teilzunehmen und trägt zur Entwicklung von KI-Systemen bei, die das Gemeinwohl fördern und nicht untergraben.\nIn diesem Kolloquium untersuchen die Studierenden den gesamten Lebenszyklus von Machine-Learning-Systemen und dessen Auswirkungen auf gesellschaftliche Ungleichheit. Der Kurs beleuchtet, wie bewusste und unbewusste menschliche Verzerrungen und Vorurteile in jeder Phase des ML-Lebenszyklus eingebettet werden können und wie diese zu Diskriminierung in verschiedenen gesellschaftlichen Kontexten führen.\nAufbauend auf den theoretischen Grundlagen der Critical Algorithm Studies lernen die Studierenden, die ethischen, politischen, ökologischen und ökonomischen Implikationen von ML-Technologien zu analysieren. Der Kurs ist entlang des ML-Lebenszyklus strukturiert:\n\nArchitekturauswahl: Diskussion verschiedener ML-Architekturen und ihrer Auswirkungen auf Modellkapazitäten und -grenzen. Kritische Betrachtung, wie architektonische Entscheidungen bestimmte Voreingenommenheiten einbetten können.\n\nDatensammlung: Untersuchung von Datenquellen, Kuratierungs- und Filterprozessen. Kritische Perspektiven auf Repräsentationsprobleme, Copyright-Fragen und Umweltkosten der Datenspeicherung.\n\nTraining: Technische Aspekte des Trainingsprozesses und Auswahl von Hyperparametern. Kritische Betrachtung der Umweltauswirkungen, Arbeitsbedingungen in der KI-Industrie und Machtkonzentration bei ressourcenstarken Unternehmen.\n\nAnwendung: Analyse verschiedener Anwendungsfälle von ML-Systemen, Feinabstimmung für spezifische Aufgaben und Bereitstellungsstrategien. Kritische Diskussion ethischer Überlegungen, potenzieller Missbrauchsszenarien und Fragen der Transparenz und Erklärbarkeit.\n\nEvaluation und Überwachung: Methoden zur Bewertung von Modellleistung und Verzerrungen. Kritische Perspektiven auf die Grenzen aktueller Evaluierungsmetriken.\n\nGovernance und Regulierung: Diskussion aktueller und vorgeschlagener Regulierungsrahmen, ethischer Richtlinien und Herausforderungen bei der Steuerung sich schnell entwickelnder KI-Technologien.\n\nDurchgehend wird betont, dass die Entwicklung und der Einsatz von ML-Systemen auch als Geschäftsmodell zu verstehen sind. Die Studierenden lernen, die kommerziellen Interessen und wirtschaftlichen Auswirkungen zu analysieren, die die Gestaltung und den Einsatz dieser Technologien beeinflussen.\nDer Kurs kombiniert theoretische Reflexion mit praktischen Übungen. Die Studierenden werden sowohl mit den theoretischen (nicht-mathematischen) Grundlagen des maschinellen Lernens vertraut gemacht als auch in die Lage versetzt, kritische Analysen auf Basis aktueller Forschungsergebnisse durchzuführen und die implikationen für minorisierte Bevölkerungsgruppen von KI in der Gesellschaft zu verstehen. Praktische Beispiele, Fallstudien und Diskussionen aktueller Forschungsarbeiten werden regelmässig in die Lehrveranstaltung integriert, um die Verbindung zwischen technologischen Entwicklungen und ihren gesellschaftlichen Auswirkungen zu verdeutlichen.\nNach Abschluss des Kurses sind die Studierenden in der Lage:\n\nDen gesamten Lebenszyklus von Machine-Learning-Systemen zu verstehen und kritisch zu reflektieren\n\nDie Auswirkungen von Entscheidungen in jeder Phase des ML-Lebenszyklus auf potenzielle Verzerrungen und Diskriminierungen zu analysieren\n\nFormen der algorithmischen Diskriminierung in verschiedenen Anwendungskontexten zu identifizieren und zu analysieren\n\nDie ethischen, gesellschaftlichen und wirtschaftlichen Implikationen von ML-Anwendungen zu bewerten\n\nDie Rolle kommerzieller Interessen und Geschäftsmodelle in der Entwicklung und dem Einsatz von ML-Systemen zu verstehen\n\nLösungsstrategien für eine gerechtere und ethischere Gestaltung algorithmischer Systeme zu entwickeln\n\nEine produktiv-kritische Haltung im Umgang mit KI und ML einzunehmen, die technische, ethische und ökonomische Aspekte berücksichtigt\n\nAktuelle Regulierungsansätze und Governance-Herausforderungen im Bereich KI und ML zu diskutieren und zu bewerten\n\n\n\nUniversität Bern\nWalter Benjamin Kolleg / Digital Humanities\nMuesmattstrasse 45\n3012 Bern",
    "crumbs": [
      "Kursbeschreibung"
    ]
  },
  {
    "objectID": "contents/home.html#impressum",
    "href": "contents/home.html#impressum",
    "title": "Decoding Inequality: Kritische Perspektiven auf Machine Learning und gesellschaftliche Ungleichheit",
    "section": "",
    "text": "Universität Bern\nWalter Benjamin Kolleg / Digital Humanities\nMuesmattstrasse 45\n3012 Bern",
    "crumbs": [
      "Kursbeschreibung"
    ]
  },
  {
    "objectID": "contents/posts/20250521-Umwelt_Gerechtigkeit_Rafael_Klöpper.html",
    "href": "contents/posts/20250521-Umwelt_Gerechtigkeit_Rafael_Klöpper.html",
    "title": "Saubere und gerechte KI?",
    "section": "",
    "text": "1. Einleitung\nKünstliche Intelligenz (KI) und ihre Anwendungsmöglichkeiten sind für viele von uns bereits zum Alltag geworden. So erreichte der Chatbot ChatGPT mit dem Start einer verbesserten Version Ende 2022 nach zwei Monaten, mit über 100 Millionen Nutzer:innen, ein für eine Internetanwendung noch nicht erreichtes Nachfragewachstum (Milmo, 2023). Gleichzeitig steigt damit auch die wirtschaftliche Bedeutung. So wird sich der Marktumfang von 184 Milliarden US Dollar auf prognostizierte 826 Milliarden US Dollar 2030 mehr als vervierfachen (Statista, 2024a). Mit dieser Bedeutung sehe ich in Umweltthemen ein sehr wichtiges Forschungsgebiet. Jedoch interessierte sich die Wissenschaft bisher vor allem für die positive Seite. Der Fokus liegt hier zum Beispiel auf Verbesserungen des Klimaschutzes (Gaur et al., 2023). Aimee van Wynsberghes (2021, S. 217) Ausführungen machen uns den konkreten Gegenstand klar. Dazu schlägt sie eine Unterscheidung in zwei Bereiche vor: Einerseits KI für Nachhaltigkeit (AI for Sustainability). KI sind hier Werkzeuge, die helfen den Klimawandel zu kontrollieren und die Folgen abzuschwächen. Andererseits spielt die Nachhaltigkeit von KI (Sustainability of AI) eine sehr wichtige Rolle.\nLeider hat sich das Interesse daran in Grenzen gehalten. Das zeigt sich im Studienangebot, das relativ überschaubar ist. Jedoch trägt der breite Einsatz von KI erheblich zum Klimawandel bei. Daneben müssen weitere Problematiken beachtet werden, wie der Ressourcenverbrauch (Gaur et al., 2023, S. 1f.). In diesem Blog soll die Auseinandersetzung mit dieser negativen Seite eine zentrale Rolle spielen.\nEine gute Einführung bietet die Studie von Emily M. Bender et al. (2021, S. 612f.) an, die bereits 2021 die negativen Folgen für Mensch und Umwelt aufgriff. Dabei gehen nicht nur die negativen Effekte für das Klima hervor, sondern es offenbart sich auch die ungleiche Verteilung von Risiken und Nutzen.\nDas ist von grosser Bedeutung, da die Menschheit durch die steigende globale Erwärmung und dem Klimawandel grossen Veränderungen gegenübersteht. Das belegen die häufiger werdenden katastrophischen Naturereignisse. Unsere Transportbedürfnisse, Energieverbrauch und Konsum führen zur Freisetzung grosser Mengen an Treibhausgasen. Das Klima heizt sich auf (Sharma und Kumar De, 2024, S. XI). Wir befinden uns damit in der dritten Welle der KI-Ethik, in deren Mittelpunkt Umweltauswirkungen und Themen der Nachhaltigkeit stehen (Van Wynsberghe, 2021, S. 214).\nMeine These folgt dieser Problematik: Die Entwicklung und Nutzung von KI-Systemen verursachen einen erheblichen Ressourcenverbrauch und hohe Treibhausgasemissionen. Dadurch verstärken sich soziale Ungleichheiten, da Vorteile vor allem privilegierten Gruppen zugutekommen. Dafür treffen Umweltbelastungen überwiegend benachteiligte Gesellschaftsgruppen. Politische Regulierungen sind notwendig, um eine gerechtere Verteilung von Kosten und Nutzen sicherstellen. Im ersten Teil gehe ich auf den hohen Ressourceneinsatz sowie den Beitrag am Klimawandel ein. Im zweiten Teil thematisiere ich die ungerechte Verteilung von Nutzen und Kosten. Abschliessend gebe ich einen Ausblick auf mögliche Lösungsansätze und Regulationen.\n\n\n2. Folgen für Umwelt und Klima\nFür einen Überblick über die Auswirkungen auf die Umwelt bietet sich das Life Cycle Assessment (LCA) an, das eine breite Anwendung auf verschiedene Sektoren ermöglicht. Es ist ein Hilfsmittel, um die verschiedenen Stufen von der Extraktion der Rohmaterialien, über die Produktion und den Einsatz bis zur Entsorgung zu erfassen (Verghese et al., 2009, S. 9 & S. 18). Folgende Grafik illustriert die Anwendung eines LCAs im Zusammenhang mit KI-Anwendungen:\n\n\n\nAbbildung 1: LCA von KI über die Lebensdauer. Quelle: Eigene Darstellung orientiert an Luccioni et al., 2023, S. 4.\n\n\nWelche Hindernisse müssen hier beachtet werden? Nicht ganz einfach in diesem Zyklus zu bestimmen sind die Treibhausgasemissionen durch die Infrastruktur. Das trifft auf das Training und den späteren Einsatz der Modelle zu. Eine Hilfestellung bietet die systematische Auseinandersetzung mit der grossen Bandbreite an Modellen und den dazugehörenden Algorithmen. So fressen gerade die von immer mehr Menschen genutzten Large Language Models (LLMs) grosse Mengen an Ressourcen. Die Komplexität steigt durch ein zunehmendes Grössenwachstum, das in der Regel einen höheren Ressourcenverbrauch mit sich bringt (Luccioni et al., 2023, S. 1-3). Selbst die Anbieter sind ein Problem. Es mangelt an Transparenz entlang der gesamten Wertschöpfungskette. Zum Beispiel fehlen konkrete Informationen der Hardwareproduzenten. Dasselbe Dilemma offenbart sich bei den nachgelagerten Schritten, wie den Auswirkungen auf die Umwelt durch die spezifischen Architekturen. Schätzungen und Experimente sind unerlässlich (Luccioni et al., 2024b, S. 86 & S. 94).\nRessourcenverbrauch\nEine zentrale Feststellung muss zu Beginn festgehalten werden: Die KI-Branche benötigt immer mehr Rechenleistung (Compute). Diese Entwicklung belegt einen Bericht von OpenAI, der den Leistungsbedarf von grossen KI-Modellen in historischer Perspektive darstellt. In der Periode von 1959 bis weit in das 21. Jahrhundert konnte ein Rhythmus von zwei Jahren für die Verdopplung der Rechenleistung festgestellt werden. Dagegen lag diese in der Periode von 2012 bis 2018 nur noch bei durchschnittlichen 3.4 Monaten (Amodei & Hernandez, 2018). Das hat enorme Auswirkungen auf die Infrastruktur. Die weltweite Anzahl von Hyperscale-Datenzentren stieg innerhalb eines Zeitraumes von zwei Jahren von 700 auf 992 im Jahr 2023 an (Statista, 2024b).\nDie Bedeutung der Hardwareseite zeigt sich auch in den geopolitischen Überlegungen vieler Länder. In der strategischen Industriepolitik nimmt diese Branche eine zentrale Rolle ein. Halbleiterhersteller wie TSMC, der Prozessorhersteller Nvidia und ASML als Lieferant von Lithographie-Systemen für die Chipproduktion wurden zu wirtschaftlichen Superstars gekürt (Vipra und Myers West, 2023). Damit kommt dem Ressourcenverbrauch, der bereits hoch ist und sich in Zukunft nochmals steigern wird, eine wichtige Rolle zu. Der beschleunigte Abbau von Rohstoffen für die leistungsfähigere Hardware ist eine gravierende Folge davon. Damit wird der Bedarf für Speicherkapazität grösser. Das Halbmetall Silicium ist ein so wichtiger Rohstoff, sodass die Nachfrage bald das Angebot übersteigen könnte (Acocella, 2024, S. 58). Da gerade für generative KI-Systeme grosse Mengen an Rohstoffen benötigt werden, zeigt sich mit einem Blick auf die für LLMs genutzte Nvidia Blackwell-Plattform. Ein einzelnes Rack (DGX GB200 NVL72) mit einem Leistungsbedarf von bis zu 120 kW wiegt bereits 1.36 Tonnen. Dieses enthält 72 Grafikprozessoren (GPU), 36 Prozessoren (CPU), 9 Switches zur Verbindung der GPUs und ein Kühlmodul. Zudem werden 3.2 Kilometer an Kupferverkabelung benötigt. Und das ist nur ein einzelner Rack (Wang et al., 2024. S. 818; Continuum Labs, 2023; Supermicro, 2025)! Neben den in den Medien heiss diskutierten seltenen Erden, werden weitere kritische Mineralien benötigt. Und beim Blick auf unsere stetig leistungsfähigere Stromversorgung muss klar werden: Auch hier werden mehr Ressourcen konsumiert (Kemplay, 2025).\nEin weiterer kritischer Aspekt liegt im Wasserverbrauch. Trotz seiner Relevanz für die Gesamtnachhaltigkeit spielte dieser bisher kaum eine Rolle in der Wissenschaft. Die Ressource Wasser ist dabei ein wesentlicher Bestandteil in der Klimabilanz. Gerade im Zusammenhang mit in vielen Weltregionen zunehmenden langanhaltenden Dürreperioden zeigt sich dieser Aspekt als besonders kritisch (Islam et al., 2018, S. 734).\nDazu gehört erstens der direkte Kühlwasserbedarf für die Datenzentren (Scope 1). Dieser kann bis zu 9 Liter Wasser pro verbrauchte Kilowattstunde (kWh) an heissen Orten wie Arizona betragen. Insbesondere liegt das an Anlagen mit Verdunstungskühlung, die bei hohen Temperaturen über 30 Grad eingesetzt werden. Zweitens muss der ausgelagerte Bedarf durch Elektrizitätskraftwerke berücksichtigt werden (Scope 2). Meta berichtete 2023 für ihre Datenzentren einen Wert von 3.7 Liter pro erzeugter kWh Strom. Drittens fällt der Wasserkonsum durch die Serverproduktion an (Scope 3). So benötigt die Wafer-Produktion hochreines Kühlwasser. Diese Abwässer können mit toxischen Produkten kontaminiert sein, die in vielen Fällen ungenügend gereinigt werden. Damit werden enorme Mengen an Wasser verbraucht. So verwendete alleine das Training des Modells GPT-3 von OpenAI, das in den amerikanischen Datenzentren von Microsoft vollzogen wurde, nach Berechnungen über 5.4 Millionen Liter Wasser. Wovon alleine 700’000 Liter nur für die Kühlung anfielen. Im Betrieb nutzt das Modell durchschnittlich einen halben Liter für den Umfang von 10 bis 50 Antworten mittlerer Länge, wobei sich Standort und Zeitpunkt darauf auswirken (P. Li et al., 2023, S. 2-4).\nEnergieverbrauch, CO2-Ausstoss und Klimawandel\nUm das Gesamtbild zu vervollständigen, muss neben dem Ressourcenverbrauch ebenso die Emission von Treibhausgasen beleuchtet werden. Erst eine Studie von Forschenden an der University of Massachusetts Amherst machte diesen Zusammenhang einer grösseren Öffentlichkeit bekannt (Dhar, 2020, S. 423). Im Fokus dieser Pionierstudie von Emma Strubell et al. (2019, S. 2-4) stand der Energieverbrauch und die damit verbundenen Kosten für das Training von Natural Language Processing (NLP) Modellen. Dazu wurden die Modelle wie Transformer und GPT-2 untersucht. In dieser Trainingsphase wurde der Stromverbrauch von den GPUs und CPUs erfasst. Jedes Modell wurde maximal für einen Tag trainiert. Diese Daten wurden hochgerechnet für die geschätzte Gesamtdauer des Trainings und der Energieverbrauch mit dem durchschnittlichen CO2-Fussabdruck des Strommixes der Vereinigten Staaten multipliziert. Im Ergebnis offenbaren sich grosse Unterschiede zwischen den Modellen in den CO2e-Emissionen. Diese Angabe in CO2-Äquivalente beinhaltet neben Kohlendioxid verschiedene Treibhausgase, wie Methan. Diese werden entsprechend ihrer Klimawirkung umgerechnet. Was war nun wichtig? Eine unterschiedlich lange Trainingsdauer, die notwendige Hardware und deren Leistungsaufnahme spielten eine wesentliche Rolle. Gerade die langen Trainingszeiträume von Wochen bis zu Monaten bedeuten grosse Stromverbräuche und damit Umweltkosten. In der folgenden Abbildung wird deutlich, was ein ineffizientes Modell für unser Klima bedeutet:\n\n\n\nAbbildung 2: CO2-Äquivalente verschiedener Tätigkeiten. Quelle: Eigene Darstellung mit Daten Strubell et al., 2019.\n\n\nDer Trend zu generativen KI-Modellen hat gravierende Auswirkungen. Gerade die erste Phase für die Entwicklung solcher Modelle durch das Training umfangreicher neuronaler Netzwerke und der Verarbeitung enormer Datenmengen ist sehr rechenintensiv. Eine steigende Komplexität durch eine höhere Quantität an Parametern kann zu einem exponentiellen Verbrauchswachstum führen (Dua & Patel, 2024, S. 35f.). Das Training ist aber nur ein Teil des Gesamtbildes (Dhar, 2020, S. 423). Auch im laufenden Betrieb verbrauchen Hochleistungsrechenzentren signifikante Mengen an Elektrizität. Im Vergleich zu Bürogebäuden bedeutet das im auf die Fläche bezogenen Stromkonsum ein zehn- bis fünfzigfach höherer Bedarf (Dua & Patel, 2024, S. 34).\nDie Erhebung ist insbesondere durch die grosse Bandbreite an Anwendungen kein leichtes Unterfangen. Die untere Grafik demonstriert diese eindrücklich. Die Balken geben den durchschnittlichen Stromkonsum für 1000 Eingaben in Bezug auf verschiedene Aufgabengebiete wieder. Dafür wurden von der Plattform Hugging Face verschiedene Opensource-Modelle gewählt. Ersichtlich ist eine enorme Spreizung (Luccioni et al., 2024a):\n\n\n\nAbbildung 3: Durchschnittlicher Energieverbrauch in Wattstunden (Wh) nach Aufgabe. Quelle: Eigene Darstellung mit Vorlage Luccioni et al., 2024a.\n\n\nDamit wird eine breite Betrachtung in der CO2-Bilanz interessant, die neben Training auch die Hardwareproduktion und den späteren Einsatz untersucht. Das konnte Alexandra Sasha Luccioni et al. (2023) mit einer Studie erstmals nachvollziehen. Leider tauchten auch dort Lücken auf. Die Klimafolgen durch Abbau und Prozessierung der Rohstoffe sowie die anschliessende Entsorgung konnte wegen fehlender Daten nicht durchgeführt werden. Die Forschenden griffen auf das BLOOM-Modell zurück, welches über 176 Milliarden Parameter umfasst. Das Training benötigte mit rund 433’196 kWh bei über 118 Tagen Trainingszeit enorme Strommengen. Trotz dieser Zahlen ergab sich bei relativ klimafreundlichen 57 g CO2e/kWh des französischen Strommixes nur 24.69 Tonnen CO2e. Zusätzlich fällt ein Leerlaufverbrauch an, wie zum Beispiel durch Netzteilverluste, den wir auch von warmen Netzteilen unserer Computer kennen. Dieser betrug nochmals 256’646 kWh und 14,6 Tonnen CO2e. Besonders spannend ist der CO2e-Fussabdruck aus der Produktion der benötigten Server und den darin enthaltenen GPUs, wo die Studie eine Vorbildfunktion einnimmt. Dieser summierte sich auf 11,2 Tonnen. Im Anschluss wurde das Modell mit Hilfe der Google Cloud Plattform und 16 Nvidia A100 GPUs in Betrieb genommen sowie der Energieverbrauch für einen Testzeitraum von 18 Tagen evaluiert. Hierbei erfolgten stündlich rund 558 Anfragen. Bescheidene 914 kWh wurden verbraucht, die sich aber durch den klimaunfreundlichen US-Strommix von 394 g während des Tests auf 340 kg CO2e summierten. Studien schätzen diesen Schritt der Inferenz aber höchst unterschiedlich ein. Gerade der Vergleich von Bloom mit den Daten aus anderen Studien legen diese Differenzen offen. Insbesondere die Zusammensetzung des Strommixes und der Energieverbrauch sind relevante Grössen (Luccioni et al., 2023, S. 2-10). In Zukunft muss neben dem Training der Inferenz Aufmerksamkeit geschenkt werden. Schnellere Veröffentlichungszyklen und eine intensivere Nutzung machen das notwendig. Dazu trägt aber auch unsere intensivere Nutzung von Heimelektronik bei (Varoquaux et al., 2024, S. 6).\nMit diesen Informationen stellt sich die Frage, welchen Beitrag KI am Klimawandel verursacht. Leider ist eine genaue Feststellung wegen Datenlücken und der Intransparenz der Anbieter bisher nicht möglich. Der Energieverbrauch konkreter Applikationen, wie LLMs bleibt uns aktuell im Verborgenen (Berreby, 2024). Zudem verkomplizieren zahlreiche Parameter eine genauere Bestimmung. Neben dem konkreten Standort beeinflusst auch die Wahl des Cloudanbieters den jeweiligen Fussabdruck. Ein Beispiel führt uns das vor: Amazon-AWS weist nur einen erneuerbaren Energien Anteil von 17% aus. Dagegen steht Google mit 56% deutlich besser dar. So verschlechtert die Nutzung von Kohlekraftwerken diese Umweltbilanz in grossem Ausmass (Strubell et al., 2019, S. 2).\nAnnäherungen über andere Messgrössen sind damit der beste Weg. So geht die Internationale Energieagentur (IEA) von einem steigenden Stromkonsum durch Rechenzentren aus. Dieser wird sich mit 1000 Terrawattstunden (TWh) im Jahr 2026 gegenüber 460 TWh im Jahr 2022 mehr als verdoppeln. Viele Regionen werden damit enorme Verbrauchssteigerungen erleben. Zum Vergleich: Das entspricht dem Verbrauch von ganz Japan, einem Industriegiganten. Leider wird nicht nach konkreter Anwendung unterschieden. Damit bleiben uns die einzelnen Beiträge von KI und Kryptowährungen im Unklaren (IEA, 2024, S. 8). KI besteht auch nicht nur aus Servern und Rechenzentren. Zur Infrastruktur gehören auch unsere persönlichen Geräte. Spannende Daten für diesen Beitrag an den weltweiten CO2-Emissionen liefert ein gemeinsamer Bericht der Weltbank und der Internationalen Fernmeldeunion (ITU). Der prozentuale Anteil der Information and Communication Technology (ICT) Emissionen betrug 2021 1.7%. Am Gesamtstromverbrauch ergab das einen Anteil von 4.7%. Auch hier ist keine genauere Unterscheidung möglich. Darunter fallen unter anderem Smartphones, Datenzentren und Kommunikationsnetzwerke (Ayers et al., 2024, S. 2 & S. 24).\nDiese relativ unbedeutenden Zahlen können einen falschen Eindruck vermitteln. Gerade im Vergleich zu anderen Emittenten, wie dem Verkehrssektor stellt sich dieser gering dar. Jedoch bestätigt ein Blick auf historische Daten im Bereich der Datenzentren hohe Wachstumsraten im Stromverbrauch. Diese Infrastruktur muss eine kontinuierlich steigende Nachfrage durch uns Nutzende abdecken. Jährliche Zunahmen lagen bisher bei nicht unerheblichen 20% bis 40%. Im Zeitraum von 2017 bis 2021 erfolgte bei den wichtigsten Cloudanbietern Amazon, Microsoft, Google und Meta sogar eine Verbrauchsverdopplung (IEA, 2023). Eine wichtige Ursache dafür sind unsere Ansprüche an die Performanz. So verdoppelte sich der Stromverbrauch im Falle Deutschlands im Zeitraum von 2010 bis 2021 besonders durch die IT-Komponenten. Wenigstens wuchs der Verbrauch für Kühlung und Notstromversorgung nicht im gleichen Tempo. Die Gesamteffizienz der Infrastruktur konnte gesteigert werden (vgl. Power Usage Effectiveness - PUE Wert). Für die Zukunft zeichnet sich trotz dieser Lichtblicke ein düsteres Bild mit einem weiteren exponentiellen Wachstum ab (Hintemann & Hinterholzer, 2022, S. 2f.). Alarmierend zeigt sich besonders die zunehmende Nutzung von KI für generative Aufgaben. Die Generierung grafischer Inhalte verbraucht viel Strom. Mit der Verbreitung umfangreicherer Modelle, die eine grosse Bandbreite an Funktionen erfüllen, wird dieser Anspruch weiter ansteigen. Zudem sollte den Nutzer:innen bewusst sein, dass diese bei der Lösung gleicher Aufgaben gegenüber spezifischen Modellen weniger effizient sind (Luccioni et al., 2024b, S. 93f.).\nEs lässt sich eines aber sicher feststellen: Die erforderliche Rechenleistung hat sich über die letzten Jahrzehnte deutlich erhöht. Wachsende und leistungsfähigere Modelle sind für diese Entwicklung eine wichtige Ursache (Varoquaux et al., 2024, S. 2). Folgende Grafik führt diesen Sachverhalt vor. Die erforderlichen FLOPS (Floating Point Operations Per Second - Messgrösse für Performanz) im Training steigen mit jedem Modell. Grok-3 von Elon Musks xAI steht an einsamer Spitze:\n\n\n\nAbbildung 4: Verschiedene Modelle und ihre Rechenleistung im Training. Quelle: EPOCH AI, 2025.\n\n\nDiese Entwicklungen haben enorme Auswirkungen auf die Nachhaltigkeitsziele der beteiligten Firmen. Zum Beispiel verfolgt Google trotz dem angestrebten Ziel einer Klimaneutralität ab 2030 seit 2023 im operativen Bereich keine notwendigen Kompensationsmassnahmen. Priorität haben marktwirtschaftliche und technologische Ziele (Kerr, 2024).\nUnd was häufig vergessen geht, sind indirekte Effekte. Diese digitalen Technologien können in der Öl-, Kohle- und Erdgasförderung eine effizientere Produktion schaffen und damit Kostensenkungen herbeiführen. Fossile Energien werden günstiger. Das kann wiederum die Nachfrage stimulieren. Berechnungen von McKinsey gehen von einem jährlichen Wertzuwachs in der Öl- und Gasindustrie von 200 Milliarden Dollar nur durch den Einsatz von Deep Learning Technologien aus. Im Bergbau können beispielsweise intelligente Minen Einsparungen erzielen. Weitere Steigerungen in der Produktion mit allen negativen Konsequenzen werden dadurch erst möglich (Dauvergne, 2020, S. 136 & S. 139). Es sollte nun klar sein, welche Bedeutung KI-Systeme auf die Umwelt und Klimawandel haben. Die Verbreitung wird die Nachfrage nach Energie weiter erhöhen. Das leistet einen wichtigen Beitrag zur Beschleunigung der globalen Erwärmung (J. L. Li et al., 2024, S. 369f.).\n\n\n3. Ungerechte Verteilung von Nutzen und Kosten\nUmweltrassismus/Umweltdiskriminierung\nIn diesem Kapitel zeige ich den Zusammenhang zwischen Umweltbelastung und Ungleichheitsstrukturen. Eine wichtige Verbindung besteht zum Umweltrassismus und zur Umweltdiskriminierung. Der Soziologie Robert D. Bullard erarbeitete eine kompakte Definition:\n«Environmental racism refers to any policy, practice or directive that differentially affects or disadvantages (whether intended or unintended) individuals, groups, or communities based on race or color.» (Bullard, 1994, S. 1037).\nDie Bewegung für Umweltgerechtigkeit in den 1970er und 1980er Jahre in den USA machte das Problem einer grösseren Öffentlichkeit bekannt. Ein Schlüsselereignis war 1982 der Konflikt über eine Deponie für kontaminierte Erde im Ort Afton. Dort lebten rund zwei Drittel Afroamerikaner:innen. Daraus entwickelten sich grosse Widerstände, die auch die nationale Ebene erreichten (Affolderbach & Schulz, 2024, S. 115-117). Diese Vorgänge mündeten im Begriff «Umweltrassismus», der 1987 durch den Bericht «Toxic Wastes and Race in the United States» der United Church of Christ aufgegriffen wurde. Statistische Auswertungen lieferten den Beweis: Deponien für Gefahrenstoffe waren disproportional häufig an Orten angesiedelt, die vorwiegend von hispanischen und afroamerikanischen Personen bewohnt wurden (Affolderbach & Schulz, 2024, S. 116; United Church of Christ, 1987, S. 15). Damit wurde ein Problemkomplex erstmals wissenschaftlich untersucht, der bis zum heutigen Tage erhebliche Folgen für marginalisierte Gruppen aufweist. Es ist aber nicht nur das Benachteiligungsmerkmal Race betroffen, sondern auch weitere intersektionale Dimensionen, wie Einkommen oder Herkunft. Damit sind nicht nur die People of Color, sondern ebenfalls ärmere gesellschaftliche Schichten betroffen. Krebserkrankungen und Lungenkrankheiten treten dort viel häufiger auf. Wohnorte mit schlechten Lebensbedingungen sind hierfür eine Ursache (Moisi, 2020, S. 229f.). Damit muss es auch als Umweltdiskriminierung betrachtet werden. Das Phänomen betrifft verschiedene geographische Räume. Neben innerstaatlichen Auseinandersetzungen muss es als globale Problematik verstanden werden (Ituen und Hey, 2021, S. 5-9).\nCancer Alley\nWo lassen sich solche Strukturen finden? Ein prominentes Beispiel für fehlende Umweltgerechtigkeit im Globalen Norden besteht in einem Korridor mit dem Namen Cancer Alley. Dieser erstreckt sich entlang des Flusses Mississippi und reicht von Baton Rouge bis New Orleans. Intensive industrielle Tätigkeiten, wie petrochemische Anlagen und Erdölraffinerien, prägen dieses Gebiet. Diese emittieren gefährliche krebserregende Stoffe in die Umwelt. Das Gebiet wird überwiegend von einer armen afroamerikanischen Bevölkerung bewohnt. Durch die Verschmutzungen sind diese verhältnismässig stark von den Auswirkungen betroffen. Krankheiten, wie Krebs treten im Vergleich zu anderen Regionen deutlich häufiger auf (Connolly et al., 2009: 150f.). Die nachfolgende Grafik zeigt diesen Zusammenhang eindrücklich auf. Das Krebsrisiko (linke Karte) ist für die Gebiete mit einem hohen Anteil an schwarzer Bevölkerung (rechte Karte) deutlich erhöht:\n\n\n\nAbbildung 5: Krebsrisiko Bundesstaat Louisiana links und Anteil schwarze Bevölkerung an der Population rechts, Quelle: Terrell & St. Julien, 2022, S. 4f.\n\n\nDamit verkörpert dieser Fall gemäss Menschenrechtsexpert:innen der United Nations (UN) Umweltrassismus. Ich finde daran besonders die historische Kontinuität interessant. Es herrscht eine lange Tradition in der Benachteiligung dieser Bevölkerungsgruppe. Denn diese Gebiete waren früher Plantagen und viele Betroffene direkte Nachfahren versklavter Menschen (UN, 2021).\nElektroschrott und der Beitrag ausrangierter KI-Hardware\nAus unserem Alltag sollte uns eigentlich auch die globale Dimension der Problematik klar werden. Sie zeigt sich besonders in der Handhabung ausrangierter elektronischer und elektrischer Güter. Sie werden in grossen Mengen in arme Länder des Globalen Südens exportiert. Regulationsversuche hatten bisher keinen Erfolg. Besonders afrikanische Nationen sind in formeller und informeller Hinsicht wichtige Ziele. Wesentliche Treiber bilden unsere hohe Konsumnachfrage und rapide Entwicklungszyklen mit schneller Obsoleszenz. Verbunden sind diese Probleme mit geringen Rückführungsquoten in das eigene Recyclingsystem. Der Export ist durch Freihandelsregelungen häufig günstiger als die Verwertung in wohlhabenden Staaten. Dabei ist nicht der eigentliche Import schädlich. Häufig besteht die Absicht einer Weiternutzung. Davon sind aber grosse Teile nicht mehr verwendbar. Erst ab diesem Punkt fangen die Risiken für Umwelt und Gesundheit an. Denn der Elektroschrott trifft auf ein in weiten Teilen unterentwickeltes Recycling (Bimir, 2020, S. 659f. & S. 666f.). So importiert Ghana grosse Mengen an ausrangierten elektrischen und elektronischen Gerätschaften aus Europa und den USA, wovon rund 40% unbrauchbar sind. Solche Mengen können lokal nicht verarbeitet werden. Diese Entsorgungsaufgaben werden auf informellen Müllhalden durch Kinder und Frauen erledigt. Für diese armutsbetroffenen Schichten stellt es häufig die einzige Einkommensmöglichkeit dar. Dabei bestehen erhebliche Gefahren. Um an die gewünschten Wertstoffe, wie Gold oder Kupfer zu gelangen, werden Kunststoffgehäuse angezündet. Dabei entstehen krebserregende Dioxine und Feinstäube. Zudem sind giftige Schwermetalle, wie Blei ein wichtiger Bestandteil in Elektronikbauteilen. Die Folgen sind kontaminiertes Grundwasser und Böden. Elektroschrott ist damit einer der bedeutendsten Ursachen für Umweltverschmutzung in Afrika (Andeobu et al., 2023, S. 5 & S. 9f.). Für diese Menschen hat es erhebliche Auswirkungen auf die Gesundheit. Wirtschaftliche Not zwingt dennoch zur weiteren Suche, Extraktion und Verkauf der darin enthaltenen wertvollen Stoffe (Moisi, 2020, S. 228). Die jährlich anfallenden Mengen an Elektroschrott werden dabei grösser. Noch 2010 betrug die Menge 34 Millionen Tonnen. Bereits 2022 wurden 62 Millionen Tonnen produziert und diese Menge könnte 2030 auf 82 Millionen Tonnen ansteigen (Baldé et al., 2024: S. 26-28 & S. 30). Mit einer globalen Recyclingquote unter 20% kommt nur ein Bruchteil in den Kreislauf zurück. Obschon sich diese Zahlen nach Weltregion unterscheiden. In Europa beträgt die Quote 42.5%, in Asien 11.7% und in Afrika nur 0.9% (Chauhan et al., 2025, S. 34).\nEs stellt sich die Frage, inwiefern der Ausbau von KI diese Problematik verschlimmern wird. Die Studie von Peng Wang et al. (2024: S. 819f.) versuchte richtweisend diesen Beitrag zu quantifizieren. Dabei konzentrierten sie sich auf die Server mit den enthaltenen GPUs und CPUs, die für generative KI und LLMs wichtig sind. Unterstützende Anlageteile, wie das Kühlequipment wurde nicht betrachtet. Für diese Abschätzung legte das Forschungsteam vier Szenarien für die Zukunft vor. Diese reichen von einer limitierten Nutzung bis zu einem aggressiven Szenario. Die untere Grafik verdeutlicht die kumulativen Mengen aus dem Prognosezeitraum 2020 bis 2030 in Zusammenhang mit den verschiedenen LLM-Anwendungsprognosen:\n\n\n\nAbbildung 6: Prognostizierte Mengen an Elektroschrott nach vier Szenarien. Quelle: Eigene Darstellung mit Daten Wang et al., 2024.\n\n\nWas werden wir zukünftig erleben? Die Menge wird sich von 2’600 Tonnen im Jahr 2023 auf 0.4 bis 2.5 Millionen Tonnen für das Jahr 2030 enorm erhöhen. In iPhone-Äquivalenten würde das 2.1 bis 13.3 Milliarden Geräte bedeuten. Kumulativ bringt das in diesem Zeitraum ein Gesamtgewicht zwischen 1.2 bis 5 Millionen Tonnen. Die Entsorgungsmengen durch Informations- und Kommunikationstechnik sind in diesem Zeitraum noch deutlich grösser. Auf Grund einer starken Konzentration an bestimmten Standorten, fallen diese global ungleichmässig verteilt an. In Nordamerika werden 58%, in Ostasien 25% und in Europa 14% des ausrangierten Materials anfallen (Wang et al., 2024, S. 820). Diese zunehmenden Mengen sind aber besonders wegen toxischer Inhaltsstoffe problematisch (Dua und Patel, 2024, S. 34). Insbesondere die Leiterplatten weisen hohe Anteile an toxischen Stoffen auf. Eine ungenügende Verbrennung dieser Komponenten kann auch hier gesundheitsgefährdende Dioxine und Furane freisetzen (Kolias et al., 2014, S. 1480 & S. 1486).\nUngleicher Nutzen: Internet, Sprache und soziodemografische Merkmale\nIm folgenden Teil beleuchte ich die ungleiche Verteilung von Nutzen und Kosten, die durch die Umweltbelastungen in Folge von KI entstehen.\nUmweltrassismus und Umweltdiskriminierung sind gute Anknüpfungspunkte, um diese Ungerechtigkeiten offen zu legen. Die zentrale Frage lautet: Wer leidet und wer profitiert? Besonders Bevölkerungen des Globalen Südens sind von dieser negativen Seite betroffen, die schon durch den Kolonialismus Leid erfahren mussten. Sie werden durch die wirtschaftliche Entwicklung und den enormen Konsum des Globalen Nordens enorm belastet. Aber selbst in wohlhabenden Nationen treffen wir auf grosse Ungerechtigkeiten. (Ituen & Hey, 2021, S. 12). Spannend in diesem Zusammenhang ist das von Ulrich Brand und Markus Wissen beschriebene Konzept der Imperialen Lebensweise. Um was geht es hier konkret? Der Alltag privilegierter Menschen wird durch die kapitalistische Ausbeutung auf Kosten marginalisierter Gesellschaften und Gruppen möglich. Ihre Arbeitskraft wird ohne Rücksicht ausgebeutet. Dazu offenbart sich eine schrankenlose Förderung von Naturressourcen. Die Beziehungen sind daher in der wirtschaftlichen, sozialen und ökologischen Sphäre von grosser Asymmetrie gekennzeichnet. Zentrale Voraussetzungen dafür liegen im ungenügenden Schutz von Natur und Mensch sowie im Bestehen einseitiger Machtverhältnisse (Brand & Wissen, 2024, S. 43f. & S. 51). Dieses Konzept ist besonders interessant, da diese Bedingungen auch eine Voraussetzung für die Ungleichheiten in der digitalen Welt bilden.\nUm zurück auf die Thematik KI zu kommen, stellt sich zuerst die Frage: Welche Menschen können diese Systeme überhaupt nutzen? Insbesondere der Digital Divide im Rahmen einer kritischen Ethik sollte Beachtung geschenkt werden. Dieser weist auf das Problem hin, dass ungleiche Zugangsmöglichkeiten bei diesen neuen Technologien bestehen. Für ausgewählte Personenkreise sind diese zugreifbar und lassen sich effektiv im Alltag einbinden. Dagegen fehlt den ausgeschlossenen Gruppen diese Möglichkeit. Relevant dafür sind aber nicht nur die Ressourcen, sondern auch das Wissen um deren Anwendung (Moghaddam & Cao, 2024, S. 432).\nEin Internetzugang, für die meisten Menschen in wohlhabenden Nationen eine Selbstverständlichkeit, ist ein wichtiger Faktor. Im Optimalfall sollte dieser zudem eine hohe Bandbreite bieten. Gerade stabile Verbindungen schaffen die Basis für die effektive Einführung von KI in wirtschaftliche Aktivitäten und bilden eine Grundlage für eine digitalisierte Wirtschaft. Eine solche Infrastruktur muss nicht unbedingt auf Kupfer- oder Glaskabel zurückgreifen. Besonders die schnellerwerdenden Funktechnologien bieten hierfür Alternativen. Jedoch haben in Afrika immer noch grosse Teile der ländlichen Bevölkerung nur Zugriff auf ein langsames 2G-Netz, was ein zentrales Hindernis für die breite Anwendung ist (Mengesha et al., 2024, S. 92). Eine Ursache liegt in der auf die Kaufkraft bezogenen teuren Breitbandinternetangebote und in der notwendigen Kommunikationsinfrastruktur. Denn diese konzentriert sich vor allem auf die Ballungsgebiete. Darüber hinaus existieren aber selbst bei der lokalen Bevölkerung häufig Wissenslücken durch fehlende Bildungsangebote, die zu einer geringeren Internetnutzung führen (Aikins, 2019, S. 73-75).\nSo lassen sich erhebliche Unterschiede in den Nutzungsquoten des Internets über die verschiedenen Weltregionen feststellen. In Afrika waren es 2024 gemäss Bericht der ITU nur 38% der Bevölkerung. Mit 91% lag die Quote in Europa deutlich höher. In der Betrachtung des jeweiligen ökonomischen Status zeigen sich erhebliche Diskrepanzen. In Nationen mit tiefen Einkommen waren es nur 27%. Dagegen liegt die Quote beim Internetzugang in Ländern mit hohen Einkommen bei 93% (ITU, 2024, S. 2):\n\n\n\nAbbildung 7: Anteile Internetnutzung 2024 nach Einkommen der Staaten. Quelle: Eigene Darstellung mit Daten ITU, 2024, S. 2.\n\n\nDieser eingeschränkte Zugang für Menschen aus ärmeren Ländern ist daher ein wesentliches Nutzungshindernis. Zudem leidet das Anwendungserlebnis bei einer Offline-Anwendung. So werden die KI-Fähigkeiten bei mangelnder Konnektivität durch geringere Interaktionsmöglichkeiten und fehlender Echtzeitverarbeitung erheblich beschnitten. Dabei spielen die Übertragungsmöglichkeiten des Internets eine zentrale Rolle (Ansah et al., 2024, S. 112). Gerade grosse Datenmengen als Big Data sind ein elementarer Bestandteil in der Innovationsfähigkeit dieser Systeme. So mangelt es zum Beispiel in Afrika nicht nur an der Quantität, sondern auch an der Qualität. Selbst, wenn diese in Bereichen, wie im Finanz- und Telekommunikationssektor durchaus vorhanden sein können, existieren diese für die meisten Bereiche des Alltags nicht (Mengesha et al., 2024, S. 92). Damit verbunden ist die Schwerpunktsetzung in der Entwicklung der Modelle auf nur wenige Sprachen. Die Bedürfnisse marginalisierter Gemeinschaften spielen nur eine untergeordnete Rolle (Bender et al., 2021, S. 612f.). Ein wichtiges Beispiel ist hierfür das NLP für die Verarbeitung und das Verstehen menschlicher Sprachen. Die englische Sprache bildet für viele KI-Modelle der Benchmark. Besonders hier existieren umfangreiche Datensätze. Zugleich spielt Englisch eine dominierende Rolle in der Forschung, Entwicklung und dem späteren Einsatz. Damit eröffnet sich ein Bias, der Schwierigkeiten auf der linguistischen und kulturellen Ebene mit sich bringt (Singh, 2025, S. 104f.). Diese Entwicklung zementiert bestehende sprachliche Hierarchien. Das Weltgeschehen dominierende Sprachen, die häufig aus Europa stammen, werden so in ihrer Reichweite verstärkt. Dagegen werden Menschen aus anderen Sprachräumen auf diese Weise marginalisiert. Die Interaktion kann dadurch für signifikante Teile der Weltbevölkerung verkompliziert oder sogar verunmöglicht werden (Tasa-Fuster, 2025, S. 49). Damit sind ärmere Weltregionen im Training und in der Weiterentwicklung von KI-Modellen unterrepräsentiert. Gleichzeitig bleiben so grosse Teile der Weltbevölkerung die Vorteile daraus verwehrt. Konsequenzen sind eine gehemmte wirtschaftliche Entwicklung. Das führt zur Erhaltung bestehender und zur Etablierung neuer Ungleichheiten (Ansah et al., 2024, S. 112).\nYan Liu und He Wang (2024) konnten diese Unterschiede in der Nutzung mit ihrer Studie belegen. Dazu fokussierten sie sich mit ChatGPT auf generative KI. So liegen hochentwickelte Nationen in der Nutzungsintensität in Relation zu den Internetnutzenden weit vorne. Dennoch konnten besonders Länder mit mittleren Einkommen in der Anwendung dieser Technologien wichtige Fortschritte erzielen. Das demonstrieren viele Länder Südamerikas:\n\n\n\nAbbildung 8: Monatliches Nutzeraufkommen im März 2024 bei ChatGPT in Relation zu der Anzahl Internetnutzenden. Quelle: Liu & Wang, 2024, S. 28.\n\n\nJedoch existieren selbst in Industrienationen grosse Ungleichheiten. Die Studie von Mariano Méndez-Suárez et al. (2023, S. 5) untersuchte den Einfluss soziodemografischer Faktoren auf die Akzeptanz von KI und Robotik. Die Ergebnisse zeigen, dass jüngere Menschen und Männer tendenziell positiver gegenüber diesen Technologien eingestellt sind. Diese Unterschiede werden jedoch durch den sozio-ökonomischen Status moderiert: Personen aus der Arbeiterschicht sind kritischer, während Männer aus der oberen Mittelschicht eine besonders positive Haltung dazu einnehmen. Die Autor:innen diskutieren als möglichen Erklärungsansatz den Zusammenhang zwischen höherem sozio-ökonomischem Status, höherem Bildungsgrad und grösserer Offenheit gegenüber Innovationen. Ein niedriger beruflicher Qualifikationsgrad korrespondiert hingegen oft mit einer kritischeren Haltung gegenüber technologischen Veränderungen.\nDiese Einstellungen können erhebliche Auswirkungen auf die tatsächliche Nutzung haben – insbesondere dann, wenn nur bestimmte Bevölkerungsgruppen Zugang haben oder Vertrauen in diese Technologien entwickeln. Anwender:innen von Chatbots besitzen im Vergleich zu Internutzenden bessere Bildungsgrade. So lässt sich eine Korrelation mit den beruflichen Hintergründen feststellen. Menschen mit höherer Qualifikation benötigen diese Systeme für ihre privilegierten Bürotätigkeiten (Liu & Wang, 2024, S. 19).\nUngleiche Kosten: Klimawandel und Vulnerabilität\nIn der Betrachtung von Umweltfolgen durch eine breite Implementation von KI verändert sich die Situation: Insbesondere ärmere Staaten sind von den Folgen betroffen. Die negativen Auswirkungen des Klimawandels und die damit verbundenen klimatischen Veränderungen treffen Länder in ungleichem Ausmass (J. L. Li et al., 2024, S. 369f.).\nDemografische Faktoren, wie zum Beispiel die Mortalität, geben Aufschluss über diese ungerechte Entwicklung. Der Klimawandel mit seinen Veränderungen wirkt sich auf den Globalen Süden stärker als auf den Globalen Norden aus. Das wird auch nicht durch Steigerungen im Einkommen und einer besseren Anpassung an die neuen Verhältnisse kompensiert. Insbesondere steigende Temperaturen sind dafür eine Ursache. So werden im ghanaischen Accra 100 zusätzliche Tage mit über 32 Grad im Jahr 2100 prognostiziert, sofern ein Weiterso-Szenario RCP8.5 eintrifft. Das führt zu einer höheren Mortalität (Carleton et al, 2022, S. 2068). Die folgende Weltkarte verdeutlicht diese Differenzen. Es lässt sich eine ungleiche Verteilung der regionalen Mortalität in Folge von katastrophischen Ereignissen durch Klimawandel feststellen. Südlich gelegene Gebiete weisen ein höheres Risiko auf:\n\n\n\nAbbildung 9: Mortalität pro Ereignis 2010 bis 2019 bei Naturkatastrophen durch Klimawandel (Überflutungen, Sturm und Trockenheiten). Quelle: Birkmann et al., 2022a, S. 10.\n\n\nDie in Zukunft in ihrer Frequenz und Intensität weiter zunehmenden klimatischen Extremereignisse werden also besonders für den Globalen Süden verheerend sein. Das liegt einerseits an der südlichen Lage auf dem Globus. Andererseits sind die lokalen Lebensverhältnisse wenig vorteilhaft angesichts dieser Bedrohung. In Entwicklungsländern sind vergleichsweise grosse Anteile der Bevölkerung im landwirtschaftlichen Sektor tätig. Es besteht eine hohe Wahrscheinlichkeit für Ernteausfälle und gesundheitliche Risiken durch Arbeiten unter freiem Himmel. Hitzewellen führen zu grossen körperlichen Belastungen und können Tätigkeiten in diesem Bereich sogar verunmöglichen. Zudem fehlt es diesen Staaten an den Fähigkeiten, um diesen neuen Herausforderungen wirkungsvoll entgegenzutreten. Dagegen kann der Globale Norden sich durch seine finanzielle Ausstattung besser anpassen. Es kann sogar vorteilhaft sein! Steigende Temperaturen können auch wirtschaftliche Impulse liefern. Damit öffnet sich die Wohlstandsschere zwischen Nord und Süd noch weiter (Soukharev, 2024, S. 325-329).\nExtreme Hitzeperioden mit Trockenzeiten und intensivere Unwetter wirken sich zwar auf den gesamten Globus aus. Jedoch spüren wirtschaftlich benachteiligte Personen die Folgen mit einer höheren Intensität. Zentrale Faktoren sind hierfür eine grössere Vulnerabilität in Kombination mit einer gesteigerten Exposition, die die Anfälligkeit für die Folgen des Klimawandels ansteigen lässt. Dieser Fakt trifft aber nicht nur auf weniger entwickelte Staaten und Schwellenländern zu, sondern auch auf einkommensschwache Gruppen in wohlhabenden Weltregionen. Zudem kann sich hier auch ein Kreislauf etablieren: Der Klimawandel führt zu mehr Armut, was wiederum den Kreis vulnerabler Menschen erweitert. Damit wird die Ungleichheit nicht nur international vergrössert, sondern auch innerhalb von Staaten (Mordeson & Mathew, 2024, S. 220).\nFolgende Grafik illustriert diese Verbindungen. Die Vulnerabilität nimmt eine zentrale Position ein. Armut und Ungleichheit beeinflussen als Faktoren im Wesentlichen diese Entwicklung und werden wiederum von der Vulnerabilität determiniert. Der Klimawandel und sozioökonomische Grundlagen wirken auf diese Wechselwirkungen ein:\n\n\n\nAbbildung 10: Zusammenhang Vulnerabilität. Quelle: Eigene Darstellung orientiert an Birkmann et al., 2022b, S. 1177.\n\n\nDamit sind nicht nur Regionen, sondern auch Individuen durch fehlende Resilienz gefährdet. Darüber hinaus besteht sogar ein intersektionaler Zusammenhang mit anderen Benachteiligungskategorien. Marginalisierung und Ungleichheit verstärken die eigene Vulnerabilität. Geschlecht, Alter oder sozialer Status haben einen erheblichen Einfluss darauf (Intergovernmental Panel on Climate Change IPCC, 2023, S. 31). So weisen Frauen durch die Diskriminierungsstrukturen in vielen Gesellschaften weltweit höhere Armutsquoten auf. Das führt zu geringeren Ressourcen, sich gegen die Auswirkungen des Klimawandels zu behaupten. Zudem schränkt sich durch eine untergeordnete soziale Rolle der persönliche Handlungsrahmen ein. Veränderungen in den klimatischen Verhältnissen werden daher am heftigsten von bereits marginalisierten Gruppen und Armutsbetroffenen erlebt. Diesen fehlt es darüber hinaus auch an erforderlichen Mitteln, sich ausreichend gegen die Folgen zu schützen. Zudem mangelt es an Einfluss auf der politischen Ebene, um Schutzmassnahmen durchzusetzen (Demetriades und Esplen, 2010, S. 133f.). Daher ist auch im Globalen Norden das individuelle Risiko nicht gerecht verteilt. Der persönliche CO2-Fussabdruck wächst mit höherem Einkommen. Jedoch sind von Diskriminierung betroffener Menschen in tieferen Gehaltsklassen überrepräsentiert und tragen daher weniger zum Klimawandel bei. Sie müssen aber gleichzeitig höhere Kosten mittragen (Ituen und Hey, 2021, S. 12). Das geht häufig bei Extremereignissen völlig vergessen. So haben zum Beispiel Waldbrände nicht nur eine ökologische Komponente, sondern auch eine soziale. Die Vulnerabilität durch diese Events stellt sich in den USA nach Ethnie höchst unterschiedlich dar. Indigene, schwarze und hispanische Gemeinschaften sind deutlich verletzlicher. Sie leben in Gemeinden, die nicht angemessen darauf reagieren können. Im Kontrast dazu besitzt die weisse Bevölkerung leistungsfähigere Adaptionsstrategien. Ihre Wohnorte sind beispielsweise besser für diese Bedrohungen vorbereitet. Eine zentrale Ursache liegt hierfür in sozioökonomischen Problemen (Davies et al., 2018, S. 6-11).\nUngleiche Kosten: Ressourcen\nNeben den Folgen des Klimawandels spielt auch der bereits beschriebene Ressourcenverbrauch eine wichtige Rolle in der Betrachtung einer ungleichen Verteilung von Risiken. Gerade im Bergbau wird diese Problematik offensichtlich. Gesundheitliche Probleme bei Bergleuten und Anwohner:innen in wenig entwickelten Staaten sind neben sozialen Folgen zentrale Aspekte in dieser Betrachtung. Eine fehlende Kostenwahrheit macht diesen Sektor besonders lukrativ. Der Ausbau der notwendigen KI-Infrastruktur und der dafür erforderlichen Hardware setzt die Extraktion grosser Mengen an Rohstoffen voraus. Dieser Punkt bleibt im Fokus auf Software und Algorithmen häufig ein unbeachteter Punkt. Jede technische Komponente basiert auf natürlichen Elementen, die die Erde in Milliarden von Jahren bildete. Das gesamte System von KI beansprucht natürliche Ressourcen, die global in einer Vielzahl von Orten gefördert werden. Zentrale Probleme ergeben sich bei vielen Elementen, wie den seltenen Erden. China deckt 95% der Nachfrage dafür ab. Diese Marktdominanz liegt aber nicht an besonders reichhaltigen Lagerstätten, sondern an der staatlichen Akzeptanz von Umweltschäden durch den Bergbau. Es entstehen bei der Extraktion hochtoxische Abfallstoffe. Landschaften mit Seen bestehend aus Säureabfällen prägen die Abbaugebiete. Intransparente und komplexe Lieferketten machen die Evaluation konkreter Probleme aber schwierig. So verfügt alleine der Prozessorhersteller Intel über die gesamte Lieferkette etwa 16’000 Lieferanten aus 100 unterschiedlichen Ländern (Crawford, 2021, S. 26-37).\nDamit führt die Rohstoffgewinnung zu erheblichen Belastungen für ganze Landstriche. Leider nehmen wir das in unserer privilegierten Position kaum wahr. Eine kontinuierliche Externalisierung der Kosten macht es für den Produzenten wirtschaftlich attraktiv und für uns Nachfragende günstig. Folgen, wie kontaminierte Gewässer durch seltene Erden, Luftverschmutzung durch die Gold- und Nickelförderung sowie Gesundheitsschäden der Beschäftigten werden nicht eingepreist. Übermässig werden diese Lasten wiederum auf bereits marginalisierte Gruppen abgewälzt (Perzanowski, 2022, S. 36). Beispielhaft dafür steht der Kupferabbau in Chile. Das Land ist einer der wichtigsten Produzenten für dieses in der Elektronik unverzichtbare Metall. Ein wichtiges Produktionsmittel ist Wasser. Jedoch befinden sich die Lagerstätten in Wüstengebieten. Entsprechend ist Wasser ein knappes Gut. Damit öffnet sich ein Interessensgegensatz zu den dort lebenden indigenen Gruppen, wie den Aymara. Denn die Landwirtschaft stellt eine Haupteinnahmequelle dar und ist auf die permanente Wasserzufuhr angewiesen. Die chilenischen Behörden schenkten dem Anspruch auf ein Wasserkontingent bisher aber keine Beachtung. Damit wird die Lebensgrundlage zerstört und der einzige Ausweg bleibt häufig die Landflucht in urbane Räume (Bryan, 2012, S. 100f.).\nDaneben spielt Wasser nicht nur in der Rohstoffextraktion eine Rolle, sondern ist wie bereits erwähnt, für die Funktion relevanter Systemkomponenten unverzichtbar. Der Verbrauch von Millionen Litern an Trinkwasser birgt ein enormes Konfliktpotenzial. In vielen Gebieten herrschen durch die Folgen des Klimawandels ein Wassermangel (P. Li et al., 2023, S. 1f.). Branchenriesen wie Google, Microsoft und Amazon nehmen bei der Errichtung ihrer Datenzentren bisher wenig Rücksicht auf die lokale Bevölkerung. Weltweit werden diese auch in sehr trockenen Gebieten aufgebaut. Insbesondere das geringe Risiko von Korrosion durch die trockene Luft überwiegt in der Interessensevaluation dieser Firmen. Eine bereits an Wasserknappheit leidende Bevölkerung stellt kein Hindernis dar. Somit wird diese Infrastruktur das Problem weiter verschärfen (Barratt & Gambarini, 2025).\nMachtkonzentration durch KI\nAbschliessend gehe ich in diesem Kapitel noch kurz auf eine zentrale Ursache ein, die es Unternehmen in der KI-Branche ohne grosse Hindernisse ermöglicht, ihre wenig rücksichtsvollen Pläne zu realisieren. Wichtig für diese Ungerechtigkeiten sind Zentralisierungsprozesse, die sich um KI entwickeln. Eine Asymmetrie in den Machtverhältnissen erlaubt es einflussreichen Unternehmen, ungeachtet der Auswirkungen auf die Bevölkerung, die eigenen Vorstellungen durchzusetzen. Jedoch profitieren nicht alle davon. Diese Vorteile gehen zu Lasten vieler Menschen, die erhebliche Einschränkungen ertragen müssen (Olson et al., 2024). Bei einem Blick auf die Vergangenheit offenbart sich, dass gerade digitale Innovationen nicht zu einer Streuung von Einfluss und Partizipation beitrugen, sondern zu Monopolisierungen. Daraus entstanden unter anderem führende Technologiefirmen (Weltbank, 2024, S. 95f.). Vorwiegend befinden sich diese Unternehmen in den USA und China. Seit 2015 intensivierte sich der Wettbewerb um KI. Dazu gehörte der Aufkauf zahlreicher Startups und der Aufbau wichtiger Infrastrukturen dafür. Diese Konzentration hat gravierende Auswirkungen. Neben einer Kontrolle über technologische Standards, wird das auch erhebliche Wirkungen auf die politischen Rahmenbedingungen haben. Damit legen wenige Unternehmen weichenstellende Entwicklungen fest (Verdegem, 2023, S. 305-307). Diese Einseitigkeit widerspiegelt sich auch im Global AI Power Ranking der Stanford University. Die Forschenden evaluierten mit 42 Indikatoren die Position einzelner Nationen in ihren Fähigkeiten im Bereich KI. Dazu gehören unter anderem Faktoren, wie der Anteil von KI in den wirtschaftlichen Leistungen und der verfügbaren KI-Infrastruktur. Hierbei liegt die USA vor dem zweitplatzierten China. Auf den nachfolgenden Plätzen sind aber nur wohlhabende Staaten, wie Grossbritannien oder einflussreiche Schwellenländer, wie Indien vertreten (Stanford University, 2024).\nDie Einseitigkeit hat für alle Nutzenden Auswirkungen. Multinationale Akteure können mit ihren Plattformen und umfangreichen Ökosystemen als Gatekeeper funktionieren und damit ihre Marktdominanz ausnutzen (Birch & Bronson, 2022, S. 10). Das wird sich auch in Zukunft nicht ändern. Die oben beschriebenen steigenden Ansprüche an die Rechenleistung sind eine wesentliche Ursache, da grosse Investitionen erforderlich sind. Besonders Technologiekonzerne besitzen hierfür die Mittel. Selbst akademische Einrichtungen und Startups können hier den Anschluss verlieren. So kostet bereits ein einzelner Nvidia GPU-Chip H100 fast 40’000 Dollar. Ein Zugang wird dadurch erheblich erschwert. Somit bleibt für das Training und den späteren Einsatz nur die Beanspruchung eines spezialisierten Clouddienstleisters als einziger Weg übrig (Varoquaux et al., 2024, S. 8). Auch beim steigenden Strombedarf müssen diese unterschiedlichen Einflussmöglichkeiten berücksichtigt werden. Die steigenden Ansprüche können nur mit dem Ausbau der Kraftwerksressourcen und der elektrischen Netze begegnet werden. Nach Zahlen von Goldman Sachs werden alleine in den USA rund 50 Milliarden Dollar an Investitionen in Stromerzeugungskapazitäten für die Abdeckung der steigenden Nachfrage benötigt. Durch eine ältere Netzinfrastruktur werden in Europa sogar 800 Milliarden Euro für die Übertragungsnetze innerhalb des nächsten Jahrzehnts notwendig (Goldman Sachs, 2024). Es ist hierbei fraglich, ob die KI-Anbieter sich fair an diesen Investitionen beteiligen werden. Wahrscheinlicher wird die Umlage zu Lasten der anderen Stromkonsument:innen, der öffentlichen Hand und der Steuerzahlenden gehen. Damit müssen die Kosten von KI nicht nur auf ihre Umwelteffekte betrachteten werden, sondern von einem Standpunkt höchst ungleicher Beziehungen.\nDas belegt eine Befragung von Führungskräften durch die Strategieberatung Deloitte. Trotz einer weitverbreiteten optimistischen Haltung über die Möglichkeiten generativer KI für ihr Unternehmen, zeigte sich im Bereich sozialer Folgen ein anderes Bild. Über die Hälfte befürchtet eine Machtzentralisierung in der Weltwirtschaft und ebenso eine Zunahme ökonomischer Ungleichheit. Das wird begleitet von einer Sorge über ein weiter sinkendes Vertrauen in Institutionen auf nationaler und globaler Ebene (Dutt et al., 2024, S. 22f.).\n\n\n4. Regulation und Lösungsansätze\nWie kann diesen Entwicklungen mit Lösungen begegnet werden? Dieser Frage möchte ich in diesem Kapitel mit einem kurzen Ausblick nachgehen. Die Ausführungen um die Entwicklung von KI belegen einen komplexen und facettenreichen Problemkomplex. Diese Fehlentwicklungen in diesem noch sehr dynamischen Markt müssen angegangen werden. Dabei zeigen sich zwei Dimensionen, die einer Lösung bedürfen: Einerseits müssen die Umweltprobleme und deren Auswirkungen angegriffen werden. Andererseits muss die anschliessende Situation bei der ungerechten Verteilung der Kosten und Nutzen gelöst werden. Ein wichtiger Ansatz liegt in der Einführung politischer Regulationswerkzeuge. Besonders für die erste Problemdimension kann das einfacher umgesetzt werden. Hierbei nimmt das KI-Gesetz der Europäischen Union eine Pionierrolle ein. Es stellt dafür den ersten gesetzlichen Rahmen weltweit dar (Europäische Kommission, 2025). Dieser umfassende regulative Ansatz verfolgt eine ganzheitliche Perspektive. Innerhalb der EU sollen diese Systeme einer Kontrolle unterstehen, um neben der Sicherheit auch ihre Umweltfreundlichkeit zu gewährleisten. Generative Modelle gelten zwar nicht als besonders risikobehaftet. An sie werden aber Kriterien über Transparenz gelegt (Europäisches Parlament, 2023). Das europäische Parlament erwirkte in den initialen Verhandlungen strikte Umweltschutzauflagen, wie ein detailliertes Energiemonitoring. Im Nachgang fand aber eine deutliche Abschwächung statt. Ein grosser Teil der Systeme unterliegt nicht diesem Monitoring und der Schwerpunkt liegt auf dem Energieverbrauch. Bereiche, wie Wasser- und Rohstoffverbrauch finden darin keine Beachtung (Heinrich Böll Stiftung, 2024). Bisher fehlt eine solche Regulation in der Schweiz. Jedoch hat der Bundesrat das Eidgenössische Justiz- und Polizeidepartement mit der Erarbeitung einer Vernehmlassungsvorlage bis Ende 2026 beauftragt. Darin sollen neben Bestimmungen über Diskriminierung auch Regeln über Transparenz eine Rolle spielen (Bundesamt für Justiz, 2025). In der globalen Betrachtung bestehen aber grosse Differenzen und höchstunterschiedliche Sichtweisen auf die regulativen Erforderlichkeiten. Mittlerweile weisen Entwicklungen sogar in die andere Richtung. So hat Präsident Donald Trump vor kurzem eine Executive Order erlassen, um die Kohleindustrie in den USA zu stärken. Hindernisse, wie Umweltschutzauflagen, sollen beseitigt werden. Hierbei hebt er die Bedeutung für den steigenden Strombedarf durch KI hervor (The White House, 2025). Es ist fraglich, ob der Anteil fossiler Erzeuger wieder steigen wird. Die Kosten für Solar- und Windenergie sind heute deutlich geringer. Jedoch kann es für den weiteren Ausbau hinderlich sein (Howland, 2025).\nDie internationale Dimension der Problematik macht eine entsprechende Regulation der Umweltbelastungen erforderlich. Van Wynsberghe (2021, S. 217) propagiert als Lösungsansatz ein Programm auf drei Ebenen. Erstens muss diese neue Technologie als ein Sozialexperiment wahrgenommen werden, bei dem noch viele Unklarheiten herrschen. Mit dieser Perspektive können ethische Richtlinien verabschiedet werden, der Mensch und den Globus vor diesen Auswirkungen schützt. Zweitens muss die Politik über eine Orientierungshilfe verfügen. Das können Fachgruppen sein, die die Umweltauswirkungen evaluieren. Daraus können konkrete Massnahmen abgeleitet werden. Nachhaltigkeitskriterien sollten dabei eine zentrale Rolle spielen. Ein Anfang kann die verpflichtende Offenlegung aller Treibhausgasemissionen sein, die mit dem Training und dem Einsatz anfallen. Drittens bedarf es auch der Einführung von Benchmarks. Damit soll vergleichend gezeigt werden, wie hoch die Umweltbelastungen bestimmter Modelle bei konkreten Aufgaben sind.\nDazu gehören Informationsmittel für eine breitere Öffentlichkeit, die nicht nur Fachkreise erreichen. Ein Beispiel stellt das Projekt AI Energy Star dar. Es ist eine Energieetikette für KI-Produkte, das sich an das amerikanische Energy Star Rating System anlehnt. Es gibt Auskunft über den Energieverbrauch einzelner Modelle und setzt diese in Relation zueinander (Luccioni et al., 2024a).\nEbenfalls muss die zweite Problemdimension angegangen werden. Damit bisher benachteiligte Gruppen und Weltregionen von diesen Innovationen profitieren, müssen Investitionen getätigt werden. Ein wichtiger Hebel liegt in der Verbesserung der digitalen Infrastruktur und den entsprechenden Anwendungskenntnissen. Bildungsprogramme, um die Fertigkeiten in diesen Bereichen zu verbessern, sind ein essenzieller Ansatzpunkt. Damit verbunden kann ein Wandel der beruflichen Landschaft sein. Das ist eine sehr wichtige Stellschraube. Der Aufbau von lokalen hochqualitativen Bürotätigkeiten hat einen bedeutenden Effekt auf die Anwendung von KI. Daneben muss auch der linguistische Bias angegangen werden. Unternehmen und Regierungen sollten sich auf einen mehrsprachigen Ansatz konzentrieren. So müssen Datensätze diverser und breiter werden, um der Pluralität verschiedenster Kulturen, Sprachen und lokaler Besonderheiten gerecht zu werden (Liu & Wang, 2024, S. 46). Dieser Wandel muss nicht zwangsläufig von Regierungen angestossen werden. Wie die Umweltgerechtigkeitsbewegung in den USA illustrierte, spielen insbesondere Graswurzelbewegungen eine wichtige Rolle. Sie können den notwendigen Druck auf die Politik ausüben, um gesetzgeberische Massnahmen zu erwirken (Bullard, 1994, S. 1045f. & S. 1047-1049).\nEine Klima-Governance muss über verschiedene geographische Räume und Akteure funktionieren. Lokale Katastrophen auf Grund klimatischer Veränderungen dürfen nicht isoliert betrachtet werden. Effektive Lösungen verknüpfen die globale, nationale und lokale Ebene. Hierbei kann ein relevanter Anknüpfungspunkt in der Stärkung der Resilienz gegenüber den Folgen von Klimawandel bestehen. Bereits das 2015 verabschiedete Pariser Klimaabkommen enthält darüber Bestimmungen (Chaturvedi, 2022, S. 188 & S. 190). Das bedarf einem ganzen Bündel an Massnahmen. Dazu gehört die Entwicklung der Infrastruktur und der Anpassungsstrategien. Dabei müssen besonders vulnerable Gruppen im Fokus stehen. Neben internationalen Kooperationen, sind auch regionale Allianzen wichtig. Nur damit können die notwendigen Investitionen angestossen werden (Asibey & Cobbinah, 2023, S. 234f.).\nVerschiedenste Sektoren müssen sich an Lösungen beteiligen. So erfordert die Entsorgung von Hardware eine zirkuläre Systemausgestaltung. Realisiert werden kann das aber nur mit verschiedenen Akteuren, wie den Hardwareherstellern und Recyclingbetrieben (Wang et al., 2024, S. 821). Konsument:innen müssen ebenfalls sensibilisiert werden. Zum Beispiel sind grosse Modelle, die eine Vielzahl von Aufgaben lösen können ineffizienter, als solche für spezifische Aufgaben. Damit haben Nutzende selbst erheblichen Einfluss auf die Umweltbelastung durch ihre Aktivitäten (Luccioni et al., 2024b, S. 94). Ferner sollten sich auch Wissenschaft und Wirtschaft an Verbesserungen beteiligen. Ein intensives Forschungsstreben nach effizienteren Algorithmen und Hardwarekomponenten muss eine Grundvoraussetzung bilden (Strubell et al., 2019, S. 2). Besonders Effizienzsteigerungen sind für Unternehmen wegen erheblicher Einsparpotenziale bereits heute ein wichtiges Aktionsfeld. Optimierungen durch bessere Modelle ermöglichen mit weniger Rechenleistung die gleichen Ergebnisse zu erzielen. In der Praxis lassen sich durchaus Beispiele dafür finden. OpenAI konnte die Rechenleistung für das Trainieren desselben Modells von 2012, im Jahr 2020 nahezu um 44-mal reduzieren. Somit übersteigen diese Effizienzmassnahmen sogar die Fortschritte auf der Hardwareebene (Vipra & Myers West, 2023; Hernandez & Brown, 2020, S. 7f.).\nEine Grundvoraussetzung für die Zukunft bildet die Internalisierung der Kosten, wovon grosse Teile ausgelagert sind. Subventioniert wird dies bisher von einer Vielzahl von Menschen, die aber selber nicht davon profitieren. Diese Kosten müssen durch die Verursacher:innen mit ihren Handlungen auf die Umwelt getragen werden. Damit werden ineffiziente und umweltschädliche Produkte deutlich teurer und somit weniger verwendet. Insgesamt ist das ein schwieriges Unterfangen, da keine Einigkeit über Höhe der Kosten sowie Vorteile besteht und wie diese umgelagert werden sollten (Hubert, 2020, S. 161).\n\n\n5. Fazit\nDie Entwicklung und die zunehmende Verbreitung von KI haben erhebliche negative Auswirkungen auf das Wohlbefinden von vielen Menschen und der Natur. Durchaus können diese Technologien den Fortschritt antreiben und neue Industriezweige eröffnen, wie das Beispiel China illustriert. Es offenbart sich in der Betrachtung von KI-Systemen ein enormer Bedarf an Ressourcen. Das sind nicht nur Rohstoffe für die Produktion der Komponenten, sondern ebenfalls der Wasserverbrauch. Während des Betriebes werden grosse Mengen davon benötigt. Gravierend zeigt sich ihr Beitrag am Klimawandel. Training und Inferenz benötigen enorme Strommengen. Insbesondere, wenn diese mit kalorischen Kraftwerken produziert werden, führt das zur Emittierung erheblicher Mengen an CO2 und damit zur Verstärkung der globalen Erwärmung.\nDiese Umweltbelastungen treffen Menschen in ungleichem Ausmass. Dazu gehören Betroffene vom Klimawandel, die zum Beispiel durch Überflutungen bedroht sind, den Anwohner:innen von Bergwerken, die durch Luftverschmutzung Atemprobleme erleiden oder den dort Angestellten, die ihr Leben und ihre Gesundheit aufs Spiel setzen. Eine wichtige Hintergrundfolie bildet hierfür die Omnipräsenz von Umweltrassismus und Umweltdiskriminierung. Der Nutzen ist sehr ungerecht verteilt. Auch hier zeigen sich grosse Unterschiede. Menschen aus ärmeren Gebieten haben deutlich weniger Zugangsmöglichkeiten zu diesen Technologien. In dieser Problematik von ungerechter Verteilung von Kosten und Nutzen spielt die Dominanz grosser Unternehmen in diesem Bereich eine wichtige Rolle. Mit ihrer ökonomischen Stärke verfolgen sie Partikularinteressen, die kaum dem Allgemeinwohl dienen. Eine Rücksichtnahme auf die Bedürfnisse betroffener Gruppen erfolgt in den meisten Fällen nicht.\nLösungen im abschliessenden Teil zeigen regulative Massnahmen, wie das europäische KI-Gesetz illustriert. Neben diesen politischen Werkzeugen bedarf es auch Anstrengungen von Anbietern und Verbraucher:innen für besseren Umweltschutz. Eine wichtige Prämisse sollte dabei die gerechtere Aufteilung von Kosten und Nutzen sein.\nIn Zukunft wird KI an Bedeutung gewinnen. Produktivitätsgewinne sind ein wesentlicher Vorteil dieser Technologien. Unternehmen werden sich dem nicht entziehen können. Die negativen Auswirkungen müssen mitgedacht und kritisch behandelt werden. Das kann nur mit der Übernahme von Verantwortung und Rücksichtnahme gelingen. Einer Nachhaltigkeitsperspektive sollte eine zentrale Rolle zukommen (Gaur et al., 2023, S. 8). Nur damit können den Folgen in Form von Umweltproblemen und sozialen Ungleichheiten effektiv entgegengearbeitet werden.\nKI-Anwendungen stellen aber nicht nur ein Problem dar. Sie können auch zur Lösung beitragen. Für den Umgang mit dem Klimawandel und dessen Folgen bieten sie sich als wichtiges Werkzeug an. So analysiert zum Beispiel die Studie von Hanen Balti et al. (2020, S. 10) die Möglichkeiten von KI-Anwendungen zur Bekämpfung von Trockenheiten. Beispielsweise können Extremwetterereignisse mit höherer Genauigkeit vorhergesagt werden. Eine weitere Anwendung liegt in der Optimierung der Stromsysteme mit einem hohen Anteil an erneuerbaren Energien. Durch bessere Prognosen von Windverhältnissen und Solareinstrahlung werden die Kapazitäten effektiver genutzt. Sie können ferner auch für die Risikoeinschätzungen bestimmter Gebiete helfen. Potenzielle Überflutungsgebiete können abgeschätzt und frühzeitig Massnahmen dagegen ergriffen werden (Gatla, 2019, S. 3-5).\nKI-Systeme können den Klimawandel in negativer und in positiver Weise beeinflussen. Für ein abschliessendes Urteil durch die Wissenschaft bezüglich Vor- und Nachteile für die Umwelt sind die Entwicklungen aber noch nicht genügend weit fortgestritten. Im Moment muss aber der Umweltbelastung ein zentraler Stellenwert in der Analyse zukommen (J. L. Li et al., 2024, S. 370).\n\n\n6. Bibliografie\nAcocella, N. (2024). Artificial Intelligence: Benefits and Costs. Cambridge Scholars Publishing. https://www.cambridgescholars.com/product/978-1-0364-1295-1\nAffolderbach, J., & Schulz, C. (2024). Wirtschaftsgeographien der Nachhaltigkeit. Transcript. https://doi.org/10.36198/9783838561325\nAikins, S. K. (2024). Determinants of Digital Divide in Africa and Policy Implications. International Journal of Public Administration in the Digital Age, 6(1), 64-79. https://doi.org/10.4018/IJPADA.2019010104\nAmodei, D., & Hernandez, D. (2018). AI and Compute. OpenAI. https://openai.com/index/ai-and-compute/\nAndeobu, L., Wibowo, S., & Grandhi, S. (2023). Informal E-Waste Recycling Practices and Environmental Pollution in Africa: What Is The Way Forward? International Journal of Hygiene and Environmental Health, 252, 1-24. https://doi.org/10.1016/j.ijheh.2023.114192\nAnsah, M. R., Ugo, H. C., Aboagye, I. A., Sowah, N. L., Osei, G., Balapangu, S. S., & Kwofie, S. K. (2024). Artificial Intelligence and Health in Africa: Opportunities, Challenges, and Ethical Considerations. In L. G. Adu Amoah (Ed.), Examining the Rapid Advance of Digital Technology in Africa (pp. 105-125). IGI Global. https://doi.org/10.4018/978-1-6684-9962-7.ch006\nAsibey, M. O., & Cobbinah, P. B. (2023). The Evidence for Climate Change on Our Planet. In R. Brinkmann (Ed.), The Palgrave Handbook of Global Sustainability (pp. 223-238). Springer Nature. https://doi.org/10.1007/978-3-031-01949-4\nAyers, S., Ballan, S., Gray, V., & McDonald, R. (2024). Measuring the Emissions & Energy Footprint of the ICT Sector: Implications for Climate Action. Weltbank & Internationale Fernmeldeunion (ITU). https://documents1.worldbank.org/curated/en/099121223165540890/pdf/P17859712a98880541a4b71d57876048abb.pdf\nBaldé, C. P., Kuehr, R., Yamamoto, T., McDonald, R., D’Angelo, E., Althaf, S., Bel, G., Deubzer, O., Fernandez-Cubillo, E., Forti, V., Gray, V., Herat, S., Honda, S., Iattoni, G., Khetriwal, D. S., Luda di Cortemiglia, V., Lobuntsova, Y., Nnorom, I., Pralat, N., & Wagner, M. (2024). Global E-Waste Monitor 2024. International Telecommunication Union (ITU) & United Nations Institute for Training and Research (UNITAR). https://ewastemonitor.info/wp-content/uploads/2024/03/GEM_2024_18-03_web_page_per_page_web.pdf\nBalti, H., Ben Abbes, A., Mellouli, N., Farah, I. R., Sang, Y., & Lamolle, M. (2020). A Review of Drought Monitoring with Big Data: Issues, Methods, Challenges and Research directions. Ecological Informatics, 60, 1-17. https://doi.org/10.1016/j.ecoinf.2020.101136\nBarratt, L., & Gambarini, C. (2025). Revealed: Big Tech’s New Datacentres Will Take Water from the World’s Driest Areas. The Guardian. https://www.theguardian.com/environment/2025/apr/09/big-tech-datacentres-water\nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be too Big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’21). Association for Computing Machinery, New York, NY, USA, 610–623. https://doi.org/10.1145/3442188.3445922\nBerreby, D. (2024). As Use of A.I. Soars, So Does the Energy and Water It Requires. Yale Environment 360. https://e360.yale.edu/features/artificial-intelligence-climate-energy-emissions\nBimir, M. N. (2020). Revisiting E-Waste Management Practices In Selected African Countries. Journal of the Air & Waste Management Association, 70(7), 659-669. https://doi.org/10.1080/10962247.2020.1769769\nBirch, K. & Bronson, K. (2022). Big Tech. Science As Culture, 31(1), 1-14. https://doi.org/10.1080/09505431.2022.2036118\nBirkmann, J., Jamshed, A., McMillan, J. M., Feldmeyer, D., Totin, E., Solecki, W., Ibrahim, Z. Z., Roberts, D., Bezner Kerr, R., Poertner, H.-O., Pelling, M., Djalante, R., Garschagen, M., Leal Filho, W., Guha-Sapir, D., & Alegría, A. (2022a). Understanding Human Vulnerability to Climate Change: A Global Perspective on Index Validation for Adaptation Planning. Science of the Total Environment, 803, 1-18. https://doi.org/10.1016/j.scitotenv.2021.150065\nBirkmann, J., Liwenga E., Pandey, R., Boyd, E., Djalante, R., Gemenne, F., Leal Filho, W., Pinho, P. F., Stringer, L., & Wrathall, D. (2022b). Poverty, Livelihoods And Sustainable Development. In H.-O. Pörtner, D. C. Roberts, M. Tignor, E. S. Poloczanska, K. Mintenbeck, A. Alegría, M. Craig, S. Langsdorf, S. Löschke, V. Möller, A. Okem & B. Rama (Eds.), Climate Change 2022: Impacts, Adaptation and Vulnerability. Contribution of Working Group II to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change (pp. 1171-1274). Cambridge University Press. https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter08.pdf\nBrand, U., & Wissen, M. (2024). Imperiale Lebensweise: Zur Ausbeutung von Mensch und Natur im Globalen Kapitalismus. Oekonom Verlag. https://doi.org/10.14512/9783960061908\nBryan, M. (2012). Americas. In B. Walker (Ed.), State of the World’s Minorities and Indigenous Peoples 2012: Events of 2011 (pp. 88-117). Minority Rights Group International. https://minorityrights.org/app/uploads/2023/12/download-1112-state-of-the-worlds-minorities-and-indigenous-peoples-2012-full-text.pdf\nBullard, R. D. (1994). Environmental Racism and Invisible Communities. West Virginia Law Review, 96(4), 1037-1050. https://researchrepository.wvu.edu/cgi/viewcontent.cgi?article=1865&context=wvlr\nBundesamt für Justiz (2025). Künstliche Intelligenz. https://www.sem.admin.ch/bj/de/home/staat/gesetzgebung/kuenstliche-intelligenz.html\nCarleton, T., Jina, A., Delgado, M., Greenstone, M., Houser, T., Hsiang, S., Hultgren, A. Kopp, R. E., McCusker, K. E., Nath, I., Rising, J., Rode, A., Seo, H. K., Viaene, A., Yuan, J., & Zhang, A. T. (2022). Valuing the Global Mortality Consequences of Climate Change Accounting for Adaptation Costs and Benefits. The Quarterly Journal of Economics, 137(4), 2037-2105. https://doi.org/10.1093/qje/qjac020\nChaturvedi, S. (2022). Adaptation Governance. In R. Shaw (Ed.), Handbook on Climate Change and Disasters (pp. 183-198). Elgar. http://doi.org/10.4337/9781800371613\nChauhan, A., Rajput, V., Stanikzai, K., & Kumar, S. (2025). Understanding the Global Status of Electronic Wastes. In S. Goswami, M. Choudhury & S. Agarwal (Eds.), Electronic Waste: Impact on Health, Animals, and the Environment (pp. 31-39). CRC Press. https://doi.org/10.1201/9781003582311\nConnolly, P., Keller, D. R., Leever, M. G., & White, B. C. (2009). Ethics in Action: A Case-Based Approach. Wiley-Blackwell. https://www.wiley.com/en-us/Ethics+In+Action%3A+A+Case-Based+Approach-p-9781405170970\nContinuum Labs. (2023). NVIDIA GB200 NVL72. https://training.continuumlabs.ai/infrastructure/servers-and-chips/nvidia-gb200-nvl72\nCrawford, K. (2021). The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale University Press. https://doi.org/10.2307/j.ctv1ghv45t.\nDauvergne, P. (2020). AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press. https://doi.org/10.7551/mitpress/12350.001.0001\nDavies, I. P., Haugo, R. D., Robertson, J. C., & Levin, P. S. (2018). The Unequal Vulnerability of Communities of Color to Wildfire. PloS One, 13(11), 1-15. https://doi.org/10.1371/journal.pone.0205825\nDemetriades, J., & Esplen, E. (2010). The Gender Dimensions of Poverty and Climate Change Adaptation. In R. Mearns & A. Norton (Eds.), Social Dimensions of Climate Change: Equity and Vulnerability in a Warming World (pp. 133-144). Weltbank. https://openknowledge.worldbank.org/server/api/core/bitstreams/57ef7f5d-df55-552f-91b8-843eb7b286a3/content\nDhar, P. (2020). The Carbon Impact of Artificial Intelligence. Nature Machine Intelligence, 2, 423-425. https://doi.org/10.1038/s42256-020-0219-9\nDua, I. K., & Patel, P. G. (2024). Optimizing Generative AI Workloads for Sustainability: Balancing Performance and Environmental Impact in Generative AI. Apress Media. https://doi.org/10.1007/979-8-8688-0917-0\nDutt, D., Ammanath, B., Perricos, C., & Sniderman, B. (2024). Now Decides Next: Insights from the Leading Edge of Generative AI Adoption: Deloitte’s State of Generative AI in the Enterprise. https://www2.deloitte.com/content/dam/Deloitte/us/Documents/consulting/us-state-of-gen-ai-report.pdf\nEPOCH AI. (2025). Notable AI Models. https://epoch.ai/data/notable-ai-models\nEuropäische Kommission (2025). AI Act. https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai\nEuropäisches Parlament (2023). KI-Gesetz: Erste Regulierung der künstlichen Intelligenz. https://www.europarl.europa.eu/topics/de/article/20230601STO93804/ki-gesetz-erste-regulierung-der-kunstlichen-intelligenz\nGatla, T. R. (2019). A Cutting-Edge Research on AI Combating Climate Change: Innovations and its Impacts. International Journal of Innovations in Engineering Research and Technology, 6(9), 1-8. https://doi.org/10.26662/ijiert.v11i3.pp1-8\nGaur, L., Afaq, A., Arora, G. K., & Khan, N. (2023). Artificial Intelligence for Carbon Emissions Using System of Systems Theory. Ecological Informatics, 76, 1-12. https://doi.org/10.1016/j.ecoinf.2023.102165\nGoldman Sachs (2024). AI Is Poised to Drive 160% Increase in Data Center Power Demand. https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand\nHeinrich Böll Stiftung (2024). The EU AI Act and Environmental Protection: The Case for a Missed Opportunity. https://eu.boell.org/en/2024/04/08/eu-ai-act-missed-opportunity\nHernandez, D., & Brown, T. B. (2020). Measuring the Algorithmic Efficiency of Neural Networks. 1-20, ArXiv. https://doi.org/10.48550/arXiv.2005.04305\nHintemann, R., & Hinterholzer, S. (2022). Cloud Computing Drives the Growth of the Data Center Industry and its Energy Consumption. Data Centers 2021, 1-4. https://www.borderstep.de/wp-content/uploads/2022/08/Borderstep_Rechenzentren_2021_eng.pdf\nHowland, E. (2025). Trump Orders Aim to Boost Coal for Grid Reliability, AI. ESG Dive. https://www.esgdive.com/news/trump-coal-executive-order-doe-power-plants-ai-grid-reliability/744990/\nHubert, F. (2020). Globaler Klimawandel aus ökonomischer Perspektive: Mikro- und makroökonomische Konsequenzen, Lösungsansätze und Handlungsoptionen. Kohlhammer Verlag. https://shop.kohlhammer.de/globaler-klimawandel-aus-okonomischer-perspektive-37391.html#147=19\nIntergovernmental Panel on Climate Change (IPCC). (2023). Summary for Policymakers. In H. Lee and J. Romero (Eds.). Climate Change 2023: Synthesis Report. Contribution of Working Groups I, II and III to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change, 1-34. https://doi.org/10.59327/IPCC/AR6-9789291691647.001\nInternationale Energieagentur (IEA) (2023). Data Centres and Data Transmission Networks. https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks\nInternationale Energieagentur (IEA) (2024). Electricity 2024: Analysis and Forecast to 2026. https://iea.blob.core.windows.net/assets/18f3ed24-4b26-4c83-a3d2-8a1be51c8cc8/Electricity2024-Analysisandforecastto2026.pdf\nInternationale Fernmeldeunion (ITU) (2024). Measuring Digital Development: Facts and Figures. https://digitallibrary.un.org/record/4074377/files/1427599-EN.pdf\nIslam, M. A., Ahmed, K., Xu, H., Tran, N. H., Quan, G., & Ren, S. (2018). Exploiting Spatio-Temporal Diversity for Water Saving in Geo-Distributed Data Centers. IEEE Transactions on Cloud Computing, 6(3), 734-746. https://doi.org/10.1109/TCC.2016.2535201\nItuen, I., & Hey, L. T. (2021). Der Elefant im Raum – Umweltrassismus in Deutschland: Studien, Leerstellen und ihre Relevanz für Umwelt- und Klimagerechtigkeit. Heinrich-Böll-Stiftung. https://www.boell.de/sites/default/files/2021-12/E-Paper%20Der%20Elefant%20im%20Raum%20-%20Umweltrassismus%20in%20Deutschland%20Endf.pdf\nKemplay, M. (2025). Global AI Push Could Drive Critical Mineral Disputes. SustainableViews. https://www.sustainableviews.com/global-ai-push-could-drive-critical-mineral-disputes-9f31fefa/\nKerr, D. (2024). AI Brings Soaring Emissions for Google and Microsoft, A Major Contributor to Climate Change. NPR. https://www.npr.org/2024/07/12/g-s1-9545/ai-brings-soaring-emissions-for-google-and-microsoft-a-major-contributor-to-climate-change\nKolias, K., Hahladakis, J. N., & Gidarakos, E. (2014). Assessment of Toxic Metals in Waste Personal Computers. Waste Management, 34(8), 1480-1487. https://doi.org/10.1016/j.wasman.2014.04.020\nLi, J. L., Litvinova, Y., Marabelli, M., & Newell, S. (2024). Ethical Implications of AI Use in Practice for Decision-Making. In I. Constantiou, M. Stelmaszak, & M. P. Joshi (Eds.), Research Handbook on Artificial Intelligence and Decision Making in Organizations (pp. 359-375). Elgar. https://doi.org/10.4337/9781803926216.00030\nLi, P., Yang, J., Islam, M. A., & Ren, S. (2023). Making AI Less “Thirsty”: Uncovering and Addressing the Secret Water Footprint of AI Models. ArXiv, 1-10.\nhttps://doi.org/10.48550/arXiv.2304.03271\nLiu, Y., & Wang, H. (2024). Who on Earth Is Using Generative AI? Policy Research Working Paper 10870. World Bank Group. https://documents1.worldbank.org/curated/en/099720008192430535/pdf/IDU-5f321eb5-4870-472d-a888-3ab677be07b0.pdf\nLuccioni, A. S., Viguier, S., & Ligozat, A.-L. (2023). Estimating the Carbon Footprint of BLOOM, A 176B Parameter Language Model. Journal of Machine Learning Research, 24, 1-15. https://jmlr.org/papers/volume24/23-0069/23-0069.pdf\nLuccioni, A. S., Gamazaychikov, B., Hooker, S., Pierrard, R., Strubell, E., Jernite, Y., & Wu, C.-J. (2024a). Light Bulbs Have Energy Ratings - So Why Can’t AI Chatbots? Nature. https://www.nature.com/articles/d41586-024-02680-3\nLuccioni, A. S., Jernite, Y., & Strubell, E. (2024b). Power Hungry Processing: Watts. Driving the Cost of AI Deployment? In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’24). Association for Computing Machinery, New York, NY, USA, 85–99. https://doi.org/10.1145/3630106.3658542\nMéndez-Suárez, M., Monfort, A., & Hervas-Oliver, J.-L. (2023). Are You Adopting Artificial Intelligence Products? Social-Demographic Factors to Explain Customer Acceptance. European Research on Management and Business Economics, 29(3), 1-8. https://doi.org/10.1016/j.iedeen.2023.100223\nMengesha, G. H., Belay, E. G., & Adams, R. (2024). Technical Considerations for Designing, Developing, and Implementing AI Systems in Africa. In L. G. Adu Amoah (Ed.), Examining the Rapid Advance of Digital Technology in Africa (pp. 86-104). IGI Global. https://doi.org/10.4018/978-1-6684-9962-7.ch005\nMilmo, D. (2023). ChatGPT Reaches 100 Million Users Two Months After Launch. The Guardian. https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app\nMoghaddam, S. N. M., & Cao, H. (2024). Artificial Intelligence-Driven Geographies: Revolutionizing Urban Studies. Springer. https://doi.org/10.1007/978-981-97-5116-7\nMoisi, L. (2020). Die Politisierung des Abfalls: Elemente einer Kulturtheorie häuslicher Müllentsorgung. De Gruyter. https://doi.org/10.1515/9783110613360\nMordeson, J. N., & Mathew, S. (2024). Sustainability and Global Challenges: Analysis by Mathematics of Uncertainty. Springer. https://doi.org/10.1007/978-3-031-61770-6\nOlson, E., Grau, A., & Tipton, T. (2024). Data Centers Draining Resources in Water-Stressed Communities. The University of Tulsa. https://utulsa.edu/news/data-centers-draining-resources-in-water-stressed-communities/\nPerzanowski, A. (2022). The Right to Repair: Reclaiming the Things We Own. Cambridge University Press. https://doi.org/10.1017/9781108946926\nSharma, N., & Kumar De, P. (2024). Auf dem Weg zu Netto-Null-Zielen: Nutzung von Data Science für Langzeit-Nachhaltigkeitswege. Springer Vieweg. https://doi.org/10.1007/978-981-97-0335-7\nSingh, N. (2025). Modern Business and AI: A Critical Review with the Role of English Language. In G. Singh (Ed.), Application of English in Artificial Intelligence (AI) and Commercialization (pp. 101-118). SGSH Publications. https://sgshpublications.com/product/application-of-english-in-artificial-intelligence-ai-and-commercialization-perspective/\nSoukharev, B. (2024). Globale Erderwärmung und Migration: Der Klimawandel und seine Auswirkungen auf die Migration in den Norden. Springer Nature. https://doi.org/10.1007/978-3-662-68647-8\nStanford University (2024). Global AI Power Rankings: Stanford HAI Tool Ranks 36 Countries in AI. https://hai.stanford.edu/news/global-ai-power-rankings-stanford-hai-tool-ranks-36-countries-in-ai\nStatista (2024a). Artificial Intelligence (AI) Market Size Worldwide from 2020 to 2030. https://www.statista.com/forecasts/1474143/global-ai-market-size\nStatista (2024b). Number of Hyperscale Data Centers Worldwide from 2015 to 2023. https://www.statista.com/statistics/633826/worldwide-hyperscale-data-center-numbers/\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. ArXiv, 1-6. https://doi.org/10.48550/arXiv.1906.02243\nSupermicro (2025). Supermicro NVIDIA GB200 NVL72: Liquid-Cooled Exascale Compute in a Rack with 72 NVIDIA Blackwell GPUs. https://www.supermicro.com/datasheet/datasheet_SuperCluster_GB200_NVL72.pdf\nTasa-Fuster, V. (2025). The Legal Rationales of the Leading Technological Models: The Challenges of Regulating Linguistic and Gender Biases. In E. Monzó-Nebot & V. Tasa-Fuster (Eds.), Gendered Technology in Translation and Interpreting: Centering Rights in the Development of Language Technology (pp. 27-66). Routledge. https://doi.org/10.4324/9781003465508\nTerrell, K. A., & St. Julien, G. (2022). Air Pollution Is Linked to Higher Cancer Rates among Black or Impoverished Communities in Louisiana. Environmental Research Letters, 17(1), 1-15. https://doi.org/10.1088/1748-9326/ac4360\nThe White House (2025). Fact Sheet: President Donald J. Trump Reinvigorates America’s Beautiful Clean Coal Industry. https://www.whitehouse.gov/fact-sheets/2025/04/fact-sheet-president-donald-j-trump-reinvigorates-americas-beautiful-clean-coal-industry/\nUnited Church of Christ (1987). Toxic Wastes and Race in the United States. https://www.ucc.org/wp-content/uploads/2020/12/ToxicWastesRace.pdf\nUnited Nations (UN) (2021). USA: Environmental Racism in “Cancer Alley” Must End – Experts. https://www.ohchr.org/en/press-releases/2021/03/usa-environmental-racism-cancer-alley-must-end-experts?LangID=E&NewsID=26824\nVan Wynsberghe, A. (2021). Sustainable AI: AI for Sustainability and the Sustainability of AI. AI and Ethics, 1(3), 213-218. https://doi.org/10.1007/s43681-021-00043-6\nVaroquaux, G., Luccioni, A. S., & Whittaker, M. (2024). Hype, Sustainability, and the Price of the Bigger-Is-Better Paradigm in AI. ArXiv, 1-20. https://doi.org/10.48550/arXiv.2409.14160\nVerdegem, P. (2023). Critical AI Studies Meets Critical Political Economy. In S. Lindgren (Ed.), Handbook of Critical Studies of Artificial Intelligence (pp. 302–311). Elgar. https://doi.org/10.4337/9781803928562.00033\nVerghese, K. L., Grant, T., & Horne, R. E. (2009). The Development of Life Cycle Assessment Methods and Applications. In: R. E. Horne, T. Grant & K. L. Verghese (Eds.), Life Cycle Assessment. Principles, Practice and Prospects (pp. 9–22)., Csiro Publishing. https://www.doi.org/10.1071/9780643097964\nVipra, J., & Myers West, S. (2023). Computational Power and Al. AI Now Institute. https://ainowinstitute.org/publication/policy/compute-and-ai#af7ad232-7414-4a5a-9893-bb6ccdd8bbad-link\nWang, P., Zhang, L.-Y., Tzachor, A., & Chen, W.-Q. (2024). E-Waste Challenges of Generative Artificial Intelligence. Nature Computational Science, 4(11), 818–823. https://doi.org/10.1038/s43588-024-00712-6\nWeltbank (2024). Digital Progress and Trends Report 2023. https://doi.org/10.1596/978-1-4648-2049-6\n\n\n\n\n Back to top",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge",
      "Saubere und gerechte KI?"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at rachel.huber@faculty.unibe.ch. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at rachel.huber@faculty.unibe.ch. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "contents/posts/20250530-Post_Decoding_Inequality_Pfister_Quirin.html",
    "href": "contents/posts/20250530-Post_Decoding_Inequality_Pfister_Quirin.html",
    "title": "The Humans in the Loop: Labor Exploitation and AI Training",
    "section": "",
    "text": "Warning\n\n\n\nDisclaimer: AI was used during the creation of this post in multiple ways and forms. I am aware of the use of AI can inflict explosive labor practices and a high carbon footprint. For further information on the ecological consequences of high data usage please see Rafaels post in the same blog. For more information on the possible labor exploitation in AI please continue reading.",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge",
      "The Humans in the Loop: Labor Exploitation and AI Training"
    ]
  },
  {
    "objectID": "contents/posts/20250530-Post_Decoding_Inequality_Pfister_Quirin.html#footnotes",
    "href": "contents/posts/20250530-Post_Decoding_Inequality_Pfister_Quirin.html#footnotes",
    "title": "The Humans in the Loop: Labor Exploitation and AI Training",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRequest made on 2025 May 22, free version of GPT 4.1 Mini Model without Loging. Exact prompt that was used “Can you be sure that there was no labor explotation regarding the annotation of your training data?”↩︎\nThéophile Simon, Die Zwansarbeiter*innen hinter der Künstlichen Intelligenz, Amnesty-Magazin März 2024. Online: https://www.amnesty.ch/de/ueber-amnesty/publikationen/magazin-amnesty/2024-1/die-zwangsarbeiter-innen-hinter-der-kuenstlichen-intelligenz↩︎\nBrandom, Russell. Scale AI’s Remotasks platform is dropping whole countries without explanation, in:\nRest of the World, 28.03.2024. https://restofworld.org/2024/scale-ai-remotasks-banned-workers/, accessed 23.05,2025.↩︎\nRemotask Working Location Policy, last updated Feb 14, 2023, last accessed 25.05.205.↩︎\nEU Artificiel Intelligence Act, https://artificialintelligenceact.eu/, last accessed 19.05.2025.↩︎\nThéophile Simon, Die Zwangsarbeiter*innen hinter der Künstlichen Intelligenz, Amnesty-Magazin März 2024. Online: https://www.amnesty.ch/de/ueber-amnesty/publikationen/magazin-amnesty/2024-1/die-zwangsarbeiter-innen-hinter-der-kuenstlichen-intelligenz↩︎\nGray, Mary L. and Siddharth Suri, Ghost Work. How to Stop Silicon Valley from Building a New Global Underclass, 2019, S.85-93.↩︎\nSee e.g. Mitratech Syntrio, online: https://syntrio.com/resources/mitratech-reporting-hotlines-overview/, last accessed 26.05.2025.↩︎\nSee for example and Reffell, Clive: Why is Crowdsourcing Vital to Make AI Smarter? On The Crowdsourcing Week, no publishing date. Online: https://crowdsourcingweek.com/blog/crowdsourcing-makes-ai-smarter/, last accessed: 18.05.2025.\nSamuel, Alexandra. Amazon’s Mechanical Turk has Reinvented Research, in: The Digital Voyage, 15.03.2018.Online: https://daily.jstor.org/amazons-mechanical-turk-has-reinvented-research/↩︎\nSamuel, Alexandra. Amazon’s Mechanical Turk has Reinvented Research.↩︎\nGray, Mary L. and Siddharth Suri, Ghost Work. How to Stop Silicon Valley from Building a New Global Underclass, 2019, S.121-39.↩︎\nCatherine D’Ignazio, Counting Frminicide: Data Feminism in Action, 2024, p.214.↩︎\nCatherine D’Ignazio, Counting Frminicide: Data Feminism in Action, 2024, p.220f.↩︎\nSame, chapter 7 and 8.↩︎\nSee https://turkopticon.net/, last accessed 21.05.2025.↩︎\nGray, Mary L. and Siddharth Suri, Ghost Work. How to Stop Silicon Valley from Building a New Global Underclass, 2019. P.138.↩︎\nBenjamin, Ruth. Race after Technology. Abolition Tools for the New Jim Code, 2019, p.60-97.↩︎",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge",
      "The Humans in the Loop: Labor Exploitation and AI Training"
    ]
  },
  {
    "objectID": "contents/posts/20250527-ChatGPT_Manifest.html",
    "href": "contents/posts/20250527-ChatGPT_Manifest.html",
    "title": "ChatGPT im Klassenzimmer",
    "section": "",
    "text": "Verbote von technologischem Fortschritt haben noch nie zu einer Verbesserung im Bildungssystem geführt.\nTransparenz und Aufklärung sind nachhaltiger als Verbote.\nChatGPT wird nur so lange verwendet, wie die begründete Überzeugung besteht, dass durch ChatGPT generierte Antworten besser bewertet werden als eigens konzipierte.\nSolange die obengenannten Überzeugungen bestehen, schafft das Bildungssystem Anreize für eigenes und kritisches Denken ab.\nEs braucht eine Reform des Bildungssystems.\n\nEin Gespenst geht um in Klassenzimmern des Globalen Nordens – ein Gespenst namens ChatGPT. Seit seiner Lancierung im November 2022 macht das Large Language Model (LLM) Lehrpersonen der privilegierten Welt zu schaffen. Dies ist ein Aufruf an Lehrpersonen und Lehrbildner:innen für einen neuen Umgang mit der sogenannten Künstlichen Intelligenz. Ein Aufruf, diese sich in allermunde befindende Technologie als Chance zu sehen anstatt als Gefahr.\n\n\nVor ChatGPT waren es die Handys und vor den Handys waren es Computer. Eine neuartige Technologie kommt auf, wird vor allem von Schüler:innen weitgehend genutzt und sofort auf alles weitere während der Unterrichtszeiten verboten. Irgendwann wächst das Bewusstsein dafür, dass es sich um eine Technologie handelt, die nicht mehr verschwinden wird und langsam werden Lehrpersonen dazu ausgebildet, Schüler:innen für den Gebrauch dieser Neuartigkeit auszubilden. Es folgt eine Übergangsphase in der das durch Schüler:innen-Neugier angeeignete Wissen jenes der wenig motivierten Lehrpersonen überragt, bis neues Fachpersonal dazustösst, welches sich in der Ausbildung bereits mit der (nun nicht mehr so) neuen Thematik befasste. An diesem Punkt übernimmt eine bestenfalls enthusiastische aber mindestens gut ausgebildete Lehrperson das Feld und fördert die Schüler:innen in einem kontrollierten Umfeld (mehr dazu in Siyam, Hussain & Alqaryouti 2021).\nDie Digitalisierung, welche als Vorreiterin von KI betrachtet wird, kann von dieser Entwicklung ein Liedchen singen. Es dauerte Jahrzehnte bis das Prinzip Bring Your Own Device (BYOD)1 und damit der Schritt in eine digitale Zukunft von den Schulen in der Schweiz vollzogen wurde. Davor galten jegliche digitalen Geräte als grosses No-Go und Computer durften lediglich im Informatikunterricht benutzt werden, welcher vor allem als Einführung in das Microsoft Office Paket fungierte. Die von kritischen Lehrpersonen verbreitete Angst einer Anarchie im Klassenzimmer blieb aus. Stattdessen folgten motiviertere Schüler:innen, die sich zumindest für die digitalen Anforderungen im künftigen Berufsleben gewappnet(er) fühlten (Al-Said 2023; He & Zhao 2020).\nDas Beispiel illustriert, dass die Bildung lediglich darunter leidet, wenn die Schule den Kopf vor technologischen Neuerungen durch Verbote in den Sand steckt. Es wird einen Punkt geben, an dem LLMs in unserem Leben eine so grosse Rolle einnehmen werden, dass das sowieso nicht mehr möglich sein wird. Dem muss sich die Schule als primäre Bildungsinstanz bewusst sein und eine Vorreiterrolle in der Ausbildung in Bezug auf LLMs einnehmen (siehe dazu Belghith et al. 2024; Macar et al. 2023; Kilhoffer et al. 2023). Mit weiteren Verboten wird lediglich dafür gesorgt, dass heutige Schüler:innen weiterhin unaufgeklärt und unkritisch LLMs benutzen, ohne einen geübten Umgang mit ihnen zu erlernen (Olari, Tenório & Romeike 2022). Denn eins ist sicher: Verbote hielten Schüler:innen noch nie von irgendetwas ab!\n\n\n\nInnerhalb dieser wenigen Zeilen wird keinesfalls behauptet, LLMs seien unproblematisch. Weiterhin soll nicht zu einer revolutionären Massennutzung von LLMs aufgerufen werden. Stattdessen plädiere ich für einen transparenten und aufgeklärten Ansatz, welcher sich immer als nachhaltiger herausstellt als Verbote.\nZahlreiche Massnahmen (wie bspw. Verbote), welche noch so gerne von Schulen lanciert werden, widersprechen dem stetig proklamierten Ziel des Bildungssystems, Schüler:innen zu kritischen Denker:innen auszubilden. Kritisch denken lernt mensch nicht dadurch, dass ihm stetig gesagt wird, dass es das ist, was er hier lernt, sondern dadurch, sich seine eigenen Gedanken auf einer aufgeklärten Wissensbasis machen zu können. Das Gleiche gilt für LLMs und dementsprechend für ChatGPT.\nDenn ja, LLMs müssen kritisch beurteilt werden; sie reproduzieren Bias und Diskriminierung (Mehrami et al. 2021; Bender et al. 2021), schaden der Umwelt (Lacoste et al. 2019; Klöpper 2025) und beuten Menschen im Globalen Süden strukturell aus (Pfister 2025). All das, nur damit eine kleine privilegierte Menschenmasse, die Zugriff zum Internet hat und eine Sprache spricht, welche in den Trainingsdaten der LLM vorhanden war, keine eigenen Geburtstagskarten, Zusammenfassungen oder Bewerbungen mehr schreiben muss. Dennoch ermöglichen LLMs gleichzeitig mehr Chancengleichheit bspw. für jene Personen, die aufgrund von Dyslexie Diskriminierung erfahren (mehr dazu bei Mitre & Zeneli 2024).\nViele Schüler:innen sind sich den Gefahren der Klimakrise oder den wiederaufkommenden faschistischen Ideologien bewusst und engagieren sich für mehr Gerechtigkeit auf unterschiedlichen Ebenen. Es ist an der Schule, Bildung zu betreiben, die sie in Bezug auf die Auswirkungen ihrer Nutzung von LLMs aufklärt, damit sie eigens entscheiden können, ob sie diese Auswirkungen in Kauf nehmen wollen.2 Mit dieser Aufklärung und der darauffolgenden autonomen Entscheidung wird ein erster Grundstein für die Ausbildung kritischer Jugendlicher gelegt (siehe dazu unter anderem Yunus et al. 2024).\n\n\n\nAlle Aufklärung der Welt bringt nichts, wenn Schüler:innen, denen von Beginn ihrer Schulkarriere an indirekt beigebracht wird, dass ihre Noten ein Spiegelbild ihrer Kompetenz darstellen, das Gefühl vermittelt wird, dass der Gebrauch von ChatGPT mit besseren Noten einhergeht. An dieser Stelle wird nicht behauptet, dass Lehrpersonen so etwas jemals explizit im Klassenzimmer behaupten würden. Jedoch wird vor allem im Sprachenunterricht ein beträchtlicher Fokus darauf gelegt, dass Schüler:innen lernen „richtig” zu schreiben. Richtig meint hier gemäss den durch eine Rechtschreibeinstanz (arbiträr) festgelegten Rechtschreibenormen. Ich werde zugunsten meines roten Fadens an dieser Stelle auf eine umfassende Kritik des präskriptiven Umgangs mit Sprache in der Schule verzichten. Dennoch möchte ich folgendes Gedankenexperiment in den Raum stellen: Angenommen, Sie, liebe:r Leser:in, müssten möglichst schnell eine Kletterwand erklimmen und würden einzig für die Schnelligkeit, in der sie das schafften, beurteilt. Und angenommen, Sie trainierten dafür bereits seit mehreren Jahren, würden es aber dennoch nicht so schnell schaffen, wie gewünscht und dementsprechend nie die beste Bewertung erhalten. Nun würde Ihnen die Möglichkeit geboten, durch eine neue Innovation lediglich an der Kletterwand hochgezogen zu werden. Dies würde natürlich keinerlei oder nur noch wenig Arbeit und Mühe von Ihnen abverlangen, aber Sie würden es nun schneller bis an die Spitze der Kletterwand schaffen und so eine bessere Bewertung erhalten. Würden Sie nicht auch von der Hilfestellung Gebrauch machen?\n\n\n\nDas zuvor genannte Gedankenexperiment bildet die aktuelle Lage in der Schule ab. Lehrpersonen können noch so oft den Schüler:innen davon abraten, ChatGPT zu benutzen, da sie so ja nichts lernen würden und sie doch in die Schule gingen, um etwas zu lernen. Schlussendlich zählt für Schüler:innen lediglich das, was auf dem Abschlusszeugnis steht und wenn gute (oder ausreichende) Noten zeitsparend durch den Gebrauch von ChatGPT erzielt werden können, dann ist der Preis, im Nachhinein nichts mehr von den Lerninhalten zu wissen, nicht schwer zu zahlen. Dass dies den Prinzipien der Schulbildung komplett widerspricht, ist offensichtlich. Dennoch basiert dieses Problem auf dem aktuellen System. Wenn Aspekte wie Rechtschreibung höher gewichtet werden als eigene Reflexion, verwundert es nicht, dass Ersteres auf Kosten Zweiteres durch den Gebrauch von ChatGPT privilegiert wird. Dadurch wird Schüler:innen von Beginn an beigebracht, dass ihre Gedanken weniger wertvoll sind als die standardisierte Form, in die sie hineingepresst werden müssen. Dies läuft dem proklamierten Ziel, Schüler:innen zu kritischen Denker:innen auszubilden zuwider. Nur durch Wertschätzung der eigenen Reflexion und das Fördern kritischen Denkens durch entsprechende Notenvergabe kann dieses Ziel erreicht werden. Schlussendlich sind Noten der Schüler:innen Lohn.\nDes Weiteren vertrete ich die Meinung, dass das Ziel Schüler:innen zu kritischen Denker:innen auszubilden vielleicht ein bisschen zu abstrakt und weitreichend ist. Es würde sich anbieten, sich vertieft mit der Frage auseinanderzusetzen, was es denn nun ist, dass Schüler:innen aus den 9 bis 13 Jahren Schulbildung mitnehmen sollen. Was sollen sie können? Wie sollen sie sich verändert haben? Mit welchen Kompetenzen sollen sie an die Uni oder die Arbeitswelt weitergereicht werden? Sobald diese Zielsetzungen stehen, geht es dann darum, sich Evaluationsmöglichkeiten zu überlegen, die mit ihren Bewertungsmassstäben genau diese Ziele fördern.\n\n\n\nAus den vorherigen Zeilen sollte klar geworden sein, dass es eine Reform des Bildungssystems braucht. Und das nicht erst seit ChatGPT. Seit der Gründung des Schulbildungssystems trägt dieses zu einem ausgeprägten klassistischen Denken bei. Ungebildetheit und ihre vermeintlichen Symptome (bspw. schlechte Rechtschreibung) werden als wertlos angesehen. Dieses System war mitverantwortlich für den Kolonialismus und erhält unsere kognitive Dissonanz gegenüber der Ausbeutung von Menschen im Globalen Süden für den Wohlstand im Globalen Norden auch heutzutage. Dieses System wird nun jedoch durch LLMs herausgefordert, die mit ihrer vermeintlichen Künstlichen Intelligenz in genau jenen Aspekten brillieren (bspw. einem «rationalen, professionellen» schriftlichen Ausdruck), die in unserer westlichen Gesellschaft als wertvoll erachtet werden.\nEin Verbot von ChatGPT wird dieses System nicht verändern. Dies kann nur durch eine komplette Reform des Bildungssystems3 geschehen. Wenn Schüler:innen durch gute Noten motiviert werden, ihre eigenen Gedanken auszudrücken und kritische Reflexionen anzubringen, wenn sie herausgefordert werden, sich ihrer eigenen Voreingenommenheit in Bezug auf unterschiedlichste Themen bewusst zu werden, erst dann trägt das Bildungssystem zu der Ausbildung kritischer Denker:innen bei. Wenn Schüler:innen über die fragwürdigen Aspekte, die mit ChatGPT einhergehen, aufgeklärt sind und autonom entscheiden können, ob und wofür sie das Tool weiterhin verwenden möchten, dann ist ein erster wichtiger Schritt gemacht. Wenn Schüler:innen über die klassistischen Wurzeln des Bildungssystems und den daraus resultierenden Diskriminierungen aufgeklärt werden, dann ist ein erster Stein für eine gerechtere Gesellschaft gelegt.4",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge",
      "ChatGPT im Klassenzimmer"
    ]
  },
  {
    "objectID": "contents/posts/20250527-ChatGPT_Manifest.html#footnotes",
    "href": "contents/posts/20250527-ChatGPT_Manifest.html#footnotes",
    "title": "ChatGPT im Klassenzimmer",
    "section": "Fußnoten",
    "text": "Fußnoten\n\n\nBspw. für den Kanton Freiburg: https://www.fr.ch/de/bildung-und-schulen/mittelschulen/byod-bring-your-own-device.↩︎\nMit der konkreten Frage, wie ein solcher Unterricht aussehen könnte, beschäftigt sich das Forschungsprojekt „Imagine AI” der University of Colorado (Forsyth et al. 2021; https://www.colorado.edu/project/imagine-ai/research).↩︎\nAn dieser Stelle möchte ich betonen, dass ich das Bildungssystem als differenzierte Institution verstehe, die aus Lehrbildner:innen, Lehrpersonen, Lehrplan und Lehrmaterialien besteht. Ich verwende den umfassenden Begriff «Bildungssystem», da im Einzelfall unterschiedliche Instanzen von meiner Kritik betroffen sind. Keineswegs möchte ich Kritik an jenen Lehrpersonen üben, die bereits einen offenen und transparenten Umgang mit KI in ihrem Unterricht verfolgen oder aber jenen, die durch ihre Lehrbildner:innen zu einem restriktiven Umgang mit der Digitalisierung geschult worden sind und nie etwas anderes gelernt haben. Mir ist bewusst, dass meine Kritik als universell und verallgemeinernd daherkommt und als Angriff auf Individuen verstanden werden kann. Dies ist jedoch nicht mein Ziel. Es braucht ein Umdenken auf allen Ebenen, damit ein produktiver Wandel geschehen kann. Dafür braucht es jedoch Individuen, die sich für genau so einen Wandel einsetzen.↩︎\nDass ein solcher Ansatz in der Berufsbildung erfolgreich angewendet kann, zeigt Philippe Wampfler, der sich als Dozent für Fachdidaktik Deutsch an der IFE der Universität Zürich genau dafür einsetzt. Eine Liste seiner Publikationen ist einsehbar unter: https://philippe-wampfler.ch/publikationen-und-projekte/.↩︎",
    "crumbs": [
      "Kursbeschreibung",
      "Studentische Beiträge",
      "ChatGPT im Klassenzimmer"
    ]
  },
  {
    "objectID": "contents/about.html",
    "href": "contents/about.html",
    "title": "Über uns",
    "section": "",
    "text": "Rachel Huber studierte Kulturmanagement in Zürich, Kulturwissenschaften in Luzern und Globalgeschichte an der Excellenzuni Hamburg. Sie arbeitete als wissenschaftliche Mitarbeiterin und promovierte mit Schwerpunkt Digital History, Erinnerungskulturen und Diskriminierungsgeschichte in den USA von 2016-2021 an der Universität Luzern am Lehrstuhl von Prof. Dr. Aram Mattioli. Von 2022-2023 arbeitete sie, ebenfalls am Historischen Seminar der Universität Luzern, als Posdoc und Projektleiterin. Beim OA  Journal «Public History Weekly» war sie von 2018-2020 als Redaktionsmitglied tätig und von 2022 bis 2023 leitete sie das Drittmittelprojekt «Auslegeordnung Erinnerungskultur Zürich». Die Auftragsforschung wurde vom Präsidialdepartement Zürich vergeben.\n\n\n\n\n\n\nNeustes Buch: Die Frauen der Red-Power-Bewegung\n\n\n\n\n\n\n&lt;p&gt;This browser does not support PDFs. Please download the PDF &lt;a href=\"/assets/files/huber-2023-die-frauen-der-red-power-bewegung.pdf\"&gt;download the PDF&lt;/a&gt; to view it.&lt;/p&gt;\n\n\n\n\n\n\n\nErinnerungskulturen\nDigital Memory\nDigital History\n(Digital) Public History\nGlobalgeschichte\nMinderheitengeschichte\nSchweizer und US-Geschichte\n\n\n\n\n\n\nMoritz Mähr ist assoziierter Forscher in Digital Humanities an der Universität Bern und digitaler Projektleiter von Stadt.Geschichte.Basel an der Universität Basel. Er studierte Geschichte und Philosophie des Wissens, Informatik sowie Bank- und Finanzwesen in Zürich und Berlin. Von 2018 bis 2022 war er wissenschaftlicher Mitarbeiter an der Professur für Technikgeschichte der ETH Zürich. Er schrieb eine Dissertation über die Digitalisierung der Migrationsbehörden in der Schweiz in den 1960er Jahren. Die Studie war Teil des vom SNF geförderten Projekts Trading Zones. Seine Forschungsinteressen liegen im Bereich der Science and Technology Studies, der Digital Humanities und der Computergeschichte. Er ist ein Verfechter von Open Science, Open Access und Open Source.\n\n\n\n\n\n\nNeustes Buch: Wie der Verwaltungscomputer die Arbeitsmigration programmierte\n\n\n\n\n\n\n&lt;p&gt;This browser does not support PDFs. Please download the PDF &lt;a href=\"/assets/files/9783657796823-71011.pdf\"&gt;download the PDF&lt;/a&gt; to view it.&lt;/p&gt;\n\n\n\n\n\n\n\nScience and Technology Studies (STS)\nDigital Humanities (DH)\nComputergeschichte (History of Computing)\nSocial network analysis und Graphen\nNatural Language Processing",
    "crumbs": [
      "Kursbeschreibung",
      "Über uns"
    ]
  },
  {
    "objectID": "contents/about.html#dr.-rachel-huber-assoziierte-forschende",
    "href": "contents/about.html#dr.-rachel-huber-assoziierte-forschende",
    "title": "Über uns",
    "section": "",
    "text": "Rachel Huber studierte Kulturmanagement in Zürich, Kulturwissenschaften in Luzern und Globalgeschichte an der Excellenzuni Hamburg. Sie arbeitete als wissenschaftliche Mitarbeiterin und promovierte mit Schwerpunkt Digital History, Erinnerungskulturen und Diskriminierungsgeschichte in den USA von 2016-2021 an der Universität Luzern am Lehrstuhl von Prof. Dr. Aram Mattioli. Von 2022-2023 arbeitete sie, ebenfalls am Historischen Seminar der Universität Luzern, als Posdoc und Projektleiterin. Beim OA  Journal «Public History Weekly» war sie von 2018-2020 als Redaktionsmitglied tätig und von 2022 bis 2023 leitete sie das Drittmittelprojekt «Auslegeordnung Erinnerungskultur Zürich». Die Auftragsforschung wurde vom Präsidialdepartement Zürich vergeben.\n\n\n\n\n\n\nNeustes Buch: Die Frauen der Red-Power-Bewegung\n\n\n\n\n\n\n&lt;p&gt;This browser does not support PDFs. Please download the PDF &lt;a href=\"/assets/files/huber-2023-die-frauen-der-red-power-bewegung.pdf\"&gt;download the PDF&lt;/a&gt; to view it.&lt;/p&gt;\n\n\n\n\n\n\n\nErinnerungskulturen\nDigital Memory\nDigital History\n(Digital) Public History\nGlobalgeschichte\nMinderheitengeschichte\nSchweizer und US-Geschichte",
    "crumbs": [
      "Kursbeschreibung",
      "Über uns"
    ]
  },
  {
    "objectID": "contents/about.html#dr.-sc.-moritz-mähr-assoziierter-forschender",
    "href": "contents/about.html#dr.-sc.-moritz-mähr-assoziierter-forschender",
    "title": "Über uns",
    "section": "",
    "text": "Moritz Mähr ist assoziierter Forscher in Digital Humanities an der Universität Bern und digitaler Projektleiter von Stadt.Geschichte.Basel an der Universität Basel. Er studierte Geschichte und Philosophie des Wissens, Informatik sowie Bank- und Finanzwesen in Zürich und Berlin. Von 2018 bis 2022 war er wissenschaftlicher Mitarbeiter an der Professur für Technikgeschichte der ETH Zürich. Er schrieb eine Dissertation über die Digitalisierung der Migrationsbehörden in der Schweiz in den 1960er Jahren. Die Studie war Teil des vom SNF geförderten Projekts Trading Zones. Seine Forschungsinteressen liegen im Bereich der Science and Technology Studies, der Digital Humanities und der Computergeschichte. Er ist ein Verfechter von Open Science, Open Access und Open Source.\n\n\n\n\n\n\nNeustes Buch: Wie der Verwaltungscomputer die Arbeitsmigration programmierte\n\n\n\n\n\n\n&lt;p&gt;This browser does not support PDFs. Please download the PDF &lt;a href=\"/assets/files/9783657796823-71011.pdf\"&gt;download the PDF&lt;/a&gt; to view it.&lt;/p&gt;\n\n\n\n\n\n\n\nScience and Technology Studies (STS)\nDigital Humanities (DH)\nComputergeschichte (History of Computing)\nSocial network analysis und Graphen\nNatural Language Processing",
    "crumbs": [
      "Kursbeschreibung",
      "Über uns"
    ]
  },
  {
    "objectID": "contents/sessions/03.html",
    "href": "contents/sessions/03.html",
    "title": "Session 3",
    "section": "",
    "text": "Recap Session 2\nLeseauftrag gemeinsam anschauen\nDatenbegriff klären\n\n\n\nmündlich\n\n\n\n\n\n\n\nIn All Data Are Local, Yanni Alexander Loukissas challenges the common belief that data are neutral, universal, and objective. He argues that data are deeply embedded in local, historical, and institutional conditions, making it impossible to separate them from their context. Instead of treating data sets as isolated and self-contained, he urges readers to examine data settings—the environments in which data are produced, organized, and used.\n\n\n\n\n\n\nLoukissas introduces four examples to illustrate how data are shaped by their origins:\n\nHarvard’s Arnold Arboretum: A data record for a cherry tree mistakenly attributes its collection to a botanist who had died years earlier, highlighting inconsistencies in institutional data.\nDigital Public Library of America (DPLA): Different institutions contribute metadata in varying formats, causing classification inconsistencies.\nNewsScape (TV News Archive): Data are inseparable from the algorithms that process them, shaping what information is surfaced or obscured.\nZillow (Real Estate Data): Zillow provides transparency in the housing market, yet masks structural inequalities.\n\n\n\n\n\nThe term data set implies that data are complete, standardized, and universally applicable, which is misleading.\n\nInstead, data settings acknowledge the social, institutional, and technological environments that shape data collection and interpretation.\n\nUnderstanding the context of data creation is essential to prevent misinterpretation.\n\n\n\n\n\nIn the early 2010s, skepticism toward data neutrality increased, with concerns about:\n\nAlgorithmic bias (e.g., Google’s search algorithms reinforcing stereotypes).\nMisinformation & manipulation (e.g., the role of fake news in the 2016 U.S. election).\nP-Hacking in academic research, where scientists manipulate statistical analyses for misleadingly significant results.\n\n\n\n\n\n\nIdentifying bias isn’t enough—we must change how we engage with data.\nRecognizing locality in data allows for mitigation of biases, context-aware findings, and ethical use.\nLoukissas advocates for a reflexive, comparative, and critical approach to data work.\n\n\n\n\nEach chapter explores six core principles through real-world examples: - Data are attached to places (Arnold Arboretum). - Data come from heterogeneous sources (DPLA). - Data and algorithms are intertwined (NewsScape). - Interfaces shape data perception (Zillow). - Later chapters offer practical guidelines for ethical data use.\n\n\n\n\nThe myth of digital universalism assumes that technology transcends place and context.\nThis belief, rooted in Silicon Valley ideology, ignores the cultural, economic, and political power structures embedded in data systems.\nLoukissas calls for resisting universalism by acknowledging the locality of data, ensuring it remains accountable to its origins and impacts.\n\n\n\n\n\n\n\n\nThis chapter explores data infrastructures, particularly the DPLA, and questions whether data can truly be separated from their local origins.\n\n\n\n\nData Standardization vs. Context Loss:\n\nThe DPLA standardizes data across institutions, but this often erases unique local contexts.\nIts MAP (Metadata Application Profile) forces diverse data sources into a rigid structure.\n\nThe Role of Locality in Data:\n\nInstitutions classify data differently (e.g., the term Upstate means different things in different regions).\nHistorical bias: Some institutions categorize race inconsistently or exclude certain demographics.\n\nData Visualization as a Critical Tool:\n\nThe Library Observatory uses a tree-map visualization to show how different institutions contribute to the DPLA.\nThe Temporalities Project highlights inconsistencies in date formatting across data sources.\n\nThe Influence of Vannevar Bush’s Memex:\n\nBush’s 1945 vision of a universal digital archive influences modern data infrastructures.\nLoukissas critiques this ambition, arguing that knowledge cannot be divorced from its social and institutional context.\n\nThe Political & Ethical Stakes of Data Infrastructures:\n\nLarge, well-funded institutions like Smithsonian or Getty dominate data collection, reinforcing power imbalances.\nLoukissas calls for counterdata infrastructures that challenge dominant narratives and promote inclusive histories.\n\n\n\n\n\n\n\n\n\nLoukissas argues that data accessibility does not guarantee understanding. Instead of simply providing open data, we need contextualized guides that explain their origins and limitations.\n\n\n\nLoukissas contrasts traditional data objectives with alternative, locally grounded goals:\n\n\n\n\n\n\n\n\nTraditional Goals\nLocal Alternatives\nExplanation\n\n\n\n\nOrientation\nPlace-Making\nData should not just help users navigate but also reveal the institutions behind them (e.g., Arnold Arboretum).\n\n\nAccess\nRestraint\nOpen data can be misleading if context is missing (e.g., misinterpretations of the 2016 U.S. election polls).\n\n\nAnalysis\nReflexivity\nAlgorithms are not neutral—we must critically engage with them (e.g., Google’s biased autocomplete).\n\n\nOptimization\nContestation\nData-driven decisions often ignore competing interests (e.g., Zillow optimizing the housing market while hiding its inequalities).\n\n\n\n\n\n\n\nLoukissas proposes a methodology for engaging with data critically:\n\nRead: Examine the dataset for inconsistencies or unusual features.\n\nInquire: Consult experts, data collectors, or subjects to understand the dataset’s background.\n\nRepresent: Use visualizations to highlight patterns and biases.\n\nUnfold: Investigate how data are collected, processed, and normalized.\n\nContextualize: Analyze who uses the data and what ethical concerns arise.\n\nThis approach treats data as an ethnographic inquiry, emphasizing critical engagement rather than passive consumption.\n\n\n\n\n\nLoukissas closes with a call to action: we must change how we engage with data. Instead of treating data as abstract, portable facts, we should see them as points of contact between people, institutions, and power structures.\nHe warns against digital universalism, arguing that data should be understood within their specific historical, institutional, and social contexts. Instead of prioritizing optimization and efficiency, we should focus on social justice, accountability, and transparency.\n\n\n\n\n\n“Do not mistake the availability of data as permission to remain at a distance.”\n\nLoukissas urges us to engage with data deeply, ethically, and contextually—not just as raw information but as a socially embedded artifact requiring care and responsibility.\n\n\n\n\n\nHow do data infrastructures reinforce social inequalities?\n\nWhat would ethical open-data policies look like in practice?\n\nIs it possible to create truly neutral datasets, or is all data inherently biased?\n\n\n\n\n\n\nTBD",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 3"
    ]
  },
  {
    "objectID": "contents/sessions/03.html#recap-session-2",
    "href": "contents/sessions/03.html#recap-session-2",
    "title": "Session 3",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 3"
    ]
  },
  {
    "objectID": "contents/sessions/03.html#leseauftrag-all-data-are-local",
    "href": "contents/sessions/03.html#leseauftrag-all-data-are-local",
    "title": "Session 3",
    "section": "",
    "text": "In All Data Are Local, Yanni Alexander Loukissas challenges the common belief that data are neutral, universal, and objective. He argues that data are deeply embedded in local, historical, and institutional conditions, making it impossible to separate them from their context. Instead of treating data sets as isolated and self-contained, he urges readers to examine data settings—the environments in which data are produced, organized, and used.\n\n\n\n\n\n\nLoukissas introduces four examples to illustrate how data are shaped by their origins:\n\nHarvard’s Arnold Arboretum: A data record for a cherry tree mistakenly attributes its collection to a botanist who had died years earlier, highlighting inconsistencies in institutional data.\nDigital Public Library of America (DPLA): Different institutions contribute metadata in varying formats, causing classification inconsistencies.\nNewsScape (TV News Archive): Data are inseparable from the algorithms that process them, shaping what information is surfaced or obscured.\nZillow (Real Estate Data): Zillow provides transparency in the housing market, yet masks structural inequalities.\n\n\n\n\n\nThe term data set implies that data are complete, standardized, and universally applicable, which is misleading.\n\nInstead, data settings acknowledge the social, institutional, and technological environments that shape data collection and interpretation.\n\nUnderstanding the context of data creation is essential to prevent misinterpretation.\n\n\n\n\n\nIn the early 2010s, skepticism toward data neutrality increased, with concerns about:\n\nAlgorithmic bias (e.g., Google’s search algorithms reinforcing stereotypes).\nMisinformation & manipulation (e.g., the role of fake news in the 2016 U.S. election).\nP-Hacking in academic research, where scientists manipulate statistical analyses for misleadingly significant results.\n\n\n\n\n\n\nIdentifying bias isn’t enough—we must change how we engage with data.\nRecognizing locality in data allows for mitigation of biases, context-aware findings, and ethical use.\nLoukissas advocates for a reflexive, comparative, and critical approach to data work.\n\n\n\n\nEach chapter explores six core principles through real-world examples: - Data are attached to places (Arnold Arboretum). - Data come from heterogeneous sources (DPLA). - Data and algorithms are intertwined (NewsScape). - Interfaces shape data perception (Zillow). - Later chapters offer practical guidelines for ethical data use.\n\n\n\n\nThe myth of digital universalism assumes that technology transcends place and context.\nThis belief, rooted in Silicon Valley ideology, ignores the cultural, economic, and political power structures embedded in data systems.\nLoukissas calls for resisting universalism by acknowledging the locality of data, ensuring it remains accountable to its origins and impacts.\n\n\n\n\n\n\n\n\nThis chapter explores data infrastructures, particularly the DPLA, and questions whether data can truly be separated from their local origins.\n\n\n\n\nData Standardization vs. Context Loss:\n\nThe DPLA standardizes data across institutions, but this often erases unique local contexts.\nIts MAP (Metadata Application Profile) forces diverse data sources into a rigid structure.\n\nThe Role of Locality in Data:\n\nInstitutions classify data differently (e.g., the term Upstate means different things in different regions).\nHistorical bias: Some institutions categorize race inconsistently or exclude certain demographics.\n\nData Visualization as a Critical Tool:\n\nThe Library Observatory uses a tree-map visualization to show how different institutions contribute to the DPLA.\nThe Temporalities Project highlights inconsistencies in date formatting across data sources.\n\nThe Influence of Vannevar Bush’s Memex:\n\nBush’s 1945 vision of a universal digital archive influences modern data infrastructures.\nLoukissas critiques this ambition, arguing that knowledge cannot be divorced from its social and institutional context.\n\nThe Political & Ethical Stakes of Data Infrastructures:\n\nLarge, well-funded institutions like Smithsonian or Getty dominate data collection, reinforcing power imbalances.\nLoukissas calls for counterdata infrastructures that challenge dominant narratives and promote inclusive histories.\n\n\n\n\n\n\n\n\n\nLoukissas argues that data accessibility does not guarantee understanding. Instead of simply providing open data, we need contextualized guides that explain their origins and limitations.\n\n\n\nLoukissas contrasts traditional data objectives with alternative, locally grounded goals:\n\n\n\n\n\n\n\n\nTraditional Goals\nLocal Alternatives\nExplanation\n\n\n\n\nOrientation\nPlace-Making\nData should not just help users navigate but also reveal the institutions behind them (e.g., Arnold Arboretum).\n\n\nAccess\nRestraint\nOpen data can be misleading if context is missing (e.g., misinterpretations of the 2016 U.S. election polls).\n\n\nAnalysis\nReflexivity\nAlgorithms are not neutral—we must critically engage with them (e.g., Google’s biased autocomplete).\n\n\nOptimization\nContestation\nData-driven decisions often ignore competing interests (e.g., Zillow optimizing the housing market while hiding its inequalities).\n\n\n\n\n\n\n\nLoukissas proposes a methodology for engaging with data critically:\n\nRead: Examine the dataset for inconsistencies or unusual features.\n\nInquire: Consult experts, data collectors, or subjects to understand the dataset’s background.\n\nRepresent: Use visualizations to highlight patterns and biases.\n\nUnfold: Investigate how data are collected, processed, and normalized.\n\nContextualize: Analyze who uses the data and what ethical concerns arise.\n\nThis approach treats data as an ethnographic inquiry, emphasizing critical engagement rather than passive consumption.\n\n\n\n\n\nLoukissas closes with a call to action: we must change how we engage with data. Instead of treating data as abstract, portable facts, we should see them as points of contact between people, institutions, and power structures.\nHe warns against digital universalism, arguing that data should be understood within their specific historical, institutional, and social contexts. Instead of prioritizing optimization and efficiency, we should focus on social justice, accountability, and transparency.\n\n\n\n\n\n“Do not mistake the availability of data as permission to remain at a distance.”\n\nLoukissas urges us to engage with data deeply, ethically, and contextually—not just as raw information but as a socially embedded artifact requiring care and responsibility.\n\n\n\n\n\nHow do data infrastructures reinforce social inequalities?\n\nWhat would ethical open-data policies look like in practice?\n\nIs it possible to create truly neutral datasets, or is all data inherently biased?",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 3"
    ]
  },
  {
    "objectID": "contents/sessions/03.html#was-sind-daten",
    "href": "contents/sessions/03.html#was-sind-daten",
    "title": "Session 3",
    "section": "",
    "text": "TBD",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 3"
    ]
  },
  {
    "objectID": "contents/sessions/10.html",
    "href": "contents/sessions/10.html",
    "title": "Session 10",
    "section": "",
    "text": "Lernziele:\n\nGrundverständnis der KI-Governance entwickeln\nDie Notwendigkeit und Herausforderungen einer umfassenden KI-Regulierung erklären können\nDie zentralen Risiken unregulierter KI-Systeme reflektieren.\nDen EU AI Act kritisch analysieren können\nDie vier Risikokategorien des EU AI Acts verstehen und anwenden können.\nAnhand konkreter Fallbeispiele Stärken und Schwächen des Gesetzes bewerten.\nDen EU-Ansatz mit den Regulierungsmodellen der Niederlande und des UK vergleichen.\nDie Schweizer Position zur KI-Regulierung einordnen\nDie aktuelle Haltung des Bundesrats zur KI-Regulierung kennen.\nDie bestehenden rechtlichen Rahmenbedingungen (z. B. Datenschutzgesetz) erläutern.\nDen Unterschied zwischen der Schweizer und der EU-Regulierung kritisch hinterfragen.\nTheoretische und normative Perspektiven auf KI-Governance reflektieren\n\nEinführung: Warum braucht es eine umfassende KI-Governance? (45 Minuten)\n1.     Definition von KI-Governance: Regeln, Normen und Institutionen zur Regulierung von KI-Systemen.\n2.     Herausforderungen: Bias, Transparenz, Verantwortung, gesellschaftliche Auswirkungen.\n3.     Diskussion mit Studierenden: Welche Risiken seht ihr bei unregulierter KI?\nTeil 1: Der EU AI Act – Chancen und Grenzen\nA. Überblick über den EU AI Act (25 Minuten)\n1.     Ziel: Risikobasierte Regulierung von KI.\n2.     Vier Risikokategorien: Unzulässig, Hochrisiko, Begrenztes Risiko, Minimales Risiko.\n3.     Diskussion der aktuellen Entwicklungen (basierend auf artificialintelligenceact.eu).\nB. Fallbeispiele zu jeder Risikokategorie (5 Minuten)\n1.     Unzulässige KI: Biometrische Massenüberwachung – Warum ist sie verboten?\n2.     Hochrisiko-KI: Automatisierte Kreditwürdigkeitsprüfungen – Chancen & Gefahren.\n3.     Begrenztes Risiko: KI-gestützte Chatbots – Anforderungen an Transparenz.\n4.     Minimales Risiko: Empfehlungssysteme in sozialen Medien – freiwillige Standards.\nC. Vergleichende Betrachtung: Niederlande und UK (15 Minuten)\n1.     Niederlande: Fokus auf menschenzentrierte KI, Algorithmenregister.\n2.     UK: Leichtgewichtiges, auf Prinzipien basierendes Framework.\n3.     Diskussion: Unterschiede und mögliche Lehren für die EU.\nTeil 2: KI-Governance in der Schweiz (Stand: März 2025) (45 Minuten)\nA. Politische Position des Bundesrats (15 Minuten)\n1.     Aktuelle Haltung zur KI-Regulierung.\n2.     Unterschiede zur EU-Politik: Warum setzt die Schweiz auf einen anderen Ansatz?\n3.     Quelle und Diskussion: AlgorithmWatch-Analyse zur Schweizer KI-Politik.\nB. Bestehende Rahmenbedingungen (15)\n1.     Datenschutzgesetz (DSG) und seine Relevanz für KI.\n2.     Selbstregulierungsinitiativen und freiwillige Standards.\n3.     Abdeckung durch bestehende Gesetze vs. Bedarf für neue Regulierung.\nAbschlussdiskussion & Fazit (15 Minuten)\n1.     Vergleich EU – Schweiz – UK/Niederlande: Welche Ansätze sind vielversprechend?\n2.     Welche offenen Fragen bestehen in der KI-Governance?\n3.     Studierendenperspektiven: Wie sollte KI in der Schweiz reguliert werden?\nLeseauftrag:\n\n(“EU Artificial Intelligence Act | Up-to-date Developments and Analyses of the EU AI Act” n.d.)\n(“AlgorithmWatch” n.d.)\n\nWeiterführende Literatur:\n\n(Mueller 2025)\n\n\n\n\n\n Back to topReferences\n\n“AlgorithmWatch.” n.d. AlgorithmWatch. Accessed November 25, 2024. https://algorithmwatch.org/de/.\n\n\n“EU Artificial Intelligence Act | Up-to-date Developments and Analyses of the EU AI Act.” n.d. Accessed November 25, 2024. https://artificialintelligenceact.eu/.\n\n\nMueller, Milton L. 2025. “It’s Just Distributed Computing: Rethinking AI Governance.” Telecommunications Policy, February, 102917. https://doi.org/10.1016/j.telpol.2025.102917.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 10"
    ]
  },
  {
    "objectID": "contents/sessions/05.html",
    "href": "contents/sessions/05.html",
    "title": "Session 5",
    "section": "",
    "text": "Lernziele:\n1.     Entwicklung und Herausforderungen von Rekrutierungsalgorithmen​\n2.     Die Studierenden sollen verstehen, wie Rekrutierungsalgorithmen entwickelt werden,\n3.     Die Studierenden sollen verstehen, wie sie zu ihren Ergebnissen gelangen, warum sie diskriminieren können und weshalb algorithmische Diskriminierung problematischer sein kann als menschliche Diskriminierung.​\nGliederung der Unterrichtseinheit:\nTeil 1: Entwicklung und Funktionsweise von Rekrutierungsalgorithmen (45 Minuten)\n1.     Einführung in Rekrutierungsalgorithmen (15 Minuten)\n1.1.   Definition und Überblick über den Einsatz von KI im Personalwesen.​\n1.2.   Vorteile der Automatisierung im Rekrutierungsprozess, wie Effizienzsteigerung und Bearbeitung großer Bewerberzahlen.​\n2.     Technische Grundlagen (20 Minuten)\n2.1.   Datenquellen und Trainingsdaten: Wie Algorithmen mit historischen Bewerberdaten trainiert werden.​\n2.2.   Merkmalsauswahl und -gewichtung: Welche Kriterien der Algorithmus zur Bewertung von Kandidaten heranzieht.​\n2.3.   Entscheidungsfindung: Wie der Algorithmus Bewerber einstuft und Empfehlungen ausspricht.​\n3.     Fallbeispiel 1: Amazon’s Rekrutierungsalgorithmus (10 Minuten)\n3.1.   Beschreibung des Falls: Amazon entwickelte einen KI-basierten Rekrutierungsalgorithmus, der männliche Bewerber bevorzugte.​SpringerLink+1Reuters+1\n3.2.   Analyse der Ursachen: Der Algorithmus wurde mit historischen Daten trainiert, die eine männliche Dominanz widerspiegelten, was zur Diskriminierung weiblicher Bewerber führte.​\n3.3.   Diskussion der Konsequenzen und der Entscheidung, das Projekt einzustellen.​\nTeil 2: Diskriminierungspotenzial von Rekrutierungsalgorithmen und Vergleich zur menschlichen Diskriminierung (45 Minuten)\n1.     Ursachen algorithmischer Diskriminierung (15 Minuten)\n1.1.   Verzerrte Trainingsdaten: Wie historische Vorurteile in Daten zu diskriminierenden Ergebnissen führen können.​\n1.2.   Fehlerhafte Merkmalsauswahl: Wenn der Algorithmus irrelevante oder proxybasierte Merkmale verwendet, die zu indirekter Diskriminierung führen.​\n2.     Vergleich: Algorithmische vs. menschliche Diskriminierung (15 Minuten)\n2.1.   Skalierbarkeit: Algorithmen können Diskriminierung systematisch und in großem Umfang reproduzieren.​\n2.2.   Transparenz: Entscheidungen von Algorithmen sind oft weniger nachvollziehbar als menschliche Entscheidungen.​\n2.3.   Verantwortlichkeit: Schwierigkeiten bei der Zuweisung von Verantwortung für diskriminierende algorithmische Entscheidungen.​\n3.     Fallbeispiel 2: Facebooks Jobanzeige-Algorithmus (10 Minuten)\n3.1.   Beschreibung des Falls: Ein Audit zeigte, dass Facebooks Algorithmus Jobanzeigen basierend auf Geschlecht unterschiedlich ausspielte, was zu geschlechtsspezifischer Diskriminierung führte.​\n3.2.   Analyse der Ursachen: Der Algorithmus optimierte Anzeigenplatzierungen basierend auf Nutzerinteraktionen, was bestehende Geschlechterstereotypen verstärkte.​\n3.3.   Diskussion der ethischen Implikationen und möglicher Gegenmaßnahmen.​\n4.     Diskussionsfragen für Gruppendiskussion (5 Minuten)\n4.1.   Inwiefern können Versuche, Geschlecht und Ethnie aus Rekrutierungsalgorithmen zu entfernen, zu neuen Formen der Diskriminierung führen?​\n4.2.   Wie können Organisationen sicherstellen, dass der Einsatz von KI im Rekrutierungsprozess nicht bestehende Ungleichheiten verstärkt, sondern zu mehr Fairness beiträgt?​\nVorbereitende Lektüre:\n\n(Chen 2023)\n(Drage and Mackereth 2022)\n\n\n\n\n\n Back to topReferences\n\nChen, Zhisheng. 2023. “Ethics and Discrimination in Artificial Intelligence-Enabled Recruitment Practices.” Humanities and Social Sciences Communications 10 (1): 1–12. https://doi.org/10.1057/s41599-023-02079-x.\n\n\nDrage, Eleanor, and Kerry Mackereth. 2022. “Does AI Debias Recruitment? Race, Gender, and AI’s ‘Eradication of Difference’.” Philosophy & Technology 35 (4): 89. https://doi.org/10.1007/s13347-022-00543-1.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 5"
    ]
  },
  {
    "objectID": "contents/sessions/06.html",
    "href": "contents/sessions/06.html",
    "title": "Session 6",
    "section": "",
    "text": "Lernziele:\n\nDie Vorteile Fernerkennungssysteme zur Erhöhung der Sicherheit vulnerabler Personen verstehen.\nDie Risiken von biometrischen Erkennungssystemen wie Gesichtserkennung in Bezug auf Datenschutz, Grundrechte und Diskriminierung reflektieren.\nDie rechtliche und politische Lage der Gesichtserkennung in der Schweiz analysieren.\nUnterscheidung zwischen biometrischen Erkennungssystemen wie Gesichtserkennung und dem Fernerkennen von Personenströmen im öffentlichen Raum.\nRisiken und Vorteile im Kontext von Verfassungsrecht, Datenschutz und Menschenrechte diskutieren\n\nGliederung der Unterrichtseinheit:\n1. Einführung (10 Min.)\n\nÜberblick über die Sitzung.\nEinführung in biometrische Systeme: Definition und Anwendungsbereiche.\nDarstellung der zentralen Fragestellung:\n\n\n„Können Fernerkennungssysteme überhaupt Sicherheit bieten, ohne Grundrechte zu gefährden und Diskriminierung zu reproduzieren?“\n\n2. Technologische und ethische Grundlagen (35 Min.)\n\nPräsentation der Forschung von Buolamwini & Gebru:\n\n1.1. Bias in Gesichtserkennungsalgorithmen.\n1.2. Diskriminierung gegenüber Frauen und nicht-weißen Personen.\n1.3. Auswirkungen auf gesellschaftliche Gruppen.\n1.4. Lösungen der Autorinnen für fairere Gesichtserkennungssysteme herausarbeiten.\n1.5. Impact der Forschung der beiden Autorinnen auf die Entwicklung dieser KI (wie haben Microsoft und Google darauf reagiert?)\n\nÜberleitung zur aktuellen Forschung:\n\n2.1. Fortschritte in der KI zur Reduktion von Bias in Gesichtserkennung.\n2.2. Kritik an der Transparenz und Nachvollziehbarkeit solcher Systeme.\n2.3. Fallbeispiele aus anderen Ländern (z. B. London, China).\n2.4. Fallbeispiele aus der Schweiz?\n3. Rechtliche und politische Situation in der Schweiz (20 Min.)\n\nGesetzliche Rahmenbedingungen:\n\n1.1. Datenschutzgesetz (DSG) und EU-Einfluss (DSGVO).\n1.2. Öffentliche Überwachung und Gesichtserkennung: aktuelle Regelungen.\n1.3. Diskussion über Haltung des Bundesrates und geplante Gesetzesänderungen.\n\nPolitische Debatte:\n\n2.1. Argumente von Datenschutzorganisationen vs. Sicherheitsbehörden.\n2.2. Öffentliche Wahrnehmung und gesellschaftlicher Diskurs in der Schweiz.\n2.3. Kantonale Entwicklungen und Anwendungen (beispielsweise bei kantonalen Polizeibehörden wie im Aargau)\n4. Interaktive Gruppenarbeit (15 Min.)\n\nFallstudienanalyse: Studierende diskutieren in Gruppen:\n\n1.1. Fall 1: Erfassen der Kundenströmen an Bahnhöfen zur Erhöhung der Sicherheit von Frauen.\n1.2. Fall 2: Massenüberwachung durch biometrische Systeme in Innenstädten.\n\nReflexion: Wo verläuft die Grenze zwischen Sicherheit und Überwachung? Wie werden Grundrechte beschnitten? Gibt es Alternativen zu biometrischen Fernerkennungssystemen, die ebenfalls zur Sicherheit von gefährdeten Personen wie Frauen beitragen, ohne geltendes Recht und persönliche Rechte zu beschneiden?\n\n5. Abschlussdiskussion und Fazit (10 Min.)\n\nOffene Fragen und ethische Dilemmata.\nAbschlussfrage: „Wie sollten Staaten mit Gesichtserkennung umgehen?“\n\nVorbereitete Lektüre:\n\n(Buolamwini and Gebru 2018)\nGesichtserkennung in der Schweiz: https://algorithmwatch.ch/de/tag/gesichtserkennung/\n\nWeiterführende Medien:\n\nFilm Coded Bias von Shalini Kantayya, 2020 7th Empire Media\n(Zuboff 2017)\n https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.\n\n\n\n\n\n Back to topReferences\n\nBuolamwini, Joy, and Timnit Gebru. 2018. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.” In Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 77–91. PMLR. https://proceedings.mlr.press/v81/buolamwini18a.html.\n\n\nZuboff, Shoshana. 2017. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. First trade paperback edition. New York, NY: PublicAffairs. https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 6"
    ]
  },
  {
    "objectID": "contents/sessions/09.html",
    "href": "contents/sessions/09.html",
    "title": "Session 9",
    "section": "",
    "text": "Recap\nLeseauftrag gemeinsam anschauen\nEvaluation and Monitoring diskutieren\n\n\n\nmündlich\n\n\n\nThis study proposes a novel framework for evaluating social biases—particularly gender and ethnicity—in Text-to-Image (TTI) systems, including DALL·E 2 and Stable Diffusion (v1.4 and v2). A central challenge is that synthetic images lack inherent social identity, making conventional bias assessment difficult. The authors address this through a structured, two-part evaluation approach:\n\n\n\nPrompt Design: Generated images using structured prompts incorporating gender and ethnicity markers (e.g., “photo portrait of a Black woman at work”) across 146 professions, based on U.S. labor statistics.\nBias Analysis:\n\nText-Based: Employed image captioning and Visual Question Answering (VQA) models to extract demographic indicators.\nVisual-Based: Clustered image embeddings to detect representational patterns associated with social identity markers.\n\n\n\n\n\n\nAll three diffusion models reflect societal labor demographics but consistently underrepresent marginalized groups—particularly women and Black individuals.\nDALL·E 2 showed the least diversity and most significant under-representation; Stable Diffusion v1.4 was more balanced.\nGender-neutral and non-binary representations were nearly absent.\nClustering of visual outputs revealed that depictions were disproportionately aligned with stereotypes of White men.\n\n\n\n\n\nDeveloped interactive tools (Diffusion Bias Explorer, Average Face Comparison, k-NN Explorer) for qualitative and quantitative bias analysis.\nReleased public datasets and low-code toolkits to support reproducibility and further research.\n\n\n\n\n\nRelied on captioning and VQA models that may themselves be biased.\nLimited access to proprietary models (e.g., DALL·E 2) restricted deeper audits.\nFocused primarily on U.S.-centric conceptions of race and gender.\n\n\n\n\nThe paper offers a scalable framework for auditing societal biases in generative image systems and advocates for multidimensional, culturally-aware model evaluations in future research and deployment.\n\n\n\n\nThis survey provides a comprehensive synthesis of research on bias and fairness in machine learning (ML), addressing how bias emerges, how fairness is conceptualized, and how both can be mitigated. It frames these issues through a data-algorithm-user feedback loop, categorizing bias accordingly.\n\n\n\nData Bias: Includes measurement bias, sampling bias, aggregation bias (e.g., Simpson’s Paradox), omitted variable bias, and representation bias.\nAlgorithmic Bias: Introduced during model design or optimization, independent of training data quality.\nUser Bias: Emerges from user interactions, feedback loops, popularity effects, and interface design.\n\n\n\n\n\nDirect Discrimination: Decisions explicitly use protected attributes (e.g., race, gender).\nIndirect Discrimination: Use of correlated variables (e.g., zip code) that serve as proxies.\nSystemic and Statistical Discrimination: Result from institutional or heuristic biases.\n\n\n\n\n\nGroup Fairness: Equalized odds, equal opportunity, demographic parity.\nIndividual Fairness: Similar individuals receive similar treatment.\nSubgroup Fairness: Ensures parity across intersectional subgroups.\nCounterfactual Fairness: Outcomes remain invariant under changes to sensitive attributes.\n\n\n\n\n\nPre-processing: Modify datasets to remove or minimize bias.\nIn-processing: Integrate fairness constraints directly into model training.\nPost-processing: Adjust predictions after model training for fairness.\n\n\n\n\n\nNLP: Debiasing word embeddings and language models.\nComputer Vision: Fair face recognition and demographic representation.\nHealthcare: Risks due to underrepresentation in clinical and genomic datasets.\nSocial Networks: Addressing bias in community detection and graph algorithms.\nCausal Inference: Use of causal graphs to detect and mitigate discrimination.\n\n\n\n\n\nTechniques include adversarial learning, variational autoencoders, and disentangled representation learning aimed at isolating or suppressing sensitive attributes.\n\n\n\n\n\nToolkits like AIF360 and Aequitas provide standardized metrics and visualizations for fairness assessment.\nCritiques of mainstream datasets (e.g., ImageNet, OpenImages) highlight representation imbalances.\n\n\n\n\n\nTrade-offs between fairness, accuracy, and interpretability are often unavoidable.\nFairness is inherently contextual and cannot be universally defined or enforced.\nThe survey advocates for temporal, cultural, and application-specific frameworks and emphasizes the importance of continual monitoring.\n\n\n\n\nThe paper presents a thorough and nuanced exploration of algorithmic bias and fairness. It underscores the systemic and recursive nature of these challenges and calls for interdisciplinary methods, transparent standards, and ongoing auditing in ML system design and evaluation.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 9"
    ]
  },
  {
    "objectID": "contents/sessions/09.html#recap",
    "href": "contents/sessions/09.html#recap",
    "title": "Session 9",
    "section": "",
    "text": "mündlich",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 9"
    ]
  },
  {
    "objectID": "contents/sessions/09.html#summary-of-stable-bias-evaluating-societal-representations-in-diffusion-models",
    "href": "contents/sessions/09.html#summary-of-stable-bias-evaluating-societal-representations-in-diffusion-models",
    "title": "Session 9",
    "section": "",
    "text": "This study proposes a novel framework for evaluating social biases—particularly gender and ethnicity—in Text-to-Image (TTI) systems, including DALL·E 2 and Stable Diffusion (v1.4 and v2). A central challenge is that synthetic images lack inherent social identity, making conventional bias assessment difficult. The authors address this through a structured, two-part evaluation approach:\n\n\n\nPrompt Design: Generated images using structured prompts incorporating gender and ethnicity markers (e.g., “photo portrait of a Black woman at work”) across 146 professions, based on U.S. labor statistics.\nBias Analysis:\n\nText-Based: Employed image captioning and Visual Question Answering (VQA) models to extract demographic indicators.\nVisual-Based: Clustered image embeddings to detect representational patterns associated with social identity markers.\n\n\n\n\n\n\nAll three diffusion models reflect societal labor demographics but consistently underrepresent marginalized groups—particularly women and Black individuals.\nDALL·E 2 showed the least diversity and most significant under-representation; Stable Diffusion v1.4 was more balanced.\nGender-neutral and non-binary representations were nearly absent.\nClustering of visual outputs revealed that depictions were disproportionately aligned with stereotypes of White men.\n\n\n\n\n\nDeveloped interactive tools (Diffusion Bias Explorer, Average Face Comparison, k-NN Explorer) for qualitative and quantitative bias analysis.\nReleased public datasets and low-code toolkits to support reproducibility and further research.\n\n\n\n\n\nRelied on captioning and VQA models that may themselves be biased.\nLimited access to proprietary models (e.g., DALL·E 2) restricted deeper audits.\nFocused primarily on U.S.-centric conceptions of race and gender.\n\n\n\n\nThe paper offers a scalable framework for auditing societal biases in generative image systems and advocates for multidimensional, culturally-aware model evaluations in future research and deployment.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 9"
    ]
  },
  {
    "objectID": "contents/sessions/09.html#summary-of-a-survey-on-bias-and-fairness-in-machine-learning-by-mehrabi-et-al.-2021",
    "href": "contents/sessions/09.html#summary-of-a-survey-on-bias-and-fairness-in-machine-learning-by-mehrabi-et-al.-2021",
    "title": "Session 9",
    "section": "",
    "text": "This survey provides a comprehensive synthesis of research on bias and fairness in machine learning (ML), addressing how bias emerges, how fairness is conceptualized, and how both can be mitigated. It frames these issues through a data-algorithm-user feedback loop, categorizing bias accordingly.\n\n\n\nData Bias: Includes measurement bias, sampling bias, aggregation bias (e.g., Simpson’s Paradox), omitted variable bias, and representation bias.\nAlgorithmic Bias: Introduced during model design or optimization, independent of training data quality.\nUser Bias: Emerges from user interactions, feedback loops, popularity effects, and interface design.\n\n\n\n\n\nDirect Discrimination: Decisions explicitly use protected attributes (e.g., race, gender).\nIndirect Discrimination: Use of correlated variables (e.g., zip code) that serve as proxies.\nSystemic and Statistical Discrimination: Result from institutional or heuristic biases.\n\n\n\n\n\nGroup Fairness: Equalized odds, equal opportunity, demographic parity.\nIndividual Fairness: Similar individuals receive similar treatment.\nSubgroup Fairness: Ensures parity across intersectional subgroups.\nCounterfactual Fairness: Outcomes remain invariant under changes to sensitive attributes.\n\n\n\n\n\nPre-processing: Modify datasets to remove or minimize bias.\nIn-processing: Integrate fairness constraints directly into model training.\nPost-processing: Adjust predictions after model training for fairness.\n\n\n\n\n\nNLP: Debiasing word embeddings and language models.\nComputer Vision: Fair face recognition and demographic representation.\nHealthcare: Risks due to underrepresentation in clinical and genomic datasets.\nSocial Networks: Addressing bias in community detection and graph algorithms.\nCausal Inference: Use of causal graphs to detect and mitigate discrimination.\n\n\n\n\n\nTechniques include adversarial learning, variational autoencoders, and disentangled representation learning aimed at isolating or suppressing sensitive attributes.\n\n\n\n\n\nToolkits like AIF360 and Aequitas provide standardized metrics and visualizations for fairness assessment.\nCritiques of mainstream datasets (e.g., ImageNet, OpenImages) highlight representation imbalances.\n\n\n\n\n\nTrade-offs between fairness, accuracy, and interpretability are often unavoidable.\nFairness is inherently contextual and cannot be universally defined or enforced.\nThe survey advocates for temporal, cultural, and application-specific frameworks and emphasizes the importance of continual monitoring.\n\n\n\n\nThe paper presents a thorough and nuanced exploration of algorithmic bias and fairness. It underscores the systemic and recursive nature of these challenges and calls for interdisciplinary methods, transparent standards, and ongoing auditing in ML system design and evaluation.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus",
      "Session 9"
    ]
  },
  {
    "objectID": "contents/syllabus.html",
    "href": "contents/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Formen der Diskriminierung (Rachel Huber): Workshop, Hands-on Session\nLeseauftrag:\n\nKein Leseauftrag, da Workshop.\n\nWeiterführende Literatur:\n\nCatherine D’Ignazio und Lauren F. Klein, Data Feminism, First MIT Press paperback edition (Cambridge, Massachusetts: The MIT Press, 2023), https://data-feminism.mitpress.mit.edu/.\n\n\n\n\nArchitecture (Moritz Mähr): Gegenüberstellung von wie Computer Scientist über Architekturentscheide sprechen vs. Humanities Scholars\nLeseauftrag:\n\nFabian Offert und Ranjodh Singh Dhaliwal, «The Method of Critical AI Studies, A Propaedeutic», 10. Dezember 2024, https://doi.org/10.48550/arXiv.2411.18833.\n\nWeiterführende Literatur:\n\nDuri Long und Brian Magerko, «What Is AI Literacy? Competencies and Design Considerations», in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, CHI ’20 (New York, NY, USA: Association for Computing Machinery, 2020), 1–16, https://doi.org/10.1145/3313831.3376727.\n\n\n\n\nCollecting Data (Moritz Mähr)\nLeseauftrag:\n\nKapitel 3 aus Yanni A. Loukissas, All Data Are Local: Thinking Critically in a Data-Driven Society (Cambridge, Massachusetts: The MIT Press, 2019), https://doi.org/10.7551/mitpress/11543.001.0001.\n\n\n\n\nTraining (Moritz Mähr): Environmental impact of training AI\nLeseauftrag:\n\nAlexandre Lacoste u. a., «Quantifying the Carbon Emissions of Machine Learning», 4. November 2019, https://doi.org/10.48550/arXiv.1910.09700.\n\nWeiterführende Literatur:\n\nLong Ouyang u. a., «Training Language Models to Follow Instructions with Human Feedback», 4. März 2022, https://doi.org/10.48550/arXiv.2203.02155.\n\n\n\n\nApplication (Recruiting) (Rachel Huber)\nLeseauftrag:\n\nZhisheng Chen, «Ethics and Discrimination in Artificial Intelligence-Enabled Recruitment Practices», Humanities and Social Sciences Communications 10, Nr. 1 (13. September 2023): 1–12, https://doi.org/10.1057/s41599-023-02079-x.\nEleanor Drage und Kerry Mackereth, «Does AI Debias Recruitment? Race, Gender, and AI’s ‹Eradication of Difference›», Philosophy & Technology 35, Nr. 4 (Dezember 2022): 89, https://doi.org/10.1007/s13347-022-00543-1.\n\n\n\n\nApplication (CCTV/Facial Recognition) (Rachel Huber)\nLeseauftrag:\n\nJoy Buolamwini und Timnit Gebru, «Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification», in Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Conference on Fairness, Accountability and Transparency, PMLR, 2018), 77–91, https://proceedings.mlr.press/v81/buolamwini18a.html.\n\nWeiterführende Literatur:\n\nShoshana Zuboff, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power, First trade paperback edition (New York, NY: PublicAffairs, 2017), https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.\n\n\n\n\nApplication (Predictive Policing/Migrationsalgo CH …) (Rachel Huber)\nLeseauftrag:\n\nLauren Kirchner Mattu Jeff Larson, «Machine Bias» (ProPublica), zugegriffen 25. November 2024, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n«Jobs für Flüchtlinge - Algorithmus verteilt neu Asylbewerber auf Kantone» (Schweizer Radio und Fernsehen (SRF), 10. Mai 2018), https://www.srf.ch/news/schweiz/jobs-fuer-fluechtlinge-algorithmus-verteilt-neu-asylbewerber-auf-kantone.\n«Algorithmus verbessert Erwerbschancen von Flüchtlingen» (ETH Zürich, 18. Januar 2018), https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/01/algorithmus-verbessert-erwerbschancen-von-fluechtlingen.html.\n\nWeiterführende Literatur:\n\nKirk Bansak u. a., «Improving Refugee Integration through Data-Driven Algorithmic Assignment», Science 359, Nr. 6373 (19. Januar 2018): 325–29, https://doi.org/10.1126/science.aao4408.\n\n\n\n\nApplication (ChatGPT) (Moritz Mähr)\nLeseauftrag:\n\nEmily M. Bender u. a., «On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜», in Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT ’21 (New York, NY, USA: Association for Computing Machinery, 2021), 610–23, https://doi.org/10.1145/3442188.3445922.\n\nWeiterführende Literatur:\n\nTed Chiang, «ChatGPT Is a Blurry JPEG of the Web», The New Yorker, 9. Februar 2023, https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web.\nDeep Dive into LLMs Like ChatGPT, 2025, https://www.youtube.com/watch?v=7xTGNNLPyMI.\n\n\n\n\nEvaluation and Monitoring (Moritz Mähr)\n\nLeseauftrag:\n\nAlexandra Sasha Luccioni u. a., «Stable Bias: Analyzing Societal Representations in Diffusion Models», 9. November 2023, https://doi.org/10.48550/arXiv.2303.11408.\nNinareh Mehrabi u. a., «A Survey on Bias and Fairness in Machine Learning», ACM Comput. Surv. 54, Nr. 6 (13. Juli 2021): 115:1–35, https://doi.org/10.1145/3457607.\n\n\n\n\nGovernance and Regulation (Rachel Huber)\nLeseauftrag:\n\n«EU Artificial Intelligence Act | Up-to-Date Developments and Analyses of the EU AI Act», zugegriffen 25. November 2024, https://artificialintelligenceact.eu/.\n«AlgorithmWatch» (AlgorithmWatch), zugegriffen 25. November 2024, https://algorithmwatch.org/de/.\n\nWeiterführende Literatur:\n\nMilton L. Mueller, «It’s Just Distributed Computing: Rethinking AI Governance», Telecommunications Policy, Februar 2025, 102917, https://doi.org/10.1016/j.telpol.2025.102917.\n\n\n\n\nPoster/Blog/Presentations\nLeseauftrag:\n\nCathy O’Neil, Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, First edition (New York: Crown Publishing Group, 2016).\n\n\n\n\nPoster/Blog/Presentations oder Glüehfisch mit Wichtel*in\nLeseauftrag:\n\nKein Leseauftrag\n\n\n\n\n\nDer Kurs wird mit Bestanden/Nicht Bestanden (Pass/Fail) bewertet. Für den Leistungsnachweis stehen drei gleichwertige Formate zur Auswahl: Blogbeitrag, Poster oder Vortrag. Alle drei Optionen werden als gleichwertig betrachtet und nach den gleichen Kriterien beurteilt, sodass Sie das Format wählen können, das am besten zu Ihren Stärken passt. In allen Fällen geht es darum, ein Thema des Kurses selbstständig zu bearbeiten und verständlich aufzubereiten.\n\n\nEin Blogbeitrag ist ein (wahlweise) online veröffentlichter, schriftlicher Artikel, der ein Kursthema in verständlicher und ansprechender Form für eine breite Leserschaft aufbereitet. Dieses Format bietet Ihnen die Möglichkeit, komplexe Inhalte in einem populärwissenschaftlichen Stil zu vermitteln. Beachten Sie dabei, dass ein Blogtext keine formelle Hausarbeit ist – der Ton darf lockerer sein, doch die inhaltliche Qualität und Fachlichkeit sollen trotzdem gewährleistet sein (Wie schreibe ich einen Blogeintrag?). Wichtig ist, die Aufmerksamkeit der Leserinnen und Leser von Anfang bis Ende zu gewinnen und zu halten – etwa durch einen persönlichen Zugang, anschauliche Beispiele, einen eingängigen Schreibstil sowie das Einbinden von weiterführenden Links. Auf diese Weise können Sie Ihr Fachwissen einem interessierten Publikum effektiv und unterhaltsam näherbringen.\n\n\n\nEin Poster ist ein wissenschaftliches Plakat, auf dem ein Thema visuell ansprechend und in prägnanter Kürze dargestellt wird (Wissenschaftliches Poster: Tipps + Beispiel). Auf dem Poster fassen Sie die wichtigsten Erkenntnisse oder Kernideen Ihres gewählten Themas so zusammen, dass sie auf einen Blick erfassbar sind. Ein gutes Poster enthält insbesondere die folgenden Elemente (in gekürzter Form):\n\nTitel und Einführung: Ein prägnanter Titel sowie eine kurze Einführung ins Thema (Fragestellung und Kontext).\nMethode und Ergebnisse: Die Darstellung des Vorgehens bzw. der Methode und die zentralen Ergebnisse (unterstützt durch Grafiken oder Abbildungen).\nFazit und Quellen: Ein Schlussfazit (ggf. mit Ausblick) sowie die Angabe der wichtigsten Quellen.\n\nDiese Inhalte sollten klar strukturiert und optisch übersichtlich präsentiert werden. Das Poster wird idealerweise im Grossformat (z. B. A0) erstellt, damit Text und Abbildungen auch aus einiger Entfernung gut lesbar sind. In der Regel präsentieren Sie Ihr Poster auch mündlich im Kurs, daher lohnt es sich, das Poster übersichtlich zu gestalten und sich auf mögliche Nachfragen vorzubereiten.\n\n\n\nEin Vortrag ist eine mündliche Präsentation eines Kursthemas vor Publikum im Kurs, typischerweise von 10 bis 15 Minuten Dauer, in der Sie das gewählte Thema in eigenen Worten erklären und die Zuhörenden mit einem klar strukturierten Aufbau – Einleitung, Hauptteil, Schluss – durch die wichtigsten Punkte führen (Präsentation im Studium halten - So klappt’s! | Studieren.at. Ein guter Vortrag folgt einem roten Faden und bereitet die Inhalte verständlich für das Publikum auf. Achten Sie dabei auf eine deutliche, nicht zu schnelle Aussprache und halten Sie Blickkontakt mit den Zuhörenden. Visuelle Hilfsmittel (z. B. Folien) sollten übersichtlich gestaltet sein und nur zur Unterstützung dienen – lesen Sie also nicht einfach Ihren Text ab. Rechnen Sie ausserdem mit Fragen im Anschluss und seien Sie bereit, diese kompetent zu beantworten.\n\n\n\n\nWie schreibe ich einen Blogeintrag? (Wie schreibe ich einen Blogeintrag? – Korpora zur Analyse von Sprache und Kontext) – Praktische Anleitung zum wissenschaftlichen Bloggen (Uni Basel).\nMein erster wissenschaftlicher Blogartikel – was schreibe ich bloß? (Mein erster wissenschaftlicher Blogartikel – was schreibe ich bloß? – Redaktionsblog) – Erfahrungsbericht und Tipps für den ersten Blogpost (Sabine Scherz, Redaktionsblog).\nEssay Einleitung: Grundlagen, Tipps & Expertenhilfe (Essay Einleitung: Grundlagen, Tipps & Expertenhilfe von StudiBucht.) – Hinweise zum Aufbau einer guten Einführung (Struktur, fesselnder Einstieg), übertragbar auch auf andere Formate.\nhttps://blog.front-matter.io/posts/rogue-scholar-authorship-guidelines/ https://doi.org/10.53731/fnv8b-qfy78\n\n\n\n\n\n\n\n\n\n\n\nHinweis: Urheberrecht\n\n\n\nWir bemühen uns, frei zugängliche Literatur zu verwenden. Sollte dies nicht möglich sein, bitten wir Sie, die Literatur über die Bibliotheksplattform swisscovery zu beziehen. Von der Verwendung von Plattformen wie Library Genesis raten wir trotz stichhaltiger Argumente ab.\nSiehe Joe Karaganis, Hrsg. Shadow Libraries: Access to Knowledge in Global Higher Education, International Development Research Centre (Cambridge: The MIT Press, 2018), https://doi.org/10.7551/mitpress/11339.001.0001.\n\n\n\n\n«Algorithms of Oppression». In Wikipedia, 28. Juni 2022. https://en.wikipedia.org/w/index.php?title=Algorithms_of_Oppression&oldid=1095369660.\n\n\n«Algorithmus verbessert Erwerbschancen von Flüchtlingen». ETH Zürich, 18. Januar 2018. https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/01/algorithmus-verbessert-erwerbschancen-von-fluechtlingen.html.\n\n\n«AlgorithmWatch». AlgorithmWatch. Zugegriffen 25. November 2024. https://algorithmwatch.org/de/.\n\n\nAlma’aitah, Wafa’ Za’al, Abdullah Zawawi Talib, und Mohd Azam Osman. «Opportunities and Challenges in Enhancing Access to Metadata of Cultural Heritage Collections: A Survey». Artificial Intelligence Review 53, Nr. 5 (1. Juni 2020): 3621–46. https://doi.org/10.1007/s10462-019-09773-w.\n\n\nBansak, Kirk, Jeremy Ferwerda, Jens Hainmueller, Andrea Dillon, Dominik Hangartner, Duncan Lawrence, und Jeremy Weinstein. «Improving Refugee Integration through Data-Driven Algorithmic Assignment». Science 359, Nr. 6373 (19. Januar 2018): 325–29. https://doi.org/10.1126/science.aao4408.\n\n\nBender, Emily M., Timnit Gebru, Angelina McMillan-Major, und Shmargaret Shmitchell. «On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜». In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610–23. FAccT ’21. New York, NY, USA: Association for Computing Machinery, 2021. https://doi.org/10.1145/3442188.3445922.\n\n\nBuolamwini, Joy. Unmasking AI: A Story of Hope and Justice in a World of Machines. First edition. New York: Random House, 2023.\n\n\nBuolamwini, Joy, und Timnit Gebru. «Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification». In Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 77–91. PMLR, 2018. https://proceedings.mlr.press/v81/buolamwini18a.html.\n\n\nChen, Zhisheng. «Ethics and Discrimination in Artificial Intelligence-Enabled Recruitment Practices». Humanities and Social Sciences Communications 10, Nr. 1 (13. September 2023): 1–12. https://doi.org/10.1057/s41599-023-02079-x.\n\n\nChiang, Ted. «ChatGPT Is a Blurry JPEG of the Web». The New Yorker, 9. Februar 2023. https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web.\n\n\nD’Ignazio, Catherine, und Lauren F. Klein. Data Feminism. First MIT Press paperback edition. Cambridge, Massachusetts: The MIT Press, 2023. https://data-feminism.mitpress.mit.edu/.\n\n\nDeep Dive into LLMs Like ChatGPT, 2025. https://www.youtube.com/watch?v=7xTGNNLPyMI.\n\n\nDrage, Eleanor, und Kerry Mackereth. «Does AI Debias Recruitment? Race, Gender, and AI’s ‹Eradication of Difference›». Philosophy & Technology 35, Nr. 4 (Dezember 2022): 89. https://doi.org/10.1007/s13347-022-00543-1.\n\n\n«EU Artificial Intelligence Act | Up-to-Date Developments and Analyses of the EU AI Act». Zugegriffen 25. November 2024. https://artificialintelligenceact.eu/.\n\n\n«Jobs für Flüchtlinge - Algorithmus verteilt neu Asylbewerber auf Kantone». Schweizer Radio und Fernsehen (SRF), 10. Mai 2018. https://www.srf.ch/news/schweiz/jobs-fuer-fluechtlinge-algorithmus-verteilt-neu-asylbewerber-auf-kantone.\n\n\nKaraganis, Joe, Hrsg. Shadow Libraries: Access to Knowledge in Global Higher Education. International Development Research Centre. Cambridge: The MIT Press, 2018. https://doi.org/10.7551/mitpress/11339.001.0001.\n\n\nLacoste, Alexandre, Alexandra Luccioni, Victor Schmidt, und Thomas Dandres. «Quantifying the Carbon Emissions of Machine Learning», 4. November 2019. https://doi.org/10.48550/arXiv.1910.09700.\n\n\nLong, Duri, und Brian Magerko. «What Is AI Literacy? Competencies and Design Considerations». In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–16. CHI ’20. New York, NY, USA: Association for Computing Machinery, 2020. https://doi.org/10.1145/3313831.3376727.\n\n\nLoukissas, Yanni A. All Data Are Local: Thinking Critically in a Data-Driven Society. Cambridge, Massachusetts: The MIT Press, 2019. https://doi.org/10.7551/mitpress/11543.001.0001.\n\n\nLuccioni, Alexandra Sasha, Christopher Akiki, Margaret Mitchell, und Yacine Jernite. «Stable Bias: Analyzing Societal Representations in Diffusion Models», 9. November 2023. https://doi.org/10.48550/arXiv.2303.11408.\n\n\nMattu, Lauren Kirchner, Jeff Larson. «Machine Bias». ProPublica. Zugegriffen 25. November 2024. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n\n\nMehrabi, Ninareh, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, und Aram Galstyan. «A Survey on Bias and Fairness in Machine Learning». ACM Comput. Surv. 54, Nr. 6 (13. Juli 2021): 115:1–35. https://doi.org/10.1145/3457607.\n\n\nMueller, Milton L. «It’s Just Distributed Computing: Rethinking AI Governance». Telecommunications Policy, Februar 2025, 102917. https://doi.org/10.1016/j.telpol.2025.102917.\n\n\nNoble, Safiya Umoja. Algorithms of Oppression: How Search Engines Reinforce Racism. New York: New York university press, 2018.\n\n\nO’Neil, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. First edition. New York: Crown Publishing Group, 2016.\n\n\nOffert, Fabian, und Ranjodh Singh Dhaliwal. «The Method of Critical AI Studies, A Propaedeutic», 10. Dezember 2024. https://doi.org/10.48550/arXiv.2411.18833.\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, u. a. «Training Language Models to Follow Instructions with Human Feedback», 4. März 2022. https://doi.org/10.48550/arXiv.2203.02155.\n\n\nPenedo, Guilherme, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, und Thomas Wolf. «The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale», 31. Oktober 2024. https://doi.org/10.48550/arXiv.2406.17557.\n\n\n«Surveillance Capitalism». In Wikipedia, 12. August 2024. https://en.wikipedia.org/w/index.php?title=Surveillance_capitalism&oldid=1239902991.\n\n\nZuboff, Shoshana. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. First trade paperback edition. New York, NY: PublicAffairs, 2017. https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus"
    ]
  },
  {
    "objectID": "contents/syllabus.html#sessions",
    "href": "contents/syllabus.html#sessions",
    "title": "Syllabus",
    "section": "",
    "text": "Formen der Diskriminierung (Rachel Huber): Workshop, Hands-on Session\nLeseauftrag:\n\nKein Leseauftrag, da Workshop.\n\nWeiterführende Literatur:\n\nCatherine D’Ignazio und Lauren F. Klein, Data Feminism, First MIT Press paperback edition (Cambridge, Massachusetts: The MIT Press, 2023), https://data-feminism.mitpress.mit.edu/.\n\n\n\n\nArchitecture (Moritz Mähr): Gegenüberstellung von wie Computer Scientist über Architekturentscheide sprechen vs. Humanities Scholars\nLeseauftrag:\n\nFabian Offert und Ranjodh Singh Dhaliwal, «The Method of Critical AI Studies, A Propaedeutic», 10. Dezember 2024, https://doi.org/10.48550/arXiv.2411.18833.\n\nWeiterführende Literatur:\n\nDuri Long und Brian Magerko, «What Is AI Literacy? Competencies and Design Considerations», in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, CHI ’20 (New York, NY, USA: Association for Computing Machinery, 2020), 1–16, https://doi.org/10.1145/3313831.3376727.\n\n\n\n\nCollecting Data (Moritz Mähr)\nLeseauftrag:\n\nKapitel 3 aus Yanni A. Loukissas, All Data Are Local: Thinking Critically in a Data-Driven Society (Cambridge, Massachusetts: The MIT Press, 2019), https://doi.org/10.7551/mitpress/11543.001.0001.\n\n\n\n\nTraining (Moritz Mähr): Environmental impact of training AI\nLeseauftrag:\n\nAlexandre Lacoste u. a., «Quantifying the Carbon Emissions of Machine Learning», 4. November 2019, https://doi.org/10.48550/arXiv.1910.09700.\n\nWeiterführende Literatur:\n\nLong Ouyang u. a., «Training Language Models to Follow Instructions with Human Feedback», 4. März 2022, https://doi.org/10.48550/arXiv.2203.02155.\n\n\n\n\nApplication (Recruiting) (Rachel Huber)\nLeseauftrag:\n\nZhisheng Chen, «Ethics and Discrimination in Artificial Intelligence-Enabled Recruitment Practices», Humanities and Social Sciences Communications 10, Nr. 1 (13. September 2023): 1–12, https://doi.org/10.1057/s41599-023-02079-x.\nEleanor Drage und Kerry Mackereth, «Does AI Debias Recruitment? Race, Gender, and AI’s ‹Eradication of Difference›», Philosophy & Technology 35, Nr. 4 (Dezember 2022): 89, https://doi.org/10.1007/s13347-022-00543-1.\n\n\n\n\nApplication (CCTV/Facial Recognition) (Rachel Huber)\nLeseauftrag:\n\nJoy Buolamwini und Timnit Gebru, «Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification», in Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Conference on Fairness, Accountability and Transparency, PMLR, 2018), 77–91, https://proceedings.mlr.press/v81/buolamwini18a.html.\n\nWeiterführende Literatur:\n\nShoshana Zuboff, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power, First trade paperback edition (New York, NY: PublicAffairs, 2017), https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.\n\n\n\n\nApplication (Predictive Policing/Migrationsalgo CH …) (Rachel Huber)\nLeseauftrag:\n\nLauren Kirchner Mattu Jeff Larson, «Machine Bias» (ProPublica), zugegriffen 25. November 2024, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n«Jobs für Flüchtlinge - Algorithmus verteilt neu Asylbewerber auf Kantone» (Schweizer Radio und Fernsehen (SRF), 10. Mai 2018), https://www.srf.ch/news/schweiz/jobs-fuer-fluechtlinge-algorithmus-verteilt-neu-asylbewerber-auf-kantone.\n«Algorithmus verbessert Erwerbschancen von Flüchtlingen» (ETH Zürich, 18. Januar 2018), https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/01/algorithmus-verbessert-erwerbschancen-von-fluechtlingen.html.\n\nWeiterführende Literatur:\n\nKirk Bansak u. a., «Improving Refugee Integration through Data-Driven Algorithmic Assignment», Science 359, Nr. 6373 (19. Januar 2018): 325–29, https://doi.org/10.1126/science.aao4408.\n\n\n\n\nApplication (ChatGPT) (Moritz Mähr)\nLeseauftrag:\n\nEmily M. Bender u. a., «On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜», in Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT ’21 (New York, NY, USA: Association for Computing Machinery, 2021), 610–23, https://doi.org/10.1145/3442188.3445922.\n\nWeiterführende Literatur:\n\nTed Chiang, «ChatGPT Is a Blurry JPEG of the Web», The New Yorker, 9. Februar 2023, https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web.\nDeep Dive into LLMs Like ChatGPT, 2025, https://www.youtube.com/watch?v=7xTGNNLPyMI.\n\n\n\n\nEvaluation and Monitoring (Moritz Mähr)\n\nLeseauftrag:\n\nAlexandra Sasha Luccioni u. a., «Stable Bias: Analyzing Societal Representations in Diffusion Models», 9. November 2023, https://doi.org/10.48550/arXiv.2303.11408.\nNinareh Mehrabi u. a., «A Survey on Bias and Fairness in Machine Learning», ACM Comput. Surv. 54, Nr. 6 (13. Juli 2021): 115:1–35, https://doi.org/10.1145/3457607.\n\n\n\n\nGovernance and Regulation (Rachel Huber)\nLeseauftrag:\n\n«EU Artificial Intelligence Act | Up-to-Date Developments and Analyses of the EU AI Act», zugegriffen 25. November 2024, https://artificialintelligenceact.eu/.\n«AlgorithmWatch» (AlgorithmWatch), zugegriffen 25. November 2024, https://algorithmwatch.org/de/.\n\nWeiterführende Literatur:\n\nMilton L. Mueller, «It’s Just Distributed Computing: Rethinking AI Governance», Telecommunications Policy, Februar 2025, 102917, https://doi.org/10.1016/j.telpol.2025.102917.\n\n\n\n\nPoster/Blog/Presentations\nLeseauftrag:\n\nCathy O’Neil, Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, First edition (New York: Crown Publishing Group, 2016).\n\n\n\n\nPoster/Blog/Presentations oder Glüehfisch mit Wichtel*in\nLeseauftrag:\n\nKein Leseauftrag",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus"
    ]
  },
  {
    "objectID": "contents/syllabus.html#leistungsnachweis",
    "href": "contents/syllabus.html#leistungsnachweis",
    "title": "Syllabus",
    "section": "",
    "text": "Der Kurs wird mit Bestanden/Nicht Bestanden (Pass/Fail) bewertet. Für den Leistungsnachweis stehen drei gleichwertige Formate zur Auswahl: Blogbeitrag, Poster oder Vortrag. Alle drei Optionen werden als gleichwertig betrachtet und nach den gleichen Kriterien beurteilt, sodass Sie das Format wählen können, das am besten zu Ihren Stärken passt. In allen Fällen geht es darum, ein Thema des Kurses selbstständig zu bearbeiten und verständlich aufzubereiten.\n\n\nEin Blogbeitrag ist ein (wahlweise) online veröffentlichter, schriftlicher Artikel, der ein Kursthema in verständlicher und ansprechender Form für eine breite Leserschaft aufbereitet. Dieses Format bietet Ihnen die Möglichkeit, komplexe Inhalte in einem populärwissenschaftlichen Stil zu vermitteln. Beachten Sie dabei, dass ein Blogtext keine formelle Hausarbeit ist – der Ton darf lockerer sein, doch die inhaltliche Qualität und Fachlichkeit sollen trotzdem gewährleistet sein (Wie schreibe ich einen Blogeintrag?). Wichtig ist, die Aufmerksamkeit der Leserinnen und Leser von Anfang bis Ende zu gewinnen und zu halten – etwa durch einen persönlichen Zugang, anschauliche Beispiele, einen eingängigen Schreibstil sowie das Einbinden von weiterführenden Links. Auf diese Weise können Sie Ihr Fachwissen einem interessierten Publikum effektiv und unterhaltsam näherbringen.\n\n\n\nEin Poster ist ein wissenschaftliches Plakat, auf dem ein Thema visuell ansprechend und in prägnanter Kürze dargestellt wird (Wissenschaftliches Poster: Tipps + Beispiel). Auf dem Poster fassen Sie die wichtigsten Erkenntnisse oder Kernideen Ihres gewählten Themas so zusammen, dass sie auf einen Blick erfassbar sind. Ein gutes Poster enthält insbesondere die folgenden Elemente (in gekürzter Form):\n\nTitel und Einführung: Ein prägnanter Titel sowie eine kurze Einführung ins Thema (Fragestellung und Kontext).\nMethode und Ergebnisse: Die Darstellung des Vorgehens bzw. der Methode und die zentralen Ergebnisse (unterstützt durch Grafiken oder Abbildungen).\nFazit und Quellen: Ein Schlussfazit (ggf. mit Ausblick) sowie die Angabe der wichtigsten Quellen.\n\nDiese Inhalte sollten klar strukturiert und optisch übersichtlich präsentiert werden. Das Poster wird idealerweise im Grossformat (z. B. A0) erstellt, damit Text und Abbildungen auch aus einiger Entfernung gut lesbar sind. In der Regel präsentieren Sie Ihr Poster auch mündlich im Kurs, daher lohnt es sich, das Poster übersichtlich zu gestalten und sich auf mögliche Nachfragen vorzubereiten.\n\n\n\nEin Vortrag ist eine mündliche Präsentation eines Kursthemas vor Publikum im Kurs, typischerweise von 10 bis 15 Minuten Dauer, in der Sie das gewählte Thema in eigenen Worten erklären und die Zuhörenden mit einem klar strukturierten Aufbau – Einleitung, Hauptteil, Schluss – durch die wichtigsten Punkte führen (Präsentation im Studium halten - So klappt’s! | Studieren.at. Ein guter Vortrag folgt einem roten Faden und bereitet die Inhalte verständlich für das Publikum auf. Achten Sie dabei auf eine deutliche, nicht zu schnelle Aussprache und halten Sie Blickkontakt mit den Zuhörenden. Visuelle Hilfsmittel (z. B. Folien) sollten übersichtlich gestaltet sein und nur zur Unterstützung dienen – lesen Sie also nicht einfach Ihren Text ab. Rechnen Sie ausserdem mit Fragen im Anschluss und seien Sie bereit, diese kompetent zu beantworten.\n\n\n\n\nWie schreibe ich einen Blogeintrag? (Wie schreibe ich einen Blogeintrag? – Korpora zur Analyse von Sprache und Kontext) – Praktische Anleitung zum wissenschaftlichen Bloggen (Uni Basel).\nMein erster wissenschaftlicher Blogartikel – was schreibe ich bloß? (Mein erster wissenschaftlicher Blogartikel – was schreibe ich bloß? – Redaktionsblog) – Erfahrungsbericht und Tipps für den ersten Blogpost (Sabine Scherz, Redaktionsblog).\nEssay Einleitung: Grundlagen, Tipps & Expertenhilfe (Essay Einleitung: Grundlagen, Tipps & Expertenhilfe von StudiBucht.) – Hinweise zum Aufbau einer guten Einführung (Struktur, fesselnder Einstieg), übertragbar auch auf andere Formate.\nhttps://blog.front-matter.io/posts/rogue-scholar-authorship-guidelines/ https://doi.org/10.53731/fnv8b-qfy78",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus"
    ]
  },
  {
    "objectID": "contents/syllabus.html#literatur",
    "href": "contents/syllabus.html#literatur",
    "title": "Syllabus",
    "section": "",
    "text": "Hinweis: Urheberrecht\n\n\n\nWir bemühen uns, frei zugängliche Literatur zu verwenden. Sollte dies nicht möglich sein, bitten wir Sie, die Literatur über die Bibliotheksplattform swisscovery zu beziehen. Von der Verwendung von Plattformen wie Library Genesis raten wir trotz stichhaltiger Argumente ab.\nSiehe Joe Karaganis, Hrsg. Shadow Libraries: Access to Knowledge in Global Higher Education, International Development Research Centre (Cambridge: The MIT Press, 2018), https://doi.org/10.7551/mitpress/11339.001.0001.\n\n\n\n\n«Algorithms of Oppression». In Wikipedia, 28. Juni 2022. https://en.wikipedia.org/w/index.php?title=Algorithms_of_Oppression&oldid=1095369660.\n\n\n«Algorithmus verbessert Erwerbschancen von Flüchtlingen». ETH Zürich, 18. Januar 2018. https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/01/algorithmus-verbessert-erwerbschancen-von-fluechtlingen.html.\n\n\n«AlgorithmWatch». AlgorithmWatch. Zugegriffen 25. November 2024. https://algorithmwatch.org/de/.\n\n\nAlma’aitah, Wafa’ Za’al, Abdullah Zawawi Talib, und Mohd Azam Osman. «Opportunities and Challenges in Enhancing Access to Metadata of Cultural Heritage Collections: A Survey». Artificial Intelligence Review 53, Nr. 5 (1. Juni 2020): 3621–46. https://doi.org/10.1007/s10462-019-09773-w.\n\n\nBansak, Kirk, Jeremy Ferwerda, Jens Hainmueller, Andrea Dillon, Dominik Hangartner, Duncan Lawrence, und Jeremy Weinstein. «Improving Refugee Integration through Data-Driven Algorithmic Assignment». Science 359, Nr. 6373 (19. Januar 2018): 325–29. https://doi.org/10.1126/science.aao4408.\n\n\nBender, Emily M., Timnit Gebru, Angelina McMillan-Major, und Shmargaret Shmitchell. «On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜». In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610–23. FAccT ’21. New York, NY, USA: Association for Computing Machinery, 2021. https://doi.org/10.1145/3442188.3445922.\n\n\nBuolamwini, Joy. Unmasking AI: A Story of Hope and Justice in a World of Machines. First edition. New York: Random House, 2023.\n\n\nBuolamwini, Joy, und Timnit Gebru. «Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification». In Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 77–91. PMLR, 2018. https://proceedings.mlr.press/v81/buolamwini18a.html.\n\n\nChen, Zhisheng. «Ethics and Discrimination in Artificial Intelligence-Enabled Recruitment Practices». Humanities and Social Sciences Communications 10, Nr. 1 (13. September 2023): 1–12. https://doi.org/10.1057/s41599-023-02079-x.\n\n\nChiang, Ted. «ChatGPT Is a Blurry JPEG of the Web». The New Yorker, 9. Februar 2023. https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web.\n\n\nD’Ignazio, Catherine, und Lauren F. Klein. Data Feminism. First MIT Press paperback edition. Cambridge, Massachusetts: The MIT Press, 2023. https://data-feminism.mitpress.mit.edu/.\n\n\nDeep Dive into LLMs Like ChatGPT, 2025. https://www.youtube.com/watch?v=7xTGNNLPyMI.\n\n\nDrage, Eleanor, und Kerry Mackereth. «Does AI Debias Recruitment? Race, Gender, and AI’s ‹Eradication of Difference›». Philosophy & Technology 35, Nr. 4 (Dezember 2022): 89. https://doi.org/10.1007/s13347-022-00543-1.\n\n\n«EU Artificial Intelligence Act | Up-to-Date Developments and Analyses of the EU AI Act». Zugegriffen 25. November 2024. https://artificialintelligenceact.eu/.\n\n\n«Jobs für Flüchtlinge - Algorithmus verteilt neu Asylbewerber auf Kantone». Schweizer Radio und Fernsehen (SRF), 10. Mai 2018. https://www.srf.ch/news/schweiz/jobs-fuer-fluechtlinge-algorithmus-verteilt-neu-asylbewerber-auf-kantone.\n\n\nKaraganis, Joe, Hrsg. Shadow Libraries: Access to Knowledge in Global Higher Education. International Development Research Centre. Cambridge: The MIT Press, 2018. https://doi.org/10.7551/mitpress/11339.001.0001.\n\n\nLacoste, Alexandre, Alexandra Luccioni, Victor Schmidt, und Thomas Dandres. «Quantifying the Carbon Emissions of Machine Learning», 4. November 2019. https://doi.org/10.48550/arXiv.1910.09700.\n\n\nLong, Duri, und Brian Magerko. «What Is AI Literacy? Competencies and Design Considerations». In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–16. CHI ’20. New York, NY, USA: Association for Computing Machinery, 2020. https://doi.org/10.1145/3313831.3376727.\n\n\nLoukissas, Yanni A. All Data Are Local: Thinking Critically in a Data-Driven Society. Cambridge, Massachusetts: The MIT Press, 2019. https://doi.org/10.7551/mitpress/11543.001.0001.\n\n\nLuccioni, Alexandra Sasha, Christopher Akiki, Margaret Mitchell, und Yacine Jernite. «Stable Bias: Analyzing Societal Representations in Diffusion Models», 9. November 2023. https://doi.org/10.48550/arXiv.2303.11408.\n\n\nMattu, Lauren Kirchner, Jeff Larson. «Machine Bias». ProPublica. Zugegriffen 25. November 2024. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n\n\nMehrabi, Ninareh, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, und Aram Galstyan. «A Survey on Bias and Fairness in Machine Learning». ACM Comput. Surv. 54, Nr. 6 (13. Juli 2021): 115:1–35. https://doi.org/10.1145/3457607.\n\n\nMueller, Milton L. «It’s Just Distributed Computing: Rethinking AI Governance». Telecommunications Policy, Februar 2025, 102917. https://doi.org/10.1016/j.telpol.2025.102917.\n\n\nNoble, Safiya Umoja. Algorithms of Oppression: How Search Engines Reinforce Racism. New York: New York university press, 2018.\n\n\nO’Neil, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. First edition. New York: Crown Publishing Group, 2016.\n\n\nOffert, Fabian, und Ranjodh Singh Dhaliwal. «The Method of Critical AI Studies, A Propaedeutic», 10. Dezember 2024. https://doi.org/10.48550/arXiv.2411.18833.\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, u. a. «Training Language Models to Follow Instructions with Human Feedback», 4. März 2022. https://doi.org/10.48550/arXiv.2203.02155.\n\n\nPenedo, Guilherme, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, und Thomas Wolf. «The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale», 31. Oktober 2024. https://doi.org/10.48550/arXiv.2406.17557.\n\n\n«Surveillance Capitalism». In Wikipedia, 12. August 2024. https://en.wikipedia.org/w/index.php?title=Surveillance_capitalism&oldid=1239902991.\n\n\nZuboff, Shoshana. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. First trade paperback edition. New York, NY: PublicAffairs, 2017. https://www.hachettebookgroup.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/?lens=publicaffairs.",
    "crumbs": [
      "Kursbeschreibung",
      "Syllabus"
    ]
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.\n\n\n\n\n\nDocs for Zenodo added\nFixed various typos and replaced favicon\n\n\n\n\n\nInitial version\n\n\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n\n…"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog",
    "section": "",
    "text": "Docs for Zenodo added\nFixed various typos and replaced favicon\n\n\n\n\n\nInitial version"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "…"
  },
  {
    "objectID": "CHANGELOG.html#section-1",
    "href": "CHANGELOG.html#section-1",
    "title": "Changelog",
    "section": "",
    "text": "…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Decoding Inequality: Kritische Perspektiven auf Machine Learning und gesellschaftliche Ungleichheit",
    "section": "",
    "text": "Die kritische Auseinandersetzung mit Machine-Learning-Systemen und ihren gesellschaftlichen Auswirkungen ist in der heutigen Zeit von höchster Relevanz. Während KI-Technologien zunehmend Einzug in alle Bereiche unseres Lebens halten - von der Gesundheitsversorgung über die Strafverfolgung bis hin zu Finanzdienstleistungen und sozialen Medien - wächst auch ihr Potenzial, bestehende soziale Ungleichheiten zu verstärken oder sogar neue zu schaffen. Die Fähigkeit, diese Systeme zu verstehen, ihre Auswirkungen auf bereits minorisierte Gesellschaftsgruppen kritisch zu hinterfragen und Lösungen für eine gerechtere Gestaltung zu entwickeln, ist entscheidend für eine ethisch verantwortungsvolle und sozial gerechte technologische Zukunft. Dieses Kolloquium befähigt Studierende, aktiv an dieser wichtigen gesellschaftlichen Debatte teilzunehmen und trägt zur Entwicklung von KI-Systemen bei, die das Gemeinwohl fördern und nicht untergraben.\nIn diesem Kolloquium untersuchen die Studierenden den gesamten Lebenszyklus von Machine-Learning-Systemen und dessen Auswirkungen auf gesellschaftliche Ungleichheit. Der Kurs beleuchtet, wie bewusste und unbewusste menschliche Verzerrungen und Vorurteile in jeder Phase des ML-Lebenszyklus eingebettet werden können und wie diese zu Diskriminierung in verschiedenen gesellschaftlichen Kontexten führen.\nAufbauend auf den theoretischen Grundlagen der Critical Algorithm Studies lernen die Studierenden, die ethischen, politischen, ökologischen und ökonomischen Implikationen von ML-Technologien zu analysieren. Der Kurs ist entlang des ML-Lebenszyklus strukturiert:\n\nArchitekturauswahl: Diskussion verschiedener ML-Architekturen und ihrer Auswirkungen auf Modellkapazitäten und -grenzen. Kritische Betrachtung, wie architektonische Entscheidungen bestimmte Voreingenommenheiten einbetten können.\n\nDatensammlung: Untersuchung von Datenquellen, Kuratierungs- und Filterprozessen. Kritische Perspektiven auf Repräsentationsprobleme, Copyright-Fragen und Umweltkosten der Datenspeicherung.\n\nTraining: Technische Aspekte des Trainingsprozesses und Auswahl von Hyperparametern. Kritische Betrachtung der Umweltauswirkungen, Arbeitsbedingungen in der KI-Industrie und Machtkonzentration bei ressourcenstarken Unternehmen.\n\nAnwendung: Analyse verschiedener Anwendungsfälle von ML-Systemen, Feinabstimmung für spezifische Aufgaben und Bereitstellungsstrategien. Kritische Diskussion ethischer Überlegungen, potenzieller Missbrauchsszenarien und Fragen der Transparenz und Erklärbarkeit.\n\nEvaluation und Überwachung: Methoden zur Bewertung von Modellleistung und Verzerrungen. Kritische Perspektiven auf die Grenzen aktueller Evaluierungsmetriken.\n\nGovernance und Regulierung: Diskussion aktueller und vorgeschlagener Regulierungsrahmen, ethischer Richtlinien und Herausforderungen bei der Steuerung sich schnell entwickelnder KI-Technologien.\n\nDurchgehend wird betont, dass die Entwicklung und der Einsatz von ML-Systemen auch als Geschäftsmodell zu verstehen sind. Die Studierenden lernen, die kommerziellen Interessen und wirtschaftlichen Auswirkungen zu analysieren, die die Gestaltung und den Einsatz dieser Technologien beeinflussen.\nDer Kurs kombiniert theoretische Reflexion mit praktischen Übungen. Die Studierenden werden sowohl mit den theoretischen (nicht-mathematischen) Grundlagen des maschinellen Lernens vertraut gemacht als auch in die Lage versetzt, kritische Analysen auf Basis aktueller Forschungsergebnisse durchzuführen und die implikationen für minorisierte Bevölkerungsgruppen von KI in der Gesellschaft zu verstehen. Praktische Beispiele, Fallstudien und Diskussionen aktueller Forschungsarbeiten werden regelmässig in die Lehrveranstaltung integriert, um die Verbindung zwischen technologischen Entwicklungen und ihren gesellschaftlichen Auswirkungen zu verdeutlichen.\nNach Abschluss des Kurses sind die Studierenden in der Lage:\n\nDen gesamten Lebenszyklus von Machine-Learning-Systemen zu verstehen und kritisch zu reflektieren\n\nDie Auswirkungen von Entscheidungen in jeder Phase des ML-Lebenszyklus auf potenzielle Verzerrungen und Diskriminierungen zu analysieren\n\nFormen der algorithmischen Diskriminierung in verschiedenen Anwendungskontexten zu identifizieren und zu analysieren\n\nDie ethischen, gesellschaftlichen und wirtschaftlichen Implikationen von ML-Anwendungen zu bewerten\n\nDie Rolle kommerzieller Interessen und Geschäftsmodelle in der Entwicklung und dem Einsatz von ML-Systemen zu verstehen\n\nLösungsstrategien für eine gerechtere und ethischere Gestaltung algorithmischer Systeme zu entwickeln\n\nEine produktiv-kritische Haltung im Umgang mit KI und ML einzunehmen, die technische, ethische und ökonomische Aspekte berücksichtigt\n\nAktuelle Regulierungsansätze und Governance-Herausforderungen im Bereich KI und ML zu diskutieren und zu bewerten\n\n\n\nUniversität Bern\nWalter Benjamin Kolleg / Digital Humanities\nMuesmattstrasse 45\n3012 Bern"
  },
  {
    "objectID": "index.html#impressum",
    "href": "index.html#impressum",
    "title": "Decoding Inequality: Kritische Perspektiven auf Machine Learning und gesellschaftliche Ungleichheit",
    "section": "",
    "text": "Universität Bern\nWalter Benjamin Kolleg / Digital Humanities\nMuesmattstrasse 45\n3012 Bern"
  },
  {
    "objectID": "LICENSE-AGPL.html",
    "href": "LICENSE-AGPL.html",
    "title": "Decoding Inequality 2025",
    "section": "",
    "text": "GNU AFFERO GENERAL PUBLIC LICENSE\n                   Version 3, 19 November 2007\nCopyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n                        Preamble\nThe GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nDevelopers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.\nA secondary benefit of defending all users’ freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate. Many developers of free software are heartened and encouraged by the resulting cooperation. However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.\nThe GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community. It requires the operator of a network server to provide the source code of the modified version running there to the users of that server. Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.\nAn older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals. This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.\nThe precise terms and conditions for copying, distribution and modification follow.\n                   TERMS AND CONDITIONS\n\nDefinitions.\n\n“This License” refers to version 3 of the GNU Affero General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\nSource Code.\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\nBasic Permissions.\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\nProtecting Users’ Legal Rights From Anti-Circumvention Law.\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\nConveying Verbatim Copies.\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\nConveying Modified Source Versions.\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\na) The work must carry prominent notices stating that you modified\nit, and giving a relevant date.\n\nb) The work must carry prominent notices stating that it is\nreleased under this License and any conditions added under section\n7.  This requirement modifies the requirement in section 4 to\n\"keep intact all notices\".\n\nc) You must license the entire work, as a whole, under this\nLicense to anyone who comes into possession of a copy.  This\nLicense will therefore apply, along with any applicable section 7\nadditional terms, to the whole of the work, and all its parts,\nregardless of how they are packaged.  This License gives no\npermission to license the work in any other way, but it does not\ninvalidate such permission if you have separately received it.\n\nd) If the work has interactive user interfaces, each must display\nAppropriate Legal Notices; however, if the Program has interactive\ninterfaces that do not display Appropriate Legal Notices, your\nwork need not make them do so.\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\nConveying Non-Source Forms.\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\na) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by the\nCorresponding Source fixed on a durable physical medium\ncustomarily used for software interchange.\n\nb) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by a\nwritten offer, valid for at least three years and valid for as\nlong as you offer spare parts or customer support for that product\nmodel, to give anyone who possesses the object code either (1) a\ncopy of the Corresponding Source for all the software in the\nproduct that is covered by this License, on a durable physical\nmedium customarily used for software interchange, for a price no\nmore than your reasonable cost of physically performing this\nconveying of source, or (2) access to copy the\nCorresponding Source from a network server at no charge.\n\nc) Convey individual copies of the object code with a copy of the\nwritten offer to provide the Corresponding Source.  This\nalternative is allowed only occasionally and noncommercially, and\nonly if you received the object code with such an offer, in accord\nwith subsection 6b.\n\nd) Convey the object code by offering access from a designated\nplace (gratis or for a charge), and offer equivalent access to the\nCorresponding Source in the same way through the same place at no\nfurther charge.  You need not require recipients to copy the\nCorresponding Source along with the object code.  If the place to\ncopy the object code is a network server, the Corresponding Source\nmay be on a different server (operated by you or a third party)\nthat supports equivalent copying facilities, provided you maintain\nclear directions next to the object code saying where to find the\nCorresponding Source.  Regardless of what server hosts the\nCorresponding Source, you remain obligated to ensure that it is\navailable for as long as needed to satisfy these requirements.\n\ne) Convey the object code using peer-to-peer transmission, provided\nyou inform other peers where the object code and Corresponding\nSource of the work are being offered to the general public at no\ncharge under subsection 6d.\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\nAdditional Terms.\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\na) Disclaiming warranty or limiting liability differently from the\nterms of sections 15 and 16 of this License; or\n\nb) Requiring preservation of specified reasonable legal notices or\nauthor attributions in that material or in the Appropriate Legal\nNotices displayed by works containing it; or\n\nc) Prohibiting misrepresentation of the origin of that material, or\nrequiring that modified versions of such material be marked in\nreasonable ways as different from the original version; or\n\nd) Limiting the use for publicity purposes of names of licensors or\nauthors of the material; or\n\ne) Declining to grant rights under trademark law for use of some\ntrade names, trademarks, or service marks; or\n\nf) Requiring indemnification of licensors and authors of that\nmaterial by anyone who conveys the material (or modified versions of\nit) with contractual assumptions of liability to the recipient, for\nany liability that these contractual assumptions directly impose on\nthose licensors and authors.\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\nTermination.\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\nAcceptance Not Required for Having Copies.\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\nAutomatic Licensing of Downstream Recipients.\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\nPatents.\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\nNo Surrender of Others’ Freedom.\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\nRemote Network Interaction; Use with the GNU General Public License.\n\nNotwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software. This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.\n\nRevised Versions of this License.\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU Affero General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\nDisclaimer of Warranty.\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\nLimitation of Liability.\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\nInterpretation of Sections 15 and 16.\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\n                 END OF TERMS AND CONDITIONS\n\n        How to Apply These Terms to Your New Programs\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n&lt;one line to give the program's name and a brief idea of what it does.&gt;\nCopyright (C) &lt;year&gt;  &lt;name of author&gt;\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published\nby the Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\nAlso add information on how to contact you by electronic and paper mail.\nIf your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source. For example, if your program is a web application, its interface could display a “Source” link that leads users to an archive of the code. There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a “copyright disclaimer” for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see https://www.gnu.org/licenses/.\n\n\n\n Back to top"
  }
]